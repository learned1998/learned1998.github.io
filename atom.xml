<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>learned🥝</title>
  
  
  <link href="https://www.fomal.cc/atom.xml" rel="self"/>
  
  <link href="https://www.fomal.cc/"/>
  <updated>2025-02-17T09:25:39.278Z</updated>
  <id>https://www.fomal.cc/</id>
  
  <author>
    <name>xiaoqi🥝</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>B站视频指南</title>
    <link href="https://www.fomal.cc/posts/8166d70a.html"/>
    <id>https://www.fomal.cc/posts/8166d70a.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.278Z</updated>
    
    <content type="html"><![CDATA[<h2 id="【工作流汇总】"><strong>【工作流汇总】</strong></h2><ol><li><strong>人物换装（pipe节点+Controlnet）</strong><a href="https://www.bilibili.com/video/BV1V94y1M7uf/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>人物换装（IDM-VTON）</strong><a href="https://www.bilibili.com/video/BV1wS421o7df/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>电商模特换装（OOTDiffusion）</strong><a href="https://www.bilibili.com/video/BV1RC411W74m/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>人物一键换背景（Image Rembg (Remove Background)节点）</strong><a href="https://www.bilibili.com/video/BV1nt4y1d7sx/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__一键产品换背景 __<a href="https://www.bilibili.com/video/BV1UH4y1j7rL/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>无锯齿产品换背景（BrushNet、IC-Light）</strong><a href="https://www.bilibili.com/video/BV1hx4y1H7jE/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__带字产品换背景 __<a href="https://www.bilibili.com/video/BV1QE421g77v/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__完美产品、模特换背景工作流：500个节点剖析 __<a href="https://www.bilibili.com/video/BV1Xx4y1b7uP/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>产品换背景（Flux、turbo、inpaint）</strong><a href="https://www.bilibili.com/video/BV1My2iYkE9t/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>实现人物指定部位指定效果（cutoff节点）</strong><a href="https://www.bilibili.com/video/BV1uK4y1B7oe/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>物体各个角度视图（stablezero123节点）</strong><a href="https://www.bilibili.com/video/BV1Be411E7yz/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>人物换脸：光影完美融合（InstaSwap节点）</strong><a href="https://www.bilibili.com/video/BV1hc411x7bn/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>人物完美换脸：像素融合、环境融合（FaceDetailer）</strong><a href="https://www.bilibili.com/video/BV1Vf421D7sA/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>人物换脸、效果最好（EcomID）</strong><a href="https://www.bilibili.com/video/BV1qzS6YGEou/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>AI写真+换脸（IpAdapter）</strong><a href="https://www.bilibili.com/video/BV1f5411y7m2/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__AI写真：“最像”（PLUID) __<a href="https://www.bilibili.com/video/BV1Ti421D7iu/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>AI摄影（IpAdapter_plus）</strong><a href="https://www.bilibili.com/video/BV1sm411m77e/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__人物一键仿妆（FaceDetailer） __<a href="https://www.bilibili.com/video/BV1om411D7TQ/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__人物多表情、面部修复 __<a href="https://www.bilibili.com/video/BV1cC41167fe/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__人物一致性工作流 __<a href="https://www.bilibili.com/video/BV1vx421Q71a/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__人物一致性工作流--在线编辑openPose+Depth：细节修复 __<a href="https://www.bilibili.com/video/BV1Px4y1B7Mr/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__人物一致性模型、InstantID部署 __<a href="https://www.bilibili.com/video/BV1Mv421279y/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>人物一致性（In-Context-LoRA）</strong><a href="https://www.bilibili.com/video/BV1T8UKYtE5m/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__多人一致性控制 __<a href="https://www.bilibili.com/video/BV1cm411B7in/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__人物风格转绘 __<a href="https://www.bilibili.com/video/BV1rH4y1E79Q/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__人物转绘人气工作流部署 __<a href="https://www.bilibili.com/video/BV1js421M7Dx/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__人物打光（IC-Light) __<a href="https://www.bilibili.com/video/BV1gx4y1i7wA/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>一键生成证件照（IpAdapter）</strong><a href="https://www.bilibili.com/video/BV1wE421g7NQ/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>分区控制，背景融合（set area节点）</strong><a href="https://www.bilibili.com/video/BV1fK411a7sj/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>卡通风格Lora（cottoncandy触发词）</strong><a href="https://www.bilibili.com/video/BV1Be411Y7kq/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__电影剧照风格图生成（IpAdapter) __<a href="https://www.bilibili.com/video/BV19e411Y71Q/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__8k级壁纸生成、低显存流畅运行 __<a href="https://www.bilibili.com/video/BV1qe411J79a/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>Wallpaper壁纸，极致细节控制（Comfyroll）</strong><a href="https://www.bilibili.com/video/BV1au4m1K7p4/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__真实手办生成 __<a href="https://www.bilibili.com/video/BV1op421Z7f9/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__自定义风格动物人形象（cutoff节点、IpAdapter） __<a href="https://www.bilibili.com/video/BV1k6421g7HP/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>2D转3D（Gemini、API、无代理平替）</strong><a href="https://www.bilibili.com/video/BV1TA4m1j7Db/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__十二生肖动物人拜年 __<a href="https://www.bilibili.com/video/BV1zJ4m1b7aL/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__游戏卡牌生成 __<a href="https://www.bilibili.com/video/BV1tU421o7hu/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>一键抠图：背景单独导出（GroundingDinaSAM、LaMa、IpAdapter、Fooocus Inpaint）</strong><a href="https://www.bilibili.com/video/BV1Fy421Y7rq/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>一键抠图：无背景主体（Laydiffuse）</strong><a href="https://www.bilibili.com/video/BV1mr421H7Ak/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__一键扩图 __<a href="https://www.bilibili.com/video/BV1By421h7Te/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__完美扩图：线条融合 __<a href="https://www.bilibili.com/video/BV1vm421V7eN/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__一键生成漫画书：自动排版与文字处理（Comfyroll） __<a href="https://www.bilibili.com/video/BV1Ry421b7DC/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__改进版一键生成漫画书：单点操作 __<a href="https://www.bilibili.com/video/BV1di421Z7ai/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__一键生成漫画书：多角色一致性、自动排版、单点操作 __<a href="https://www.bilibili.com/video/BV1sx4y1J7dG/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>室内设计工作流：噪声注入（LCM）</strong><a href="https://www.bilibili.com/video/BV1z1421S72b/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__噪声反演+区域注入+细节提升工作流 __<a href="https://www.bilibili.com/video/BV1GZ421t7uC/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__无Lora一键材质转换 __<a href="https://www.bilibili.com/video/BV1Y1421R74N/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__局部放大重绘：差分扩散+边缘融合 __<a href="https://www.bilibili.com/video/BV1jw4m117HR/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__lora训练素材生成：人物一致性 __<a href="https://www.bilibili.com/video/BV1mm421p7S3/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>动画工作流（AnimateDiff）</strong><a href="https://www.bilibili.com/video/BV1qi421U7W4/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__视频转绘 __<a href="https://www.bilibili.com/video/BV1xt421K7oB/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__视频表情迁移（LivePotrait） __<a href="https://www.bilibili.com/video/BV1hf421q75R/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__自定义人物一致性动画 __<a href="https://www.bilibili.com/video/BV1wr421w7Ac/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__老照片上色 __<a href="https://www.bilibili.com/video/BV1gJ4m1u7AK/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__动态海报 __<a href="https://www.bilibili.com/video/BV1qx4y1t7XL/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__真实系网红生成工作流（PhotoMaker、Flux） __<a href="https://www.bilibili.com/video/BV1Nfxke9ECN/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__高清放大与人物皮肤纹理增强，低硬件需求，高效果 __<a href="https://www.bilibili.com/video/BV1vgyeYgEjM/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>数字人对口型（LatentSync）</strong><a href="https://www.bilibili.com/video/BV19orLY5EGg/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__红包+人物拜年 __<a href="https://www.bilibili.com/video/BV1awfDYDEZE/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li></ol><h2 id="【模型、插件安装】"><strong>【模型、插件安装】</strong></h2><ol><li>__cfg++效果测试 __<a href="https://www.bilibili.com/video/BV18y411B7JC/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>N-Sidebar插件（管理插件）</strong><a href="https://www.bilibili.com/video/BV15E421P78K/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>Ollama、Forence、WD1.4、ClipInterrogator插件（提示词反推）</strong><a href="https://www.bilibili.com/video/BV1Jx4y1t7BJ/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>DynamicPrompt插件（动态提示词）</strong><a href="https://www.bilibili.com/video/BV1Nz421z7T8/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__262种提示词模板 __<a href="https://www.bilibili.com/video/BV1nJ4m1w78N/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__Stable Cascade本地部署 __<a href="https://www.bilibili.com/video/BV1Rm411D7tV/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__Lora训练（SDTrainer) __<a href="https://www.bilibili.com/video/BV1rc411e7c6/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>cutoff插件（增强描述与主体之间的联系）</strong><a href="https://www.bilibili.com/video/BV1uK4y1B7oe/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__10个真实人物脸部放大模型Upscale测评 __<a href="https://www.bilibili.com/video/BV1aT421k7CG/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__快手Kolors模型安装测评 __<a href="https://www.bilibili.com/video/BV12H4y1w7zy/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>SD3重绘插件UltraEdit（提示词打光类似于IC-Light）</strong><a href="https://www.bilibili.com/video/BV16W421R7Pu/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>controlnet Union插件（集成controlnet多个功能）</strong><a href="https://www.bilibili.com/video/BV1nM4m127Rr/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>PaintsUndo插件（一键生成手绘）</strong><a href="https://www.bilibili.com/video/BV19S421R72E/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__Kolors+Ipadapter __<a href="https://www.bilibili.com/video/BV1Pi421Y7M3/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__IPdapter Mad Assistant安装测评 __<a href="https://www.bilibili.com/video/BV1zS421R7i2/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__Kolors官方Ipadapter __<a href="http://bilibili.com/video/BV132421Z73T/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>kolors-inpainting模型（局部重绘、扩图）</strong><a href="https://www.bilibili.com/video/BV1Lrv1eKEKb/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__kolors全部模型解析 __<a href="https://www.bilibili.com/video/BV1Ahv4ecEaH/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__SAM v2模型安装和测试 __<a href="https://www.bilibili.com/video/BV1NfvaejEux/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__混元DIT模型安装测评 __<a href="https://www.bilibili.com/video/BV1ay411e7Em/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__SD生态分析+Flux安装测评 __<a href="https://www.bilibili.com/video/BV1fivoeMEKu/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__插件收藏量排行榜，前100插件简介分析分享 __<a href="https://www.bilibili.com/video/BV14qYFeWEkm/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__Flux pro模型安装测评 __<a href="https://www.bilibili.com/video/BV1bfY5evEoo/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__Flux量化修剪模型安装测评 __<a href="https://www.bilibili.com/video/BV1CXYfe7EUb/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__Flux Controlnet模型安装测评 __<a href="https://www.bilibili.com/video/BV1CXYfe7EUb/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__Flux V3 Controlnet模型安装测评 __<a href="https://www.bilibili.com/video/BV1KRp9eLEG9/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__Flux Controlnet Union模型安装测评 __<a href="https://www.bilibili.com/video/BV1m3WNe5EdR/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__Flux生态汇总及量化模型使用 __<a href="https://www.bilibili.com/video/BV1syWhemE1X/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>CogVideoX模型安装（文生视频）</strong><a href="https://www.bilibili.com/video/BV177pweSE3T/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>ComfyUI-3D-Pack插件（3D图像视频插件）</strong><a href="https://www.bilibili.com/video/BV1oFHQenEei/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__Flux控制方法大全 __<a href="https://www.bilibili.com/video/BV1cXpie9EUo/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__torch2.4.1+cu124安装，适配xformers __<a href="https://www.bilibili.com/video/BV1eQt4ecEnz/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>MiniCPM+Flux（自然语言提示词反推）</strong><a href="https://www.bilibili.com/video/BV1amsfeGEZq/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__Flux-controlnet-upscaler模型测试 __<a href="https://www.bilibili.com/video/BV1N64PejEJ3/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__Flux+Pulid效果测试 __<a href="https://www.bilibili.com/video/BV188xXeWE4y/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__Flux1.1 Pro molmo模型（提示词反推） __<a href="https://www.bilibili.com/video/BV18p25Y7ExA/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__Flux Turbo（8秒出图、产品换背景） __<a href="https://www.bilibili.com/video/BV1My2iYkE9t/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>Lora管理节点（自动获取Civitai模型信息，触发词，示例图像，正反向提示词等各种信息）</strong><a href="https://www.bilibili.com/video/BV1bPyWYeEbz/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li>__SD3.5及Torbo模型测试 __<a href="https://www.bilibili.com/video/BV1ew1wYJECi/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>EcomID插件（人物换脸）</strong><a href="https://www.bilibili.com/video/BV1qzS6YGEou/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>hunyuanVideo插件、混元大模型</strong> <a href="https://www.bilibili.com/video/BV1wUiRYxEKK/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li><li><strong>LatentSnyc插件（数字人对口型）</strong><a href="https://www.bilibili.com/video/BV19orLY5EGg/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>点击直达</strong></a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;【工作流汇总】&quot;&gt;&lt;strong&gt;【工作流汇总】&lt;/strong&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;人物换装（pipe节点+Controlnet）&lt;/strong&gt;&lt;a href=&quot;https://www.bilibili.com/video/BV1V</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
  <entry>
    <title>In-Context-LoRA使用教程</title>
    <link href="https://www.fomal.cc/posts/712cd454.html"/>
    <id>https://www.fomal.cc/posts/712cd454.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.279Z</updated>
    
    <content type="html"><![CDATA[<p><strong>前言：</strong></p><p><strong>Flux 模型本身可以在一定程度上保持图像风格和主题的一致，而 In-Context -LoRA作为一种微调手段，通过增强上下文关系，使得图像之间更加协调，风格一致，进一步增强Flux模型的一致性保持，尤其适用于需要连贯故事情节和一致风格设计的场景。</strong></p><p><strong>模型以及示例工作流下载：</strong><a href="https://pan.quark.cn/s/ef8c64027412">https://pan.quark.cn/s/ef8c64027412</a>，<strong>模型放置在models/loras目录中，拖入示例工作流即可进行使用。</strong></p><p><strong>官方页面：</strong><a href="https://huggingface.co/ali-vilab/In-Context-LoRA"><strong>https://huggingface.co/ali-vilab/In-Context-LoRA</strong></a></p><p><strong>在该页面可以看到详细的提示词模板以及图片设置参数，如下图所示，请严格按照官方给出的示例进行图片尺寸设置，以及提示词的书写规范，因为标签会严重影响出图质量。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000386.png" alt="image"></p><p><strong>一、film-storyboard的LoRA模型使用。</strong></p><p><strong>如下图所示，使用默认参数的出图效果，同一个图片的三个画面，对于任务一致性的保持很好，而且场景的复杂程度以及细节有很多，只是不容易保持多次生成的人物都是同一个。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000387.png" alt="image"></p><p><strong>可以使用单独的Flux lora来进行出图，比如上次训练的</strong><a href="https://www.bilibili.com/video/BV1Zkm8YkEzC/?spm_id_from=333.999.0.0&amp;vd_source=fc308fafd0eb9d759dccb9a42d40ae6c"><strong>人物一致性LoRA</strong></a><strong>，我们可以尝试去生成多张人物相同的图像。因为在LoRA训练的时候没有让衣服属于人物的特征，所以任务的衣服并没有保持一致。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000388.png" alt="image"></p><p><strong>二、font-design的LoRA模型使用。</strong></p><p><strong>如下图所示，使用默认参数的出图效果，该LoRA模型主要是完成平面设计。因为Flux模型优秀的文本生成能力，再加上该LoRA模型的一致性保持能力，能够非常优秀的去完成海报的设计，并且能够保持画风的一致性，还能够保持文本的理解能力。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000389.png" alt="image"></p><p><strong>使用到的提示词如下：The four-panel image showcases a playful bubble font in a vibrant pop-art style. [TOP-LEFT] displays “Pop Candy” in bright pink with a polka dot background; [TOP-RIGHT] shows “Sweet Treat” in purple, surrounded by candy illustrations; [BOTTOM-LEFT] has “Yum!” in a mix of bright colors; [BOTTOM-RIGHT] shows “Delicious” against a striped background, perfect for fun, kid-friendly products.</strong></p><p><strong>翻译后：这张四格图片展示了一种充满活力的波普艺术风格的俏皮泡泡字体。[TOP-LEFT]以亮粉色显示“Pop Candy”，背景为圆点；[上图]显示了紫色的“甜食”，周围是糖果插图；[BOTTOM-LEFT]以明亮的颜色混合着“美味！”；[BOTTOM-RIGHT]在条纹背景下显示“美味”，非常适合有趣、适合儿童的产品。</strong></p><p><strong>我们可以修改提示词去生成不通风格的图像，</strong></p><p><strong>使用到的提示词如下：This four grid image showcases a mysterious and sophisticated black grey art style with a black premium font design. [TOP-LEFT] Display “High Quality” in gray white color with a background of patchy advanced content; The picture shows a golden “Title” surrounded by men’s products; [BOTTOM-LEFT] blends “taste” with a deep and sophisticated color scheme; [BOTTOM-RIGHT] displays “Advanced” against a striped background, making it perfect for high-end products.</strong></p><p>__<br>翻译后：这张四格图片展示了一种神秘而又高级的黑灰艺术风格的黑色高级字体设计。[TOP-LEFT]以灰白颜色显示“High Quality”，背景为片状高级内容；[上图]显示了金色的“Title”，周围是男士用品；[BOTTOM-LEFT]以低沉高级的配色混合着“品味”；[BOTTOM-RIGHT]在条纹背景下显示“高级”，非常适合高端产品。__</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000390.png" alt="image"></p><p><strong>三、ppt-templates的LoRA模型使用。</strong></p><p><strong>如下图所示，使用默认参数的出图效果，该LoRA模型主要是完成PPT的设计，并且能够给出一致的PPT风格，能够根据你输入的内容去生成适合你主题的风格。如下图所示是一个瓜果蔬菜的烹饪工作坊的PPT设计，大模型给出了一种页面的排版方式。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000391.png" alt="image"></p><p><strong>我们通过修改提示词可以生成不同的主题的PPT，但是由于图像中留给文字的像素点并不多，所以最终出图文本基本上是不能使用的，所以更多的是作为一种风格参考来使用。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000392.png" alt="image"></p><p><strong>更多的性能发现以及LoRA模型的使用可能需要不断的测试以及发挥自行的创造力，所以大家可以尽情的测试和使用，同时我们也可以训练自己的IC-Context-Lora，和一般的Flux的Lora模型训练过程一样，只是数据集需要自行准备和进行标签标注，祝大家玩的开心！</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Flux 模型本身可以在一定程度上保持图像风格和主题的一致，而 In-Context -LoRA作为一种微调手段，通过增强上下文关系，使得图像之间更加协调，风格一致，进一步增强Flux模型的一致性保持，</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
  <entry>
    <title>[人物一致性]全套工作流详细指南（第一篇）数据集生成</title>
    <link href="https://www.fomal.cc/posts/a1df8914.html"/>
    <id>https://www.fomal.cc/posts/a1df8914.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.281Z</updated>
    
    <content type="html"><![CDATA[<p><strong>前言：</strong></p><p><strong>人物一致性一直是难以解决的难题，最近从</strong><a href="https://www.youtube.com/@mickmumpitz"><strong>Mick</strong></a><strong>大佬处获得灵感，我们可以使用Lora模型去进行人物特征的控制，从而完成一致人物的创作，但在这之前我们需要经过数据集生成，数据集处理以及Lora训练等过程，所以接下来我会用几篇文章将整个过程进行完整的复刻，并且会将中间产生的各种对比进行展示。</strong></p><p><strong>我基于这个方法训练的Lora模型：</strong><a href="https://civitai.com/models/922842/a-character-named-ssx"><strong>https://civitai.com/models/922842/a-character-named-ssx</strong></a></p><p><strong>全部内容整合包百度网盘： <a href="https://pan.baidu.com/s/1kMWahSx3_5Ht0m95yrl_XA?pwd=728c">https://pan.baidu.com/s/1kMWahSx3_5Ht0m95yrl_XA?pwd=728c</a></strong></p><p><strong>全部内容整合包夸克网盘：</strong><a href="https://pan.quark.cn/s/f0aeb1899a47"><strong>https://pan.quark.cn/s/f0aeb1899a47</strong></a></p><p>第一篇文章主要解决人物一致性数据集的生成，在__Mick的工作中他预先准备了openpose骨骼图，并选择Flux+union的方式去生成一致性人物__，但是经过我个人的测试该效果没有在我的电脑上表现很好，<strong>一方面是时间消耗过长，一方面是出图质量并不好</strong>。</p><ol><li><strong>下方为Flux+union的生图工作流，使用到了</strong><a href="https://huggingface.co/Shakker-Labs/FLUX.1-dev-ControlNet-Union-Pro"><strong>union-pro</strong></a><strong>的Controlnet模型。</strong></li></ol><p>下图为控制强度为1时，生成的图片似乎调取了union模型的canny效果，最终出图根本不成型，没有办法作为初始数据集使用。<img src="https://xiao666.sbs/PicGo/IMG_000000394.png" alt="image"></p><p>当我__降低控制强度到0.5__的时候，生成的图像并不会根据openpose而产生影响，该数据集也没有办法提供使用。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000395.png" alt="image"></p><p>当__控制强度给到0.58__，发现出图效果并不好，而且控制强度有明显的减弱，出图并不会根据骨骼图进行严格控制，导致最终的数据集不能够使用。<img src="https://xiao666.sbs/PicGo/IMG_000000396.png" alt="image"></p><p>所以针对以上的测评结果我放弃了对Flux+union的选择。</p><p>在选择其他方式生成数据集之前，先做理论分析，因为我们要生成严格按照姿势图进行扩散的图像，所以我们__要尽可能地保证模型可操作的像素点较多__，假如使用SD1.5的模型进行出图，那么__512*512的尺寸很难保证一张图像可以产生19个面部特征__，并且1.5的模型语义理解能力较差，综上所示，我选择在SDXL的模型中进行选择去完成初始数据集的生成。</p><ol><li><strong>传统的SDXL模型+controlnet结果测试</strong></li></ol><p>如下图所示，当我使用SDXL的模型+openpose进行出图时，为了保证SDXL模型较高的出图性能，所以我们选择使用__短词__的形式进行提示词的书写。</p><p><strong>能够明显的感觉到SDXL模型在色域的控制上不如Flux模型，比如生成的图像难以理解“纯白色的背景”，并且图像中包含较多噪点（可能可以通过调整提示词修改这一情况），而且生成的人物并不能保证统一的着装，或者说保证人物的统一发型，发色等一致性的内容。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000397.png" alt="image"></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000398.png" alt="image"><img src="https://xiao666.sbs/PicGo/IMG_000000399.png" alt="image"><img src="https://xiao666.sbs/PicGo/IMG_000000400.png" alt="image"></p><p><strong>但是这些也不是不能使用，假如经过多次抽卡也是有较大可能输出较好的数据集图像，所以大家可以自行尝试选择自己喜欢的工作流去进行数据集的生成。</strong></p><ol><li><strong>Kolors模型+Controlnet进行出图</strong></li></ol><p><strong>在我的测试当中，kolors模型展现了非常好的语义理解能力以及较好的姿势控制能力，并且可以通过中文提示词的输入进行图像的控制，并且对人物一致性的保持较好，所以我最终选择使用kolors进行图像处理，但是相较于其他的SDXL模型的控制方式，其实相差不大，所以数据集的生成大家可以按照自己的需求进行选择。</strong></p><p>__<br>__<img src="https://xiao666.sbs/PicGo/IMG_000000401.png" alt="image"><img src="https://xiao666.sbs/PicGo/IMG_000000402.png" alt="image"><img src="https://xiao666.sbs/PicGo/IMG_000000403.png" alt="image"><img src="https://xiao666.sbs/PicGo/IMG_000000404.png" alt="image"></p><p><strong>综上所示，在人物一致性的数据集生成阶段，我推荐大家优先选择kolors+cn的方式去进行数据集的生成，重点是在提示词中一定要出现“人物设计稿”这个词语，这样能够尽最大的可能去保证你出图的一致性。</strong></p><p><strong>在这个阶段不要太纠结出图的质量（比如人物的面部细节，衣服的细节），这些内容可以在下一步的图像修复以及分割完成，后续通过修复可以提升图像的质量并且进一步保证一致性的控制。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;人物一致性一直是难以解决的难题，最近从&lt;/strong&gt;&lt;a href=&quot;https://www.youtube.com/@mickmumpitz&quot;&gt;&lt;strong&gt;Mick&lt;/strong&gt;&lt;/a&gt;&lt;</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
  <entry>
    <title>[ComfyUI便携包]星球内部便携包，解压即用</title>
    <link href="https://www.fomal.cc/posts/9d8656e4.html"/>
    <id>https://www.fomal.cc/posts/9d8656e4.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.280Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言："><strong>前言：</strong></h3><p><strong>为了各位更加便捷的使用ComfyUI，并且解决部分安装插件的错误，我做了一个便携包，内置多种常用插件，各位下载后只需将之前的model文件夹进行复制粘贴即可使用。</strong></p><p><strong>便携包插件目录：</strong><img src="https://xiao666.sbs/PicGo/IMG_000000393.png" alt="image"></p><p><strong>一、ComfyUI_Comfyroll_CustomNodes插件</strong></p><p>该插件内置许多图像处理节点以及随机图案生成节点，对于潜空间噪声设置，以及用作底图参考具有重要意义。</p><p><strong>二、comfyui_controlnet_aux插件</strong></p><p>该插件为Controlnet预处理插件，包含几乎所有的图像预处理方式，比如depth、openpose等。</p><p><strong>三、ComfyUI_FaceAnalysis插件</strong></p><p>该插件节点主要作用是分析两张图像人物脸部的相似程度，常配合faceid、instantID使用。</p><p><strong>四、ComfyUI_InstantID插件</strong></p><p>该插件常用作AI摄影以及换置顶人脸使用，适用性极广，为必备插件。</p><p><strong>五、ComfyUI_IPAdapter_plus插件</strong></p><p>该插件用做风格迁移，AI摄影，材质转换等等场景，适用性极广，为必备插件。</p><p><strong>六、comfyui_segment_anything插件</strong></p><p>该插件常用来做蒙版绘制、语义分割等各种事宜，为必备插件。</p><p><strong>七、ComfyUI-Crystools插件</strong></p><p>该插件常用功能为功能占用显示，比如实时显存占用，显卡温度等各种设备信息展示。</p><p><strong>八、ComfyUI-depth-fm插件</strong></p><p>该插件用来生成fm深度图，包含超多细节信息，做雕塑和浮雕必备插件。</p><p><strong>九、ComfyUI-Impact-Pack插件</strong></p><p>该插件为SEGS蒙版插件，可实现脸部修复，完美换脸，局部重绘等各种效果较好的节点，为必备插件。</p><p><strong>十、ComfyUI-Inspire-Pack插件</strong></p><p>该插件为第九配套插件，必备。</p><p><strong>十一、comfyui-inpaint-nodes插件</strong></p><p>该插件为局部填充，局部重绘插件，可搭配fooocus使用，效果较好。</p><p><strong>十二、ComfyUI-layerdiffusion插件</strong></p><p>该插件可以生成无背景主题图，对表情包生成，贴纸生成有较好的协助作用。</p><p><strong>十三、ComfyUI-Manager插件</strong></p><p>该插件为管理器插件，可进行环境维护，插件升级，插件安装等各种功能，为必备插件！</p><p><strong>十四、comfyui-mixlab-nodes插件</strong></p><p>该插件首先可以使用两个端口使用comfyui，其次可以生成工作流api接口，可以链接节点到github地址。</p><p><strong>十五、Comfyui-StableSR插件</strong></p><p>该插件为高清修复节点插件。</p><p><strong>十六、ComfyUI-SUPIR插件</strong></p><p>该插件为高清修复节点插件。</p><p><strong>十七、ComfyUI-WD14-Tagger插件</strong></p><p>该插件可对图像进行提示词反推，包内已携带wd-v1-4-moat-tagger-v2.onnx模型。</p><p><strong>十八、rgthree-comfy插件</strong></p><p>该插件为工作流控制插件，可以快速bypass组或者节点，等各种功能。</p><p><strong>十九、sdxl_prompt_styler插件</strong></p><p>该插件为提示词模板插件。</p><p><strong>特色：该插件更新torch版本并且已经安装适配的xformers库。</strong></p><p><strong>xformers可以极大减少内存占用和显存占用，可以提高模型推理能力，比如depth-fm插件节点的使用，如果没有安装xformers，则会导致内存占用接近35G，而安装后仅需6-8个G即可完成推理。</strong></p><p><strong>下载链接：</strong></p><p>__百度网盘：链接: <strong><a href="https://pan.baidu.com/s/1jq87z5BWyY0sYZbfsLufCA?pwd=ahpe"><strong>https://pan.baidu.com/s/1jq87z5BWyY0sYZbfsLufCA?pwd=ahpe</strong></a></strong> 提取码: ahpe __</p><p><strong>夸克网盘：</strong><a href="https://pan.quark.cn/s/18992dca0aac"><strong>https://pan.quark.cn/s/18992dca0aac</strong></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;前言：&quot;&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;为了各位更加便捷的使用ComfyUI，并且解决部分安装插件的错误，我做了一个便携包，内置多种常用插件，各位下载后只需将之前的model文件夹进行复制粘贴即可使用。&lt;/strong&gt;</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
  <entry>
    <title>[人物一致性]全套工作流详细指南（第三篇）批量图像修复以及分割多表情</title>
    <link href="https://www.fomal.cc/posts/a09b499f.html"/>
    <id>https://www.fomal.cc/posts/a09b499f.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.282Z</updated>
    
    <content type="html"><![CDATA[<p><strong>前言：</strong></p><p><strong>人物一致性一直是难以解决的难题，最近从</strong><a href="https://www.youtube.com/@mickmumpitz"><strong>Mick</strong></a><strong>大佬处获得灵感，我们可以使用Lora模型去进行人物特征的控制，从而完成一致人物的创作，但在这之前我们需要经过数据集生成，数据集处理以及Lora训练等过程，所以接下来我会用几篇文章将整个过程进行完整的复刻，并且会将中间产生的各种对比进行展示。</strong></p><p><strong>我基于这个方法训练的Lora模型：</strong><a href="https://civitai.com/models/922842/a-character-named-ssx"><strong>https://civitai.com/models/922842/a-character-named-ssx</strong></a></p><p><strong>全部内容整合包百度网盘：</strong><a href="https://pan.baidu.com/s/1kMWahSx3_5Ht0m95yrl_XA?pwd=728c">__ https://pan.baidu.com/s/1kMWahSx3_5Ht0m95yrl_XA?pwd=728c__</a>__ __</p><p><strong>全部内容整合包夸克网盘：</strong><a href="https://pan.quark.cn/s/f0aeb1899a47"><strong>https://pan.quark.cn/s/f0aeb1899a47</strong></a></p><p><strong>下图为高清修复工作流，在确定方法之前做了很多的测试，本篇文章将对测试过程中出现的各种问题进行详细的描述，以及对比各种放大插件之间的区别，可能不同风格的图像各有区别，目前我个人测试下来动漫最优的组合为StableSR进行图像的去模糊，然后使用Flux+upscaler进行高清放大。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000405.png" alt="image"></p><p><strong>一、假如使用Supir进行图像修复</strong></p><p><strong>下图为使用SUPIR进行高清放大的工作流，使用SDXL的加速模型配合使用，提示词给出anime man，让他进行修复。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000406.png" alt="image"></p><p><strong>下图为修复后的结果展示，从结果来看，在人物的SUPIR放大过程中，会向图像中添加纹理（可能真实人物使用SUPIR会更加适合），比如人物的头发会出现多余的线条，眼睛的瞳孔也会因为纹理的添加而导致最终非动漫的效果，丧失了原图眼睛的光晕，但是去模糊效果还是很不错的。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000407.png" alt="image"></p><p><strong>二、使用FLUX+SDupscaler进行放大。</strong></p><p><strong>当我们使用SDupscaler的时候，需要去选择合适的</strong><a href="https://openmodeldb.info/models/2x-MLP-StarSample-V1-0"><strong>放大模型</strong></a><strong>，我在网站上找了很久找到了一个Anime的放大，但是配合Flux放大效果依然不好。</strong></p><p><strong>工作流如下图所示，从放大结果来看原图的模糊程度并没有去除，可能是因为重绘幅度过低的原因，但是当我们提高重绘幅度还是会造成原图的变化，更甚者会造成最终的图像出现明显的接缝。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000408.png" alt="image"></p><p><strong>下图为不同重绘幅度下的表现，可以看到放大的效果并不好，而且最终的结果是图像既没有去模糊也没有很好的处理线条轮廓，所以这种方法就不做推荐（大家可以自行测试，也许某种参数下会表现更好。）</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000409.png" alt="image"></p><p><strong>三、因为SUPIR可以完成去模糊的操作，所以不需要添加StableSR去做事先的处理，所以这次我们选择直接使用Flux+UPscaler进行放大。</strong></p><p><strong>下图为Flux+upscaler放大工作流，使用到了Florence进行提示词的反推。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000410.png" alt="image"></p><p><strong>当我们给出的控制强度较低时，模型可能会在放大的过程中对图像进行变化，而且没有整体出图，可能出现一致性出现问题，最容易出现的情况就是人物的眼睛会有颜色的改变，但是当我们提高控制强度的时候，最终的出图一致性保持较好但是会产生拟合原图的模糊情况。但这也给我们提供了很好的思路，就是控制强度高能做到几乎无差的分辨率调整放大。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000411.png" alt="image"></p><p><strong>四、StableSR去模糊后使用Flux+upscaler进行放大修复（最终方法）</strong></p><p><strong>该方法即为最终敲定的方式，就如上面的分析所示，假如我们使用高强度的upscaler去进行修复，能够最大程度地保证原图的一致性，但是会难以去除原图的模糊，导致数据集的质量低下（非常影响Lora的训练效果），所以这个时候我就想到了StableSR插件，它本身就可以较好的保持一致性去除模糊，在配合Flux+upscaler就可以非常好的去完成这一项操作。</strong></p><p><strong>下图为初步进行去模糊操作的结果，从右边可以看到，StableSR对原图几乎没有改变的情况下，进行了图像的去模糊操作，让图像的马赛克几乎消除完毕，随后可以再利用FLUX+UPscaler优秀的一致性保持去完成后续的放大操作。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000412.png" alt="image"></p><p><strong>下图为原图-去模糊-高清放大后的图像，最终的结果我非常满意，在加上整体的时间消耗并不大，可以让我在较短的时间完成二十多张数据集的放大修复过程，并且保持一致性。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000413.png" alt="image"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;人物一致性一直是难以解决的难题，最近从&lt;/strong&gt;&lt;a href=&quot;https://www.youtube.com/@mickmumpitz&quot;&gt;&lt;strong&gt;Mick&lt;/strong&gt;&lt;/a&gt;&lt;</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
  <entry>
    <title>[人物一致性]全套工作流详细指南（第二篇）图像修复以及分割多表情</title>
    <link href="https://www.fomal.cc/posts/8e5504f.html"/>
    <id>https://www.fomal.cc/posts/8e5504f.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.283Z</updated>
    
    <content type="html"><![CDATA[<p><strong>前言：</strong></p><p><strong>人物一致性一直是难以解决的难题，最近从</strong><a href="https://www.youtube.com/@mickmumpitz"><strong>Mick</strong></a><strong>大佬处获得灵感，我们可以使用Lora模型去进行人物特征的控制，从而完成一致人物的创作，但在这之前我们需要经过数据集生成，数据集处理以及Lora训练等过程，所以接下来我会用几篇文章将整个过程进行完整的复刻，并且会将中间产生的各种对比进行展示。</strong></p><p><strong>我基于这个方法训练的Lora模型：</strong><a href="https://civitai.com/models/922842/a-character-named-ssx"><strong>https://civitai.com/models/922842/a-character-named-ssx</strong></a></p><p><strong>全部内容整合包百度网盘：</strong><a href="https://pan.baidu.com/s/1kMWahSx3_5Ht0m95yrl_XA?pwd=728c">__ https://pan.baidu.com/s/1kMWahSx3_5Ht0m95yrl_XA?pwd=728c__</a></p><p><strong>全部内容整合包夸克网盘：</strong><a href="https://pan.quark.cn/s/f0aeb1899a47"><strong>https://pan.quark.cn/s/f0aeb1899a47</strong></a></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000414.png" alt="image"></p><p><strong>该阶段工作流如上图所示，此时的放大不仅要增加图像的分辨率而且需要对原图毁坏部分进行重绘，所以我选择Flux+UPscaler的方式进行图像的高清修复，因为该过程需要涉及到扩散并且会对原图产生一定的修复，同时又能够利用Flux模型优秀的美学特征能力，而且在一整张图像进行扩散的时候能够从全局进行一致性人物的控制，综上所述，初步的放大阶段，使用该方式。</strong></p><h3 id="一、下图为放大模块的主要工作流，其中有几个注意事项一定要重视。image"><strong>一、下图为放大模块的主要工作流，其中有几个注意事项一定要重视。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000415.png" alt="image"></h3><ol><li><strong>Florence提示词反推要在反推后卸载模型</strong></li></ol><p><img src="https://xiao666.sbs/PicGo/IMG_000000416.png" alt="image"></p><p>当我们对图像进行高清修复时，<strong>因为要进行扩散，所以需要引入提示词</strong>，如果能够提供符合原图的提示词，那么一定会使扩散的过程更加的稳定可控，所以我们需要使用到合适的提示词反推模型去完成图片的描述，F__lux模型使用Clipl+T5模型作为文本编码模块，在训练的过程中使用自然语言进行图像的标注，<strong>所以我们需要选择LLM进行提示词的反推，<strong>诸如“prompt styler，WD14”的短词提示词反推模型就不适合在Flux模型中使用</strong>，而诸如Ollama，joycaption，molmo等模型就能更好地完成任务，而__LLM对显存的占用会到较高的程度，所以我们必须在模型反推完提示词之后进行模型的卸载</strong>，不然会严重影响我们出图的速度，毕竟后续是使用了Flux+upscaler+1536*1536的出图尺寸。<strong>即上图节点必须关闭keep_model_loaded参数。</strong></p><ol><li><strong>UPscaler模型的强度会较为影响出图效果</strong></li></ol><p><strong>在测试的过程中发现UPscaler模型的强度对最终的出图效果会有较为强烈的影响，当我们设置模型的强度过高，则会导致模型在扩散的过程中更见偏向与拟合输入的图像（即毁坏的图像），所以修复程度较低。</strong></p><p><strong>下图为1.0的控制强度，最终出图区域拟合原图中毁坏的地方，所以约等于重绘幅度很低，最终出图人物的面部特征修复并不明显，特别是较小的脸部（左下角），会导致无面部特征。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000417.png" alt="image"></p><p><strong>下图为0.5的控制强度，可以看到减弱控制强度相当于增强模型的重绘幅度，最终出图完成了人物的面部修复，并且在较小的面部仍然能够很好地完成面部特征描绘。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000418.png" alt="image"></p><p><strong>下图为0.5的控制强度，以及0.5的end_persent，这只是提供的一种参考参数设置，大家可以按照自己的想法创建，从对比结果来看效果跟上面的0.5控制强度差不多，但是我个人想让模型能够有更大的空间去发挥自己的性能，所以在end_persent就多给出了0.5的自我发挥时间。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000419.png" alt="image"></p><ol><li><strong>Color match进行色彩匹配</strong></li></ol><p><strong>当我们使用UPscaler进行图像放大后，因为放给了模型一定的自我发挥空间，所以就会带来一定的副作用，比如最终出图会影响原图的色彩信息，如下图所示，当我们完成了图像的修复以及分辨率放大，图片的背景就不再是纯白色，进而带来的就是图片发灰，而背景和主体的颜色对比会影响，（当图片主体和背景的对比产生变化，会导致最终出图受影响，最明显的就是在人物换装插件中，如果上传参考衣服背景不是纯白，换装后衣服会产生色差），所以我就做了一个color match操作，（也可能是多虑了，反正大家自己考虑是否使用）。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000420.png" alt="image"></p><h3 id="二、下图为修复模块的工作流"><strong>二、下图为修复模块的工作流</strong></h3><p><strong>在该模块使用两个facedetailer节点用来做原图的修复，根据上传BBox探测器的不同完成不同部分的修复，比如当我们上传hand检测模型，则该节点功能为对原图进行手部修复。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000421.png" alt="image"></p><p><strong>在进行脸部修复之前，我加载了Pulid模型来增强面部的相似程度，因为该节点是分区域进行重绘，并不如Flux upscaler模型一样进行全局的重绘，所以在这个阶段我们有必要去保持人物面部的相似程度，那么当前在Flux模型中，面部迁移就使用Pulid就可。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000422.png" alt="image"></p><p><strong>下方节点可以通过选择不同的模型去完成不同区域的重绘，所以大家需要根据自己的图像需要修复的区域去选择对应的模型。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000423.png" alt="image"></p><h3 id="三、多表情生成区域。"><strong>三、多表情生成区域。</strong></h3><p>__<br>__<img src="https://xiao666.sbs/PicGo/IMG_000000424.png" alt="image"></p><p><strong>该部分依然使用多个facedetailer节点去进行面部表情的更换，依然需要加载Pulid模型去保证人物面部特征的统一，通过提示词和增加重绘幅度来完成面部表情的变换，因为使用了Flux模型，所以我们只需要修改正向提示词即可。</strong></p><p><strong>在我测试的过程中，发现提示词和Pulid并不能完全控制人物眼睛颜色变化，可能是由于重绘幅度并不高的原因，但是增加重绘幅度会导致出图的边缘融合度降低，所以需要大家自行选择或者尝试多次抽卡去完成数据集的生成。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000425.png" alt="image"></p><h3 id="四、图像分割以及放大保存区域"><strong>四、图像分割以及放大保存区域</strong></h3><p><strong>该区域需要完成图像的裁剪，因为坐标的不同以及图像大小的不同，所以可能需要大家自行调整参数。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000426.png" alt="image"></p><p><strong>下面的节点为设置裁剪图像的长宽，然后设置裁剪的坐标起始位置，在ComfyUI中，坐标原点从图像的左上角开始（不同的插件可能有区别），所以如果大家跑图的时候出现在裁剪图像不符合原图，则需要大家自行进行参数的调整。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000427.png" alt="image"></p><p><strong>图像尺寸调整完毕之后，我们需要将图像进行保存，但是保存之前我们要将尺寸调整到适合Flux的lora训练的大小，在SD1.5模型中，使用到的数据集是512*512的尺寸，但是在SDXL和SD3架构下的大模型，训练集使用的是1024*1024的尺寸，所以我们需要将我们的图像调整到1024附近。下图所示的节点即完成了图像到list的处理，并且完成了图像尺寸的调整，同时保持数据集的分辨率。但是此时的数据集还不能够使用，需要在做下一步的去噪和放大。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000428.png" alt="image"></p><p><strong>数据集的保存文件夹为output/im/下。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;人物一致性一直是难以解决的难题，最近从&lt;/strong&gt;&lt;a href=&quot;https://www.youtube.com/@mickmumpitz&quot;&gt;&lt;strong&gt;Mick&lt;/strong&gt;&lt;/a&gt;&lt;</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
  <entry>
    <title>[人物一致性]全套工作流详细指南（第四篇）动物IP形象数据集制作指南</title>
    <link href="https://www.fomal.cc/posts/c3e17296.html"/>
    <id>https://www.fomal.cc/posts/c3e17296.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.283Z</updated>
    
    <content type="html"><![CDATA[<p><strong>前言：</strong></p><p><strong>通过骨骼图只能完成真实人物或动漫人物的创作，那么对于非人物的IP形象就带来了困扰，前段时间刚发布的redux模型能够非常不错的保持风格和一致性，所以就给我带来了灵感，通过图像融合可以非常轻松的完成动物数据集的制作，如果再配合fluxfill+redux完成扩图就可以进一步丰富数据集的多样性，那么本篇文章将详细的描述数据集制作的整个过程。</strong></p><p><strong>我基于这个方法训练的Lora模型：</strong><a href="https://civitai.com/models/991000"><strong>https://civitai.com/models/991000</strong></a></p><p><strong>全部内容整合包百度网盘：</strong><a href="https://pan.baidu.com/s/1kMWahSx3_5Ht0m95yrl_XA?pwd=728c"><strong>https://pan.baidu.com/s/1kMWahSx3_5Ht0m95yrl_XA?pwd=728c</strong></a></p><p><strong>全部内容整合包夸克网盘：</strong><a href="https://pan.quark.cn/s/f0aeb1899a47"><strong>https://pan.quark.cn/s/f0aeb1899a47</strong></a></p><p><strong>数据集生成可以有多种方式，如果要生成动物的IP形象，可以直接通过Flux模型生成，就像IC-Context-lora所述一样，Flux模型本省就具有上下文能力，只是我们要通过怎么样的方式去调用这种性能，如下图所示基础的Flux文生图工作流，可以通过简单的提示词去生成对应的IP形象：（该工作流可在网盘下载）</strong><img src="https://xiao666.sbs/PicGo/IMG_000000429.png" alt="image"></p><p><strong>上述提示词为：A design with multiple perspectives of a cute little raccoon on a pure white background, featuring nine different angles and actions, wearing a large yellow flat topped straw hat, blue big eyes, cute pink tail, rich colors, and accessories,</strong></p><p><strong>翻译：一个在纯白色背景上有多个视角的可爱小浣熊的设计，有九个不同的角度和动作，戴着一顶黄色平顶草帽，蓝色大眼睛，可爱的粉红色尾巴，丰富的色彩和配饰，</strong></p><p><strong>假如说要生成一致性的数据集，那么提示词当中“多视角xxx的设计图”是十分重要的存在，设计图本身的概念就牵扯到一致性，所以大家要注意将这句话写在提示词的前面增加提示词的权重以及模型的遵守能力，但是该方法生成的数据集只有9张，不足以支持我们完成Lora模型的训练（推荐20张以上，并且包含多个视角多种分辨率多种表情），所以说下一步我们可以通过redux+fluxfill的方式去完成我们额外数据集的制作，并且保证形象的一致性。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000430.png" alt="image"></p><p><strong>扩图结果如下图所示，从原来的3*3到5*5，数据集增加到25张，并且很好的保持了一致性，比如角色的装饰以及粉色的尾巴，那么这些数据集经过分割和放大之后就可以完成lora模型的训练，如果觉得质量还有待提高，那么可以经过后续的修复完成数据集的制作。（该工作流在网盘中为Fluxfill+redux）</strong></p><p><strong>在该工作流当中，进行扩图不仅要用到redux进行原图的形象参考，还需要使用到提示词进行控制，这个时候我们可以通过“一致的形象”等提示词去增加模型的一致性控制能力。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000431.png" alt="image"></p><p><strong>那么我们还可以基于redux进行图像的融合，完成我们动物人数据集的制作，将之前的人物图像和动漫形象进行合并，参考出图，如下图所示可以将之前生成的人物数据集作为融合图的一部分去控制最终出图的形象分布，随后将需要融合的动物形象作为第二个条件进行输入，经过融合即可完成动物人数据集的制作，但是可能数据集中角色表情以及脸部朝向不够丰富，后续我们可以通过图像反转完成视角的转换，也可以通过多次运行 工作流改变种子去生成多张数据集，从中选择形象相近的角色去完成数据集的选取。（该工作流为网盘中redux+duble）</strong><img src="https://xiao666.sbs/PicGo/IMG_000000432.png" alt="image"></p><p><strong>经过数据集的处理和筛选，我们可以选择20张左右的数据集去尝试进行标签标注，此过程特别的重要，</strong><a href="https://www.bilibili.com/video/BV1Zkm8YkEzC/?spm_id_from=333.999.0.0&amp;vd_source=fc308fafd0eb9d759dccb9a42d40ae6c"><strong>B站视频有详细描述标签标注的细节</strong></a><strong>，如果做lora训练，该内容为必须学习内容，请大家足够重视，标注后的数据集以及标签我都有上传到网盘（dreamoo放大后的数据集文件夹中），大家可以参考进行个人数据集的标注。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000433.png" alt="image"></p><p><strong>随后就是模型训练，训练的工作流以及参数等内容均在网盘中有提供，不想自己配置插件和环境的可以下载“整合包-人物一致性”去完成Lora模型的训练，细节大家可以</strong><a href="https://www.bilibili.com/video/BV1Zkm8YkEzC/?spm_id_from=333.999.0.0&amp;vd_source=fc308fafd0eb9d759dccb9a42d40ae6c"><strong>观看该视频</strong></a><strong>进行学习，这里不做赘述了，最终lora模型效果如下图所示，大家可以在网盘当中下载</strong><a href="https://civitai.com/models/991000"><strong>该模型</strong></a><strong>进行测试，这个角色名字叫做“dreamoo”，祝大家玩的开心。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000434.png" alt="image"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;通过骨骼图只能完成真实人物或动漫人物的创作，那么对于非人物的IP形象就带来了困扰，前段时间刚发布的redux模型能够非常不错的保持风格和一致性，所以就给我带来了灵感，通过图像融合可以非常轻松的完成动物数</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
  <entry>
    <title>[各类网站使用方法]OpenArt、GitHub、Huggingface、Civitai使用方法介绍</title>
    <link href="https://www.fomal.cc/posts/319b8668.html"/>
    <id>https://www.fomal.cc/posts/319b8668.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.284Z</updated>
    
    <content type="html"><![CDATA[<p><strong>前言：</strong></p><p>ComfyUI入门之后将接触各种各样的网站，现在AI作为新兴行业，众多资本介入，网络上的模型分享以及工作流下载网站类型繁多，但一手资料和一手资源大都来自于科研前线，其中GitHub作为各种领域论文相关源码发布的头部平台，近乎99%的开源代码均发布在该网站，Huggingface作为深度学习领域头部网站，依靠Transformers开启王朝，现如今约99%的深度学习模型依托该网站进行托管，而OpenArt作为国外工作流共享平台已经发展很久，经过几次工作流大赛的积累，已经拥有近万开放工作流，Civitai为stablediffusion大模型发布的前沿平台，众多“炼丹师”（非官方的个人创作者）会将自己训练的优秀模型发布到该平台。</p><p>学习ComfyUI，熟练掌握这四个平台就已经足够了，后续可能有更多细分领域的平台出现，到时候会继续补充学习。</p><p><strong>主题内容</strong></p><p><strong>Civitai网站的使用教程：</strong><a href="https://civitai.com/"><strong>https://civitai.com/</strong></a></p><p>一、网站主页模块</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000435.png" alt="image"></p><p>常用到搜索框进行检索，比如常用到的dreamshaper8等各类大模型，可在此处搜索名称进行查找。</p><p>导航栏可以通过点击对应的模块进行条件筛选。</p><p>图像预览可点击该图像查看图像相关的原始信息，比如正反向提示词，使用到的大模型等。</p><p>二、点击Models选项可看到如下</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000436.png" alt="image"></p><p>在在图像预览中可以看到对应模型的类型以及作者名称和模型名称(<a href="https://www.bilibili.com/video/BV1e1421k7Gy/?spm_id_from=333.999.0.0&amp;vd_source=fc308fafd0eb9d759dccb9a42d40ae6c">模型类型可看该视频</a>)</p><p>在右上角筛选选项卡可以指定种类的模型进行筛选。</p><p>三、点击图像进入模型预览界面</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000437.png" alt="image"></p><p>在该页面，重点关注模型的类型，以及模型的简介区域，简介区域常包含模型出图最优的参数设置。</p><p>四、点进去预览图像看到的内容</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000438.png" alt="image"></p><p>在该页面可以看到作者封面图使用到的原始数据（假如作者上传的话），改页面重点关注ksampler参数以及用到的正反向提示词，可以给我们后续使用该模型提供参考。</p><p><strong>GitHub网站使用教程：</strong><a href="https://github.com/"><strong>https://github.com/</strong></a></p><p>一、github网站主页<img src="https://xiao666.sbs/PicGo/IMG_000000439.png" alt="image"></p><p>重点关注搜索栏，在这里可以搜索很多想要的插件</p><p>二、搜索项目之后</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000440.png" alt="image"></p><p>在中间可以找到很多相关项目，根据项目名称可以选择合适自己的项目进行观看预览，在左侧可以通过条件进行不同的筛选，比如搜索作者等。</p><p>三、进入项目页面</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000441.png" alt="image"></p><p>该页面包含特别多重要信息，特别是项目简介页面一定要认真看，项目简介中会包含常用的模型下载地址，模型链接，有些还会写上安装方式。</p><p>四、在ComfyUI的mananger管理器中可以直接跳转上述页面。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000442.png" alt="image"></p><p><strong>Huggingface使用教程：</strong><a href="https://huggingface.co/"><strong>https://huggingface.co/</strong></a></p><p>一、主页预览</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000443.png" alt="image"></p><p>该页面只关注搜索栏即可，一般进入huggingface是通过其他地方跳转。</p><p>二、在搜索框输入东西后显示的内容<img src="https://xiao666.sbs/PicGo/IMG_000000444.png" alt="image"></p><p>这里搜索完我建议搭建选择预览搜索到的所有内容，而不是跳转到项目内，这样就会缺少很多的选择。</p><p>三、预览所有搜索的内容<img src="https://xiao666.sbs/PicGo/IMG_000000445.png" alt="image"></p><p>在这里重点关注与搜索内容相关的项目，该区域可以选择你自己确定好的要下载的模型。</p><p>四、进入一个项目之后</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000446.png" alt="image"></p><p>在这个页面重点关注简介以及文件选项卡，因为后续下载模型需要通过文件选项卡跳转，部分项目带有云端运行操作，可以直接测试模型的效果。</p><p>五、点击文件之后跳转的内容</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000447.png" alt="image"></p><p>在该区域可以看到下面的文件，可以<a href="https://www.bilibili.com/video/BV1e1421k7Gy/?spm_id_from=333.999.0.0&amp;vd_source=fc308fafd0eb9d759dccb9a42d40ae6c">参考该视频</a>。点击文件后的↓按钮，可以下载选中的文件。</p><p><strong>OpenArt网站使用：</strong><a href="https://openart.ai/workflows/all"><strong>https://openart.ai/workflows/all</strong></a></p><p>一、网站主页<img src="https://xiao666.sbs/PicGo/IMG_000000448.png" alt="image"></p><p>该页面重点关注选项卡区域，在该区域可通过选择ALL查看所有的公开工作流。</p><p>二、工作流宏观预览界面<img src="https://xiao666.sbs/PicGo/IMG_000000449.png" alt="image"></p><p>在该页面重点关注工作流区域，可以查看当前的所有工作流，并可以通过筛选选项来选择最新或者下载最多的工作流。</p><p>三、工作流预览选项卡介绍<img src="https://xiao666.sbs/PicGo/IMG_000000450.png" alt="image"></p><p>该页面为第二个页面向下滑动看到的内容，可以预览工作流的出图效果以及工作流包含的节点数量等。</p><p>四、工作流预览界面</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000451.png" alt="image"></p><p>该界面重点关注工作流发布者对工作流的简介，以及工作流使用到的插件以及如何下载工作流。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ComfyUI入门之后将接触各种各样的网站，现在AI作为新兴行业，众多资本介入，网络上的模型分享以及工作流下载网站类型繁多，但一手资料和一手资源大都来自于科研前线，其中GitHub作为各种领域论文相关源码发布的头部平台</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
  <entry>
    <title>[高清放大方法汇总]收集目前高清放大工作流进行测试和分享（一）</title>
    <link href="https://www.fomal.cc/posts/13de3033.html"/>
    <id>https://www.fomal.cc/posts/13de3033.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.285Z</updated>
    
    <content type="html"><![CDATA[<p><strong>前言：</strong></p><p><strong>因为</strong><a href="https://www.bilibili.com/video/BV1KBUkYZENp/?spm_id_from=333.1387.homepage.video_card.click&amp;vd_source=fc308fafd0eb9d759dccb9a42d40ae6c"><strong>大模型本身性能的限制</strong></a><strong>，所以在ComfyUI中初步图像生成只能以较低分辨率(512*512或1024*1024)进行生图，但又因为使用场景的不同，需要图像进行放大或者修复或者高清处理，那么我们就必须掌握图像的放大方法，而放大模型众多，放大插件众多，再加上不同的风格所面临的放大场景不同，就给我们的选择带来了诸多困扰，本文将测试目前的多种放大方法，尽可能从原理进行分析给各位提供参考，希望大家批判性的吸收本文的内容，不要将此篇文章“奉为圭臬”。</strong></p><h2 id="第一种：潜空间放大"><strong>第一种：潜空间放大</strong></h2><p>该方法为ComfyUI自带基础放大方法，原理为初步生图后在潜空间进行图片放大，<strong>由于潜空间放大的图像会导致解码后图像毁坏（下图）。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000452.png" alt="image"></p><p>所以需要__较低重绘幅度__进行二次重绘，可以看到下方二次采样的重绘幅度给到了0.5左右，在保持跟原图高度相似的同时能够将图像的进行2倍的放大。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000453.png" alt="image"></p><p><strong>但是该方法有以下缺点，第一：放大需要进行重绘，所以会较大的改变原图的内容，如果去噪幅度低可能会导致放大后的潜空间噪点不能够清除干净，第二：二次采样以放大后的潜空间为主体，所以对电脑性能要求很高，过高的分辨率会直接导致程序崩溃。</strong></p><h2 id="第二种：up-scale模型放大"><strong>第二种：up_scale模型放大</strong></h2><p><strong>这种放大方法为简单的数学计算，即</strong><a href="https://openmodeldb.info/"><strong>下载相关的放大模型</strong></a><strong>，”模型本身是记录了各种数值的函数“，通过像素点之间的数据计算，输出放大后的图像。如下图所示，加载选择的放大模型，上传需要放大的图像，即可进行图像放大，优点在于该方法几乎不会对原图产生过大的改变，缺点是不能修复图像或者明显消除模糊。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000454.png" alt="image"></p><p><strong>该方法的核心为放大模型的选择，在</strong><a href="https://openmodeldb.info/models/2x-AnimeSharpV2-MoSR-Sharp"><strong>该网站</strong></a><strong>有众多的放大模型，比如动漫图像的放大模型，真实世界的放大模型等等，所以下载的时候需要按自己的需求进行选择，不然可能会非常影响最后的放大效果，并且放大模型有本身的倍率选择，比如2x-AnimeSharp模型，名字中带有2x，则是对输入图像进行两倍的放大。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000455.png" alt="image"></p><h2 id="第三种：upscale的Controlnet模型进行放大。"><strong>第三种：upscale的Controlnet模型进行放大。</strong></h2><p><strong>该方法为使用UPscale的controlnet模型进行图像的放大，因为要跟大模型进行配合，所以说大模型的选择将会严重影响放大效果，目前Flux模型为Stablediffusion领域美学特征最为优秀的开源模型，所以我就以Flux的Upsclae Controlnet模型进行示例工作流的搭建。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000456.png" alt="image"></p><p><strong>该方法依然需要二次扩散，但是可以以1的去噪强度进行重新的图像生成，因为Controlnet的参与，所以可以几乎不产生变化的方式进行图像的生成，缺点跟第一种方法一样，需要单次对全图进行扩散出图，假如放大倍数过大将会导致内存不足程序崩溃，但是该方法对原图整体的一致性保持很好，比如</strong><a href="https://t.zsxq.com/yke1R"><strong>该篇文章中</strong></a><strong>进行任务一致性控制用的就是controlnet进行修复放大。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000457.png" alt="image"></p><p><strong>根据CN节点的参数不同，则放大效果会有较大的区别，因为CN模型在该工作流中的作用是为了保持出图跟上传的预处理图一致，所以当降低强度和降低作用时间时会较强烈的影响最终效果，该方法在”保持一致性“的场景中非常推荐使用，但是如果是做超高分辨率的图像生成，完全不推荐该方法。</strong></p><p>__<br>因为该方法可以传入预处理图进行图像的控制，可以对于需要修复的图像有模糊和线条的情况可以通过预处理进行模糊处理消除线条，随后使用CN进行控制，既能保持原图的色彩分布和建筑信息，又可以通过扩散增加原图当中的细节，所以可以使用该方法进行图像的修复。__</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000458.png" alt="image"></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000459.png" alt="image"></p><h2 id="第四种：StableSR图像放大"><strong>第四种：StableSR图像放大</strong></h2><p><strong>该方法的插件地址：</strong><a href="https://github.com/WSJUSA/Comfyui-StableSR"><strong>https://github.com/WSJUSA/Comfyui-StableSR</strong></a><strong>，此方法需要选择插件对应的StableSR模型，并且尽量使用配套的大模型进行出图效果会较好，模型可以在星球的共享文件中小黄瓜自用models文件夹下载，该方法因为需要使用到扩散节点，而且跟原图的一致性保持需要使用加载的中间模型进行控制，所以出图跟原图会有差别，下图中为示例工作流。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000460.png" alt="image"></p><p><strong>如下图所示，最终结果会有纹理的丢失，企鹅胸部就出现了涂抹感，所以该方法可以较好地修复原图中的模糊效果，并且可以消除一定的噪点，可以当做后续放大(比如supir)的初步操作使用，该方法个人认为还是有必要掌握的，因为使用到的模型对显存占用较少，可以以较快的速度完成初步的图像处理，那么对后续的图像放大会带来较好的效果。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000461.png" alt="image"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;因为&lt;/strong&gt;&lt;a href=&quot;https://www.bilibili.com/video/BV1KBUkYZENp/?spm_id_from=333.1387.homepage.video_</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
  <entry>
    <title>[高清放大方法汇总]收集目前高清放大工作流进行测试和分享（三）</title>
    <link href="https://www.fomal.cc/posts/6ed67fb9.html"/>
    <id>https://www.fomal.cc/posts/6ed67fb9.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.287Z</updated>
    
    <content type="html"><![CDATA[<p><strong>前言：</strong></p><p><strong>因为</strong><a href="https://www.bilibili.com/video/BV1KBUkYZENp/?spm_id_from=333.1387.homepage.video_card.click&amp;vd_source=fc308fafd0eb9d759dccb9a42d40ae6c"><strong>大模型本身性能的限制</strong></a><strong>，所以在ComfyUI中初步图像生成只能以较低分辨率(512*512或1024*1024)进行生图，但又因为使用场景的不同，需要图像进行放大或者修复或者高清处理，那么我们就必须掌握图像的放大方法，而放大模型众多，放大插件众多，再加上不同的风格所面临的放大场景不同，就给我们的选择带来了诸多困扰，本文将测试目前的多种放大方法，尽可能从原理进行分析给各位提供参考，希望大家批判性的吸收本文的内容，不要将此篇文章“奉为圭臬”。</strong></p><h2 id="第七种：Ultimate-SD-Upscale"><strong>第七种：Ultimate SD Upscale</strong></h2><p><strong>该方法为使用</strong><a href="https://github.com/ssitu/ComfyUI_UltimateSDUpscale"><strong>Ultimate SD Uplscale</strong></a><strong>插件进行图像的高清放大，该插件的使用需要跟大模型配合，并且需要使用到放大模型，而且对接缝处有相应的操作，参数也较多，所以使用的过程存在很多的疑难点以及参考方案，本文将会尽可能地将这些细节给进行描述，并提供相应的示例工作流放在网盘当中，可查看</strong><a href="https://articles.zsxq.com/id_wr4pca2nf7wv.html"><strong>该文章</strong></a><strong>获取。</strong></p><p><strong>下图为SD放大的基础示例工作流，需要配合大模型完成重绘操作，所以说在大模型的选择上就存在多种方案，比如可以使用SDXL,FLUX架构的大模型，或者使用真实系模型，或者动漫系列模型，那么不同的模型对最后的放大效果会产生较为严重的影响，特别是细节的丰富程度会存在较大差别。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000462.png" alt="image"></p><p><strong>下图为FLUX模型和SDXL模型的对比放大工作流,从放大结果来看效果差不多，但是因为重绘幅度较低所以给模型发挥本身性能的空间不大，假如重绘幅度提升，那么FLUX模型是要优于SDXL模型的，而且我们的问题提示也较为重要，本示例中给出的文本较为简单，大家可以自行测试效果。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000463.png" alt="image"><img src="https://xiao666.sbs/PicGo/IMG_000000464.png" alt="image"></p><p><strong>下图为真实系的大模型和动漫大模型之间的放大对比，底模的性能对最终图片的影响较为强烈，因为Pony模型独特的数据集设置，所以说需要假如额外的质量提示词进行性能的调用，还有就是-2的clip set layer去设置最优的conditioning，最终出图如下所示，Pony模型会给原图加上很多的阴影去突出毛发的细节，这是真实人物对比动漫所多的内容，所以说，在使用SDupscale进行图像放大时，迎合场景的大模型选择会提升最终的图片放大质量。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000465.png" alt="image"><img src="https://xiao666.sbs/PicGo/IMG_000000466.png" alt="image"></p><p><strong>SDupscale在放大之前需要对原图先进性指定倍数的放大，在Ultimate SD Upscale节点当中的upscale_by参数体现，而这个时候使用到的是预先选择的放大模型，所以在预处理的过程中，放大模型的选择会影响最终的出图，一定要选择合适的放大模型，具体可看</strong><a href="https://articles.zsxq.com/id_05kj2ruwb1i2.html"><strong>该篇文章</strong></a><strong>。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000467.png" alt="image"></p><p><strong>SDupscale为了能让我们在较低的显存上进行图像的放大，就进行了分块处理的方式，也就是说2048*2048的图像，如果设置块大小为512*512，那么我们要进行16次的重绘，才能完成最终图像的一个生成，那么这个时候每一块的扩散过程就需要用到“提示词，去噪强度”等参数，所以我们的提示词的书写就尤为重要，因为SDupscale并没有办法对单独的某一块输出对应的提示词，所以就需要使用统一提示词，所以我们的正反向提示词，就尽量&quot;模糊，全局&quot;进行书写，比如8k,hdr,这些质量提示词，不管作用到原图当中的哪一块都可以较好的适配。下图所示的参数就决定了，块的大小。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000468.png" alt="image"></p><p><strong>又因为分块的存在，所以相邻块之间的接缝会进行二次的重绘，会导致原图出现明显的放大断层，如下图所示，避免该情况有几种方式，第一种就是较低的重绘幅度进行放大，这样对原图的改变较低，第二种就是SDupscale提供的可以将块进行扩展，从而避免同一个接缝面临两次的重复去噪，第三种就是重绘完成后在对接缝进行单独重绘。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000469.png" alt="image"></p><p><strong>下图为三种消除接缝的效果对比，从最终效果来看，32的边缘扩展非常有效的解决了接缝的问题，而接缝的二次重绘反而是的最终的效果变得更差。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000470.png" alt="image"></p><p><strong>下图为宏观对比工作流展示。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000471.png" alt="image"><img src="https://xiao666.sbs/PicGo/IMG_000000472.png" alt="image"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;因为&lt;/strong&gt;&lt;a href=&quot;https://www.bilibili.com/video/BV1KBUkYZENp/?spm_id_from=333.1387.homepage.video_</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
  <entry>
    <title>[高清放大方法汇总]收集目前高清放大工作流进行测试和分享（二）</title>
    <link href="https://www.fomal.cc/posts/23c8dceb.html"/>
    <id>https://www.fomal.cc/posts/23c8dceb.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.287Z</updated>
    
    <content type="html"><![CDATA[<p><strong>前言：</strong></p><p><strong>因为</strong><a href="https://www.bilibili.com/video/BV1KBUkYZENp/?spm_id_from=333.1387.homepage.video_card.click&amp;vd_source=fc308fafd0eb9d759dccb9a42d40ae6c"><strong>大模型本身性能的限制</strong></a><strong>，所以在ComfyUI中初步图像生成只能以较低分辨率(512*512或1024*1024)进行生图，但又因为使用场景的不同，需要图像进行放大或者修复或者高清处理，那么我们就必须掌握图像的放大方法，而放大模型众多，放大插件众多，再加上不同的风格所面临的放大场景不同，就给我们的选择带来了诸多困扰，本文将测试目前的多种放大方法，尽可能从原理进行分析给各位提供参考，希望大家批判性的吸收本文的内容，不要将此篇文章“奉为圭臬”。</strong></p><h2 id="第五种：CCSR高清放大"><strong>第五种：CCSR高清放大</strong></h2><p><strong>该方法为使用</strong><a href="https://github.com/kijai/ComfyUI-CCSR"><strong>ComfyUI-CCSR插件</strong></a><strong>进行图像放大，</strong><a href="https://github.com/csslc/CCSR"><strong>原始论文</strong></a><strong>表述该方法可以对图像进行高分辨率修复并且提升画面的视觉质量，下图为CCSR示例工作流。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000473.png" alt="image"></p><p><strong>首先该方法用到了</strong><a href="https://huggingface.co/Kijai/ccsr-safetensors/tree/main"><strong>自身训练的CCSR大模型</strong></a><strong>(其本质仍然是Stable diffusion模型)，我们可以通过文生图工作流加载该模型进行出图测试。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000474.png" alt="image"></p><p><strong>但是该插件中CCSR_Upscale节点传入的模型，必须为该插件对应的CCSR大模型，该方法对模型架构进行调整，如果使用普通的SD1.5或者SDXL模型，会导致出图过程中参数尺寸不匹配，导致出现报错的问题，该模块的核心内容为CCSR_Upscale节点，在该节点中会完成分块扩散，完成图像的放大和修复，在sampling method参数中，可以选择CCSR或者CCSR_TILE方法，tile即可对图像进行分块的放大，能够在低显存中完成图像的高清放大，但是有可能会产生“接缝”的情况.</strong><img src="https://xiao666.sbs/PicGo/IMG_000000475.png" alt="image"></p><p><strong>从下图可以看到放大的效果对比，从结果可以看到修复可以明显的降低原图中的噪点内容，将整体毛发变得平滑，即会消除原图中的彩色斑点，但是缺点也很明显，消除彩色噪点的同时将整体变得过渡平滑失去了真实场景中的纹理细节，所以放大效果类似于StableSR。(也许调整参数可以增强放大效果，具体就看各位自行测试了)</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000476.png" alt="image"></p><p><strong>在后续的模块中，为了弥补第一步带来的纹理缺失，增加了噪声的注入方式，在上面模块通过SDXL模型配合recolor的controlnet模型进行初步放大带来的色差，同时在下方对放大后的图像进行噪声的添加，使得在扩散出图的同时不仅完成色彩修复还同时增加部分细节。(但是我个人还是喜欢在这个步骤中使用SUPIR的放大去增加原图消失掉的纹理)。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000477.png" alt="image"></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000478.png" alt="image"></p><p><strong>从结果来看，注入噪声0.01的强度可以适当的增加阴影，是的图像纹理更加清晰，但是对比于后续讲的(Supir)还是差点意思的，所以在官方示例流中的后续修复过程大家可以批判性的吸收，学习一下噪声注入的思路。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000479.png" alt="image"></p><p><strong>CCSR放大方法的优点在于可以消除原图中的彩色噪声并且将高频细节进行抹平，增加画面的平滑度，消除镜头的模糊感觉，与StableSR的放大效果较为类似，所以推荐作为SUPIR纹理添加前的图像预处理。</strong></p><h2 id="第六种：SUPIR高清放大"><strong>第六种：SUPIR高清放大</strong></h2><p><strong>该方法为使用</strong><a href="https://github.com/kijai/ComfyUI-SUPIR"><strong>SUPIR放大插件</strong></a><strong>调用supir相关的放大模型进行图像的高分辨率修复，该插件目前只能配合SDXL的大模型进行使用，所以底模的选择可能会较为严重的影响最终图像的放大效果，下图为示例放大工作流。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000480.png" alt="image"></p><p><strong>该工作流通过分析可以了解到SUPIR方法的大概使用方式以及注意是在，该工作流进行了两步的处理，第一步是先对输出的图像进行放大然后进行初步的去噪，在下图中可以看到初步去噪节点完成了原始图像中的噪点去除，所以SUPIR的修复很容易受到原图中噪点强度的影响。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000481.png" alt="image"></p><p><strong>下图为初步去噪的简单对比，所以说SUPIR会更加倾向于在干净的图像上进行纹理的添加，这个在工作流中第二步就能看到效果表现，那么关于原图的去噪，我们就可以使用到之前讲到两种方法（CCSR或者StableSR），这样的配合就能够完成原图去噪后的放大，并且可以完成纹理的添加，所以说SUPIR更加适合真实人物的修复。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000482.png" alt="image"></p><p><strong>下图为示例工作流中的第二部分，进行图像修复和纹理的添加，为了弥补硬件设备带来的显存不足或者内存不足的问题，SUPIR就进行了图像的分块处理，在采样节点中可以通过设置tile的参数去完成图像分块采样的方式，但是在该方法中不能够对每一块使用单独的提示词，所以说放大之前，写入的文本信息，个人建议使用全局可用的质量提示词，而不是整张图象的内容。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000483.png" alt="image"></p><p><strong>下图为经过SUPIR放大后的效果，能够将去噪后的图像进一步添加纹理，并且对原图的改变很小，所以该方法可以较好完成图像分辨率的调整，并保持与原图的一致性。但是这种方法因为要进行大模型的选择，所以说我们找到合适的大模型至关重要，下面我们可以测试一下使用真实的大模型进行图像的放大和其他场景的大模型进行一个对比。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000484.png" alt="image"></p><p><strong>下图为搭建的两个不同风格的大模型进行的测试对比，使用相同的提示词和相同的图像，相同的随机数种子进行出图测试，上面为动漫大模型，下面为真实的大模型，可以通过对比看看大模型对于最终出图的影响。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000485.png" alt="image"></p><p><strong>下图为最终的结果对比，可以看出真实的大模型对比纹理的表达比动漫大模型的表达更为贴切，但是可能是由于真实的大模型并没有使用加速方法进行模型训练，所以在同样的采样步数下表现出的效果不如有加速放大的动漫大模型来的清晰合理。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000486.png" alt="image"></p><p><strong>下图为Pony真实系大模型和动漫大模型的放大效果对比，因为pony模型用了加速的方法，再加上该模型通过大量高质量的图像对模型进行了微调，所以对于皮肤纹理的添加就显得尤为明显，从下图中可以明显地看出不同的大模型队最终结果的影响巨大，当我们了解了插件的使用方式以及注意事项，保证个人基础知识牢固的情况下，那么就可以通过实践去完成自己的想法，所以说基础很重要！！</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000487.png" alt="image"></p><p><strong>当你掌握了SUPIR的放大方法，并且设置好了参数之后，可以使用该工作流进行批量图像的放大，即从一个目录中选择你要放大的图片数量，将每一个图片进行提示词的反推然后使用SUPIR进行图像的放大修复，因为大模型为SDXL的基础模型，所以我们的提示词反推就可以使用WD14进行，这样获得的就是短词的文本，我个人还是建议直接自己书写我们的质量提示词进行控制，因为我们是分块进行的修复。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000488.png" alt="image"></p><p><strong>下图为使用StableSR去噪后进行修复的工作流和直接使用SUPIR自带降噪进行修复的工作流对比，不同的与处理方式会严重影响最终的出图效果，所以说对于预处理的选择一定要多测试多实验。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000489.png" alt="image"></p><p><strong>下图为两种去噪方式的对比，从下图中可以看出StableSR可以通过我们的正反向提示词去大幅度的对原图当中的噪声进行消除，并且可以保持原图当中画面的一致性，反而是SUPIR自带的去噪方式因为暴露的参数过少，导致可以调整的范围缩小，从以下结果对比可以看出StableSR的去噪会更加强烈。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000490.png" alt="image"></p><p><strong>下图为放大后的结果对比，从结果来看由于StableSR的去噪较为强烈，所以后续SUPIR进行纹理添加就有更大的发挥空间，而SUPIR的去噪效果不够导致原图残留很多的色块，所以后续的放大过程可能更倾向于消除噪声(个人推测)，所以说最终的结果表现为经过StableSR去噪后的图像纹理添加的非常明显。具体的效果还是需要各位自行进行测试。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000491.png" alt="image"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;因为&lt;/strong&gt;&lt;a href=&quot;https://www.bilibili.com/video/BV1KBUkYZENp/?spm_id_from=333.1387.homepage.video_</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
  <entry>
    <title>《零基础课程第九期》：插件安装方法以及重要文件讲解</title>
    <link href="https://www.fomal.cc/posts/102b.html"/>
    <id>https://www.fomal.cc/posts/102b.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.288Z</updated>
    
    <content type="html"><![CDATA[<p><strong>前言：</strong></p><p>在ComfyUI中有成百上千的插件，<strong>分别给出不同的控制方法，功能模块以及功能扩展</strong>，比如常用到换脸插件InstantID，常用到的风格迁移IPadapter插件等，而这些插件的安装有时会带来很大的麻烦，特别是涉及深度环境安装的过程，这里将用通俗易懂的方式，细致入微的描述来进行插件安装的教学。</p><p><strong>插件发布的源码网址</strong>：<a href="https://github.com/">https://github.com/</a> <strong>网站使用教程</strong>：<a href="https://t.zsxq.com/0jOwt">https://t.zsxq.com/0jOwt</a></p><p><strong>文章中用到的manager管理器插件</strong>：<a href="https://github.com/ltdrdata/ComfyUI-Manager">https://github.com/ltdrdata/ComfyUI-Manager</a></p><p><strong>manager插件使用教程</strong>：<a href="https://www.bilibili.com/video/BV1xx4y1t7qW/?spm_id_from=333.999.0.0&amp;vd_source=fc308fafd0eb9d759dccb9a42d40ae6c">UP主主页视频</a></p><h3 id="插件安装的两种方式"><strong>插件安装的两种方式</strong></h3><p><strong>一、从github下载插件源码安装（以</strong><a href="https://t.zsxq.com/19HTumxkP"><strong>IPadapter</strong></a><strong>为例）</strong></p><p><strong>抵达ipadapter的</strong><a href="https://github.com/cubiq/ComfyUI_IPAdapter_plus"><strong>官方插件地址</strong></a><strong>。（在github进行搜索）</strong></p><p><strong>插件项目地址页面均为此排版方式，我们点击code进行后续操作</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000492.png" alt="image"></p><p><strong>这里有两种插件下载方式，第一种是给出链接我们可以通过git clone进行插件的安装（需要使用到git工具，可查看</strong><a href="https://www.bilibili.com/video/BV1pD421H7Hc/?spm_id_from=333.999.0.0&amp;vd_source=fc308fafd0eb9d759dccb9a42d40ae6c"><strong>该视频</strong></a><strong>），第二种是直接下载zip压缩包。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000493.png" alt="image"></p><p><strong>使用git工具进行安装时，先复制上图中给出的连接，在插件目录打开CMD，然后输入git clone xxx，按回车即可进行安装。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000494.png" alt="image"></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000495.png" alt="image"></p><p><strong>如果是下载zip压缩包进行安装的，首先在插件页面的位置下载压缩包，下载后解压文件。该方式下载的插件后缀会多出一个-main的名称，建议把这个符号删掉，某些插件会影响使用。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000496.png" alt="image"></p><p><strong>然后将这个文件夹复制到ComfyUI对应的插件目录即可。</strong></p><p><strong>！！！请注意，当您使用压缩包的方式进行安装，会缺少git元数据，具体就是在插件文件夹中缺少.git文件，所以会导致后续插件不能自动通过manager管理器更新。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000497.png" alt="image"><img src="https://xiao666.sbs/PicGo/IMG_000000498.png" alt="image"></p><p><strong>二、通过manager管理器进行插件安装。（建议使用</strong><a href="https://www.bilibili.com/video/BV1pD421H7Hc/?spm_id_from=333.999.0.0&amp;vd_source=fc308fafd0eb9d759dccb9a42d40ae6c"><strong>便携包</strong></a><strong>）</strong></p><p><strong>在你已经安装manager管理器的情况下，打开ComfyUI进入manager管理器插件安装界面。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000499.png" alt="image"></p><p><strong>在弹出的页面搜索你想要安装的插件，勾选后点击install即可进行安装。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000500.png" alt="image"></p><p><strong>从下图可以在cmd命令行看出，在manager管理器安装插件本质上就是替我们做了检索，git clone的命令。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000501.png" alt="image"></p><h3 id="插件文件结构讲解。"><strong>插件文件结构讲解。</strong></h3><p><strong>不同的插件结构不完全相同，有些插件不需要额外的依赖项，那么就可能不包含requirement文件，有些插件可能包含未编译好的python环境wheel文件，所以需要setup安装额外的包，环境问题很难通过一个视频全部涵盖所有问题，所以就必须学习基础的知识，还有就是不断的实验。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000502.png" alt="image"></p><p><strong>插件源码中涵盖了该插件有关的所有节点信息，以及这个节点的作用，想要深入了解节点做的事情，可能需要有一定的python编程基础。</strong></p><p><strong>插件相关信息可以看到插件地址，作者，插件版本等内容。</strong></p><p><strong>插件简介主要是在github中浏览。</strong></p><p><strong>！！！需要的环境依赖，该部分为重点信息，插件安装能否成功主要就是看相关的python环境是否健全。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000503.png" alt="image"></p><p><strong>当我们打开一个requirement文件夹，可以看到里面包含的这个插件运行所必需的环境依赖都有哪些，其中重点关注比如torch，xformers，torchversion这些，因为torch包和我们环境中的cuda有对应版本关系，如果该插件安装了其他的torch版面，会导致环境出现不匹配，导致ComfyUI不能够启动。</strong></p><p><strong>当我们删除其中我们排除掉的环境依赖之后，复制requirement文件，放到包中的python中，</strong><img src="https://xiao666.sbs/PicGo/IMG_000000504.png" alt="image"></p><p><strong>在这个目录下面打开CMD控制命令行，安装requirement文件夹中的环境依赖。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000505.png" alt="image"></p><p><strong>python -m pip 表示使用当前的python环境中的pip模块，执行install命令去-r(read)读取requirement文件，去安装文件中的环境依赖。</strong></p><p><strong>加入这个过程没有出现错误，那么插件就已经完全安装成功了，通过启动ComfyUI就能够使用该插件中的节点。</strong></p><p><strong>还有极个别的情况存在安装失败，比如缺少编译器，常见的问题就是build wheel失败，可以尝试通过安装visaul studio来弥补底层环境问题，在进行pip install尝试安装。</strong></p><p><strong>总之，经过上述步骤，你可以完成90%左右插件的安装，环境内容多且复杂，具体问题需要找到具体的报错才能够针对性解决，当你接触的内容越接近底层，你会发现越难通过一个视频完整学完所有错误。</strong></p><p><strong>希望大家继续积累！问题总能解决的！</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在ComfyUI中有成百上千的插件，&lt;strong&gt;分别给出不同的控制方法，功能模块以及功能扩展&lt;/strong&gt;，比如常用到换脸插件InstantID，常用到的风格迁移IPadapter插件等，而这些插件的安装有时会</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
  <entry>
    <title>【ComfyUI插件】 ComfyUI-Advanced-ControlNet核心节点(一)</title>
    <link href="https://www.fomal.cc/posts/429d6e7c.html"/>
    <id>https://www.fomal.cc/posts/429d6e7c.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.297Z</updated>
    
    <content type="html"><![CDATA[<p><strong>前言：</strong></p><p>ComfyUI-Advanced-ControlNet库包含大量时间插值控制方法，及从时间维度和latent层的维度对图像的生成过程进行控制，主要概念就是__时间步长关键帧__和__潜在关键帧__两个概念。当您学会使用该库，你可以在图片或视频生成过程中加入自己的控制方法，比如在扩散的前50使用权重0.1，在扩散的后50使用0.9的权重，也可以在latent维度，对单个潜空间进行时间步长设置，<strong>本文将对节点进行逐个讲解，并且会以尽量详细的过程和配图，尽量通俗易懂的语言进行书写。</strong></p><p>__Comfy-Advanced-ControlNet（二）: __<a href="https://t.zsxq.com/wNGkq"><strong>https://articles.zsxq.com/controlNet/2.html</strong></a></p><p><strong>目录：</strong></p><p><strong>先行：安装方法</strong></p><p><strong>一、Apply Advanced ControlNet节点</strong></p><p><strong>二、Timestep Keyframe节点</strong></p><p><strong>三、Latent Keyframe节点</strong></p><p><strong>四、Latent Keyframe Group节点</strong></p><p><strong>五、Latent Keyframe Interpolation节点</strong></p><p><strong>六、ControlNet Custom Weights/ControlNet Soft Weights节点</strong></p><p><strong>七、T2IAdapter Soft Weights/T2IAdapter Custom Weights 节点</strong></p><p><strong>&quot;转绘&quot;示例工作流：</strong></p><p><strong>安装方法：</strong></p><p><strong>在ComfyUI主目录里面输入CMD回车。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000506.png" alt="image"></p><p><strong>在弹出的CMD命令行输入git clone xxx,即可开始下载。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000507.png" alt="image"></p><p><strong>github项目地址:</strong><a href="https://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet.git"><strong>https://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet.git</strong></a></p><p><strong>*****特别重要*****</strong></p><p><strong>时间步长关键帧：将时间进行分割，设置为你满意的时间尺度，比如0-1s，分割成0-0.1,0.1-0.5,0.5-1。</strong></p><p><strong>潜在关键帧： 假如我们Latent的batch设置为10，则每一个latent称为一个关键帧。</strong></p><p><strong>模型权重:指模型中的参数，用于调整模型的行为和输出。在控制网络中，权重通常用于调整模型对不同输入特征的关注程度。</strong></p><p><strong>控制强度:指定某种影响或调整的程度或强度。在控制网络中，“strength” 可能用于调整某些参数或控制某些操作的强度或影响程度。</strong></p><p><strong>注意：在计算机领域，索引或者编号，默认为从0开始。</strong></p><p><strong>一、Apply Advanced ControlNet节点</strong></p><p><strong>节点功能：该结点应用ControlNet，并且接收蒙版信息，以及时间分布信息，并且设置有相应的覆盖策略。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000508.png" alt="image"></p><p><strong>输入：</strong></p><p>positive -&gt; 正向提示词的条件信息</p><p>negative -&gt; 反向提示词的条件信息</p><p>control_net -&gt; 传入ControlNet模型，适配的模型自动转为Advanced版 **大部分都适配**</p><p>image -&gt; 出入预处理图片，比如深度图，线稿等</p><p>mask_optional -&gt; 传入蒙版信息</p><p>timestep_kf -&gt; 传入时间步长关键帧信息</p><p>latent_kf_override -&gt; 传入潜在关键帧信息</p><p>weights_override -&gt; 权重覆盖，如果这里有参数传入，则会覆盖传入的强度信息</p><p>model_optional -&gt; 传入大模型</p><p><strong>注意：如下图所示虽然在时间步长关键帧(红色节点)中我们设置了，控制权重一直为1，即代表严格按照深度图进行扩散，但是因为weights_override我们设置为0.1，所以对传入的权重进行覆盖，最终生成的图像并不符合深度图信息。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000509.png" alt="image"></p><p><strong>注意：如下图所示在下方紫色方框中设置潜空间图像的控制强度为1，则应该产生与深度图接近的图像，但是在latent_kf_override参数出，我们传入图像的控制强度为0.1，所以进行了权重覆盖，最终出图与深度图信息没有关系。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000510.png" alt="image"></p><p><strong>参数：</strong></p><p>strength -&gt; 设置模型的控制强度 **未有参数传入时，起作用**</p><p>start_percent -&gt; 设置控制信息开始百分比 **未有参数传入时，起作用**</p><p>end_percent -&gt; 设置控制信息结束百分比 **未有参数传入时，起作用**</p><p><strong>输出:</strong></p><p>positive -&gt; 混合控制信息后输出的条件信息</p><p>negative -&gt; 混合控制信息后输出的条件信息</p><p>model_opt -&gt; 混合控制信息后输出的模型信息</p><p><strong>二、Timestep Keyframe节点</strong></p><p><strong>节点功能：该结点用来汇总时间表，以及提供潜在关键帧设置策略的输入点，将这些信息汇聚为时间步长信息。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000511.png" alt="image"></p><p><strong>输入：</strong></p><p>prev_timestep_kf -&gt; 时间步长信息，通过start_percent控制 **多个该节点可以串联**</p><p>cn_weights -&gt; 权重时间表，代表ControlNet的作用权重 **如果有传入有效值，会覆盖stength的值**</p><p>latent_keyframe -&gt; 代表潜空间的某一个或某一组 **可传入单个控制信息，或整组控制信息**</p><p>mask_optional -&gt; 代表蒙版信息</p><p><strong>注意：如下图所示通过串联两个(或者多个)该节点，即完成时间表的创建，通过strat_percent参数用来控制作用域(即起作用的时间范围)。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000512.png" alt="image"></p><p><strong>参数：</strong></p><p>start_percent -&gt; 设置该时间步长关键帧起作用的开始时间。</p><p>strength -&gt; 设置在该时间步长关键帧起作用时的控制强度 **先前有传入，此值会一起计算强度**</p><p>null_latent_kf_strength -&gt; 未提供索引的潜在关键帧的控制强度</p><p>inherit_missing -&gt; 如果某时间段未设置强度，可选择是否继承该时间段的控制强度</p><p>guarantee_usage -&gt; 确保无分配时间步长就近选取控制强度</p><p><strong>注意：如下图所示，左边时间步长关键帧设置start_percent=0，strength=0.5，右边时间步长关键帧设置start_percent=0.5，strength=1，即表示在0到0.5的时间内，我们使用0.5的控制权重，在0.5到1的时间内，我们使用1的控制权重</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000513.png" alt="image"></p><p><strong>输出：</strong></p><p>TIMESTEP_KF -&gt; 输出已经设置的时间步长信息</p><p><strong>注意：start_percent的取值范围为0-1，strength的取值范围0-10，但是strength设置值过大会导致生成的图像毁坏，如下图所示：</strong><img src="https://xiao666.sbs/PicGo/IMG_000000514.png" alt="image"></p><p><strong>注意：当strngth我们设置为1的时候，控制强度就基本等于100%了，所以不需要过大的值(大家自行选择)，下面两幅图分别代表在时间0-0.8设置strngth=0.1 0.8-1设置strngth=1.0和在时间0-0.8设置strngth=1 0.8-0.1设置strngth=1.0，可以看出时间域长的占据主导图片生成的过程。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000515.png" alt="image"></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000516.png" alt="image"></p><p><strong>三、Latent Keyframe节点</strong></p><p><strong>节点功能：该节点用来指定对应的潜空间图像去使用指定的控制强度。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000517.png" alt="image"></p><p><strong>输入：</strong></p><p>prev_latent_kf -&gt; 潜在关键帧信息，通过batch_index指定 **多个该节点可以串联**</p><p><strong>参数：</strong></p><p>batch_index -&gt; 表示潜空间帧索引 **计算机领域，索引从0开始**</p><p>strength -&gt; 作用与该帧的控制强度 **如果设置索引冲突，后会和前共同计算**</p><p><strong>如图:第0个潜空间图像，设置强度为1，在0-0.8的时间步长我们设置强度为0.1，设置null_latent_kf_strength(未指定索引的潜空间图像)为10，所以在第一个时间步长关键帧中，第0个图像的控制强度为(1与0.1共同计算结果)，而第1个图像的控制强度为(10与0.1共同计算结果)，所以第0个图像稍微不受深度图约束，而第二张则与深度图更加符合。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000518.png" alt="image"></p><p>__<br>如图:在0-0.8的时间步长我们设置强度为0.1，设置null_latent_kf_strength(未指定索引的潜空间图像)为10，最终生成的两张图像与深度图均不符合，所以只有当latent_keyframe有输入的时候，null_latent_kf_strength才会起作用。__<img src="https://xiao666.sbs/PicGo/IMG_000000519.png" alt="image"></p><p><strong>输出：</strong></p><p>LATENT_KF -&gt; 输出蕴含设置信息的潜在关键帧信息</p><p><strong>注意：如下图所示，我们初始生成了两个Latent图像，在Latent Keyframe节点，我们分别对不同的步长进行不同的索引设置，索引0的潜空间图像，在0-0.8使用strength=1的控制强度，而索引1的潜空间图像，在0-0.8使用strength=0.1的控制强度，所以最终生成的两张图像，第一张符合深度图信息，但是第二张并不符合。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000520.png" alt="image"></p><p><strong>四、Latent Keyframe Group节点</strong></p><p><strong>节点功能：这个节点可以批量给潜在关键帧赋予权重，以编程语言的书写习惯给出。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000521.png" alt="image"></p><p><strong>输入：</strong></p><p>prev_latent_kf -&gt; 潜在关键帧信息 **多个该节点可以串联**</p><p>latent_optional -&gt; 此参数可以不传入 **此参数我在代码没找到应用，所以忽略**</p><p><strong>参数:</strong></p><p>文本框 -&gt; 输入格式按照 索引=权重,索引=权重来写 **注意逗号应使用英文**</p><p>print_keyframes -&gt; 是否打印输出的信息 **在命令行会打印相关信息**</p><p><strong>输出：</strong></p><p>LATENT_KF -&gt; 输出潜在关键帧信息</p><p><strong>注意：如下图所示，我们在Latent Keyframe Group节点中，我们设置第0个潜空间图像权重为0.1在一开始就参与控制扩散，在第1个潜空间图像权重设置为1.0同样在一开始就参与扩散，最终我们生成两张图像，其中第一张图像与深度图几乎无关，第二张按照深度图进行扩散生成。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000522.png" alt="image"></p><p><strong>注意：如下图所示，当我们把print_keyframes设置为true的时候，我们可以在命令行看到输出的潜在关键帧信息和其对应的强度信息。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000523.png" alt="image"></p><p><strong>五、Latent Keyframe Interpolation节点</strong></p><p><strong>节点功能：该节点用来选择潜在关键帧的顺序索引，并且赋予可选的渐变效果。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000524.png" alt="image"></p><p><strong>输入：</strong></p><p>prev_latent_kf -&gt; 潜在关键帧信息 **多个该节点可以串联**</p><p><strong>参数：</strong></p><p>batch index from -&gt; 索引的开始值 **包含在内**</p><p>batch index to excl -&gt; 索引的结束值 **不包含在内**</p><p>strength from -&gt; 控制强度的起始值</p><p>strength to -&gt; 控制强度的最终值</p><p>interpolation -&gt; 渐变效果 **提供了4中渐变效果**</p><p>print_keyframes -&gt; 是否打印输出的信息 **在命令行会打印相关信息**</p><p><strong>注意：如下图所示，给出四种渐变效果linear、ease-in、ease-out、ease-in-out，他们分别代表匀速变化，渐进，减速，渐进-减速四种状态。</strong></p><p><strong><img src="https://xiao666.sbs/PicGo/IMG_000000525.png" alt="image"></strong></p><p><strong>输出：</strong></p><p>LATENT_KF -&gt; 输出潜在关键帧信息</p><p><strong>注意：如下图所示，我们设置索引为[0,1)，那么我们就等于只选择第0个潜在关键帧，渐变方式为匀速渐变，控制强度从1降低到0，最终可以看到第一张图像按照深度图信息进行扩散，但是第二张图像并没有按照深度图进行扩散。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000526.png" alt="image"></p><p><strong>六、ControlNet Custom Weights/ControlNet Soft Weights节点</strong></p><p><strong>节点功能：这两个节点用来批量设置强度信息。</strong></p><p><strong>注意：这两个节点的区别就是Custom需要自行设置参数，Soft是默认给出了一个参数列表</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000527.png" alt="image"></p><p><strong>输入：</strong></p><p>weight_xx -&gt; 设置强度信息</p><p>flip_weights -&gt; 表示是否对权重进行翻转</p><p><strong>输出：</strong></p><p>CN_WEIGHTS -&gt; 输出设置的强度信息</p><p>TK_SHORTCUT -&gt; 输出时间步数关键帧</p><p><strong>注意：这个权重真的是很玄学的东西，这13个权重的值以我的理解来看是去代替掉网络中的部分参数，但是具体的替代方式我并没有找到，其次就是这些权重不针对专门的Latent帧去做控制，我做了很多对比实验，但是得不出合理的结果，实验我放在下面了，大家可以自行推测：</strong></p><p><strong>1):参数全为0</strong><img src="https://xiao666.sbs/PicGo/IMG_000000528.png" alt="image"></p><p><strong>2):参数全为1</strong><img src="https://xiao666.sbs/PicGo/IMG_000000529.png" alt="image"></p><p><strong>3):参数前面1，后面为0</strong><img src="https://xiao666.sbs/PicGo/IMG_000000530.png" alt="image"></p><p><strong>4):参数前面0，后面为1</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000531.png" alt="image"></p><p><strong>七、T2IAdapter Soft Weights/T2IAdapter Custom Weights 节点</strong></p><p><strong>节点功能：该节点用来设置控制强度。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000532.png" alt="image"></p><p><strong>输入：</strong></p><p>weight_xx -&gt; 代表权重信息</p><p><strong>参数：</strong></p><p>flip_weights -&gt; 是否要将强度进行反转</p><p><strong>输出：</strong></p><p>CN_WEIGHTS -&gt; 输出设置的强度信息</p><p>TK_SHORTCUT -&gt; 输出时间步数关键帧</p><p><strong>注意：当我们使用T2IAdapter节点的时候，必须使用对应的ControlNet模型，个人感觉T2I-Adapter模型的效果要比传统的ControlNet好一点，下图所示结果为赋予不同强度变化的情况下得到的图像。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000533.png" alt="image"></p><p><strong>模型下载链接：<a href="https://huggingface.co/TencentARC/T2I-Adapter/tree/main/models">https://huggingface.co/TencentARC/T2I-Adapter/tree/main/models</a></strong></p><p><strong>&quot;转绘&quot;示例工作流：</strong></p><p>学习完以上节点，您就可以搭建&quot;转绘&quot;示例工作流了<img src="https://xiao666.sbs/PicGo/IMG_000000534.png" alt="image"></p><p>这里使用SD1.5的大模型，使用ControlNet Soft Weights节点去分散赋予不同时间步长不同的控制强度，在保证大体深度信息不变的情况下，又给与模型一定的自我创造能力，最终完成对图像的转绘工作：<img src="https://xiao666.sbs/PicGo/IMG_000000535.png" alt="image"></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000536.png" alt="image"></p><p><strong>孜孜不倦,方能登峰造极。坚持不懈,乃是成功关键。</strong></p><p>__Comfy-Advanced-ControlNet（二）: __<a href="https://t.zsxq.com/wNGkq"><strong>https://articles.zsxq.com/controlNet/2.html</strong></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ComfyUI-Advanced-ControlNet库包含大量时间插值控制方法，及从时间维度和latent层的维度对图像的生成过程进行控制，主要概念就是__时间步长关键帧__和__潜在关键帧__两个概念。当您学会使用</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
  <entry>
    <title>【ComfyUI插件】 ComfyUI-Advanced-ControlNet核心节点(二)</title>
    <link href="https://www.fomal.cc/posts/edacf51e.html"/>
    <id>https://www.fomal.cc/posts/edacf51e.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.303Z</updated>
    
    <content type="html"><![CDATA[<p><strong>前言：</strong></p><p>ComfyUI-Advanced-ControlNet库包含大量时间插值控制方法，及从时间维度和latent层的维度对图像的生成过程进行控制，主要概念就是__时间步长关键帧__和__潜在关键帧__两个概念。当您学会使用该库，你可以在图片或视频生成过程中加入自己的控制方法，比如在扩散的前50使用权重0.1，在扩散的后50使用0.9的权重，也可以在latent维度，对单个潜空间进行时间步长设置，<strong>本文将对节点进行逐个讲解，并且会以尽量详细的过程和配图，尽量通俗易懂的语言进行书写。</strong></p><p>__ComfyUI-Advanced-ControlNet核心节点(一）: __<a href="https://t.zsxq.com/15a9J"><strong>https://articles.zsxq.com/controlNet/1.html</strong></a></p><p><strong>目录：</strong></p><p><strong>先行：安装方法</strong></p><p><strong>一、Force Default Weights节点</strong></p><p><strong>二、Scaled Soft Weights\Scaled Soft Masked Weights节点</strong></p><p><strong>三、SparseCtrl节点</strong></p><p><strong>四、Load Advanced ControlNet Model (diff)/Load Advanced ControlNet Model节点</strong></p><p><strong>&quot;动画&quot;示例工作流：</strong></p><p><strong>安装方法：</strong></p><p><strong>在ComfyUI主目录里面输入CMD回车。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000537.png" alt="image"></p><p><strong>在弹出的CMD命令行输入git clone xxx,即可开始下载。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000538.png" alt="image"></p><p><strong>github项目地址:</strong><a href="https://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet.git"><strong>https://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet.git</strong></a></p><p><strong>*****特别重要*****</strong></p><p><strong>时间步长关键帧：将时间进行分割，设置为你满意的时间尺度，比如0-1s，分割成0-0.1,0.1-0.5,0.5-1。</strong></p><p><strong>潜在关键帧： 假如我们Latent的batch设置为10，则每一个latent称为一个关键帧。</strong></p><p><strong>模型权重:指模型中的参数，用于调整模型的行为和输出。在控制网络中，权重通常用于调整模型对不同输入特征的关注程度。</strong></p><p><strong>控制强度:指定某种影响或调整的程度或强度。在控制网络中，“strength” 可能用于调整某些参数或控制某些操作的强度或影响程度。</strong></p><p><strong>注意：在计算机领域，索引或者编号，默认为从0开始。</strong></p><p><strong>一、Force Default Weights节点</strong></p><p><strong>节点功能：该结点将该时间步长关键帧的强度设置和时间步长设置强制为默认(CN_WEIGHTS该参数我理解并不透彻！！)。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000539.png" alt="image"></p><p><strong>输出：</strong></p><p>CN_WEIGHTS -&gt; 强制设置为默认参数 **我没有找到应用的方法**</p><p>TK_SHORTCUT -&gt; 强制时间步长关键帧为默认设置</p><p><strong>注意：如下图所示我们在0-0.5的时间步长关键帧设置控制强度为1，但是我们加入了Force Default Weights节点之后，该强制总时间域的控制强度为默认值0.1(即Apply Advanced ControlNet节点设置的值)，所以最终生成的图像并没有受到深度图的约束。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000540.png" alt="image"></p><p><strong>注意：时间步长关键帧的设置必须从0开始，Apply Advanced ControlNet设置的时间也必须从0开始，Force Default Weights是覆盖整个时间域的强度。</strong></p><p><strong>二、Scaled Soft Weights\Scaled Soft Masked Weights节点</strong></p><p><strong>节点功能：这两个节点通过给与&quot;乘子&quot;的方式进行权重调节，mask节点可以通过蒙版控制不同区域设置成为不同的控制权重。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000541.png" alt="image"></p><p><strong>输入：</strong></p><p>mask -&gt; 使用蒙版信息传递该区域的控制权重 **总体有偏，大体符合**</p><p><strong>注意：如下图所示我们设置时间步长关键帧的控制权重为1，则图像应该按照深度图的信息进行扩散，但是我们设置蒙版区域的&quot;乘子为0.1&quot;，即设置在蒙版区域的控制权重为0.1，所以最终生成的图像，非蒙版区域基本按照深度图进行扩散，但是蒙版区域并不受深度图的约束。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000542.png" alt="image"></p><p><strong>参数：</strong></p><p>base_multiplier -&gt; 基础乘子是多少 **该值与默认权重值相乘来控制权重**</p><p>flip_weights -&gt; 是否将权重进行翻转 **先前有传入，此值会一起计算强度**</p><p>min_base_multiplier -&gt; 最小乘子值</p><p>max_base_multiplier -&gt; 最大乘子值</p><p><strong>注意：如下图所示，我们可以通过使用两个时间步长关键帧，两个蒙版表示不同的区域和两个Scaled Soft Masked Weights结点来控制不同区域的不同权重，下图为让0-0.5的时间步长在右下角蒙版中权重为0.1，在0.5-1的时间步长内让窗户的权重为0.1，最终生成的图像这两处模型行为有改变。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000543.png" alt="image"></p><p><strong>重要！！！：至于为什么没蒙版区域的墙壁却不被深度图影响，这我也不了解，因为深度学习模型的可解释性一直是个未解之谜，这里调整的是权重而不是强度，权重指的是存在模型中的参数，控制模型的行为，所以相互之间可能存在作用关系。</strong></p><p><strong>输出：</strong></p><p>CN_WEIGHTS -&gt; 输出模型权重的更改信息</p><p>TK_SHORTCUT -&gt; 输出时间步长设置信息</p><p><strong>三、SparseCtrl节点</strong></p><p><strong>节点功能：这些是稀疏控制模型使用到的节点，对视频进行处理需要用到。</strong></p><p><strong>节点索引:Load Merged SparseCtrl Model/ RGB SparseCtrl/ SparseCtrl Index Method/ SparseCtrl Spread Method/ Load SparseCtrl Model</strong></p><p><strong>注意:博主电脑不太行，没有办法跑这些节点，不过可以提供节点的下载方式。等后续有钱了换个好电脑，补上这一块的缺失。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000544.png" alt="image"></p><p><strong>目前SparseCtrl提供了两个模型，分别是RGB image condition和scribble condition两个模型，地址如下：</strong></p><p><strong>AnimateDiff库：<a href="https://huggingface.co/guoyww/animatediff/tree/main">https://huggingface.co/guoyww/animatediff/tree/main</a></strong></p><p><strong>该库基本包含所有AnimateDiff用到的模型，比如运动lora模型，运动大模型等。</strong></p><p><strong>这些节点的使用需要用到AnimateDiff库，后续会合并讲解，敬请期待！！！</strong></p><p><strong>下图为参考工作流，其中紫色代表基本文生图工作流，重点在于固定随机数种子和潜空间设置为16图像，最终预览每8帧为1秒。绿色表示AnimateDiff节点，用来设置运动模型和运动lora，其中v3_sd15_adapter模型为域适配器，与普通的lora加载方式一样，主要目的是去除图片中的噪点信息。红色代表SparseCtrl模型的加载和应用，使用ControlNet预处理生成线稿，然后通过稀疏控制模型去影响生图。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000545.png" alt="image"></p><p><strong>开启v3_sd15_adapter域适配器图像:</strong><img src="https://xiao666.sbs/PicGo/IMG_000000546.png" alt="image"></p><p><strong>未开启v3_sd15_adapter域适配器:</strong><img src="https://xiao666.sbs/PicGo/IMG_000000547.png" alt="image"></p><p><strong>**这两张图一共4秒钟，用了我30多分钟**</strong></p><p><strong>四、Load Advanced ControlNet Model (diff)/Load Advanced ControlNet Model节点</strong></p><p><strong>节点功能：这两个结点用来加载ControlNet模型，并自动转换为Advanced版本。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000548.png" alt="image"></p><p><strong>输入：</strong></p><p>model -&gt; 输入允许diff版本的模型 **有些ControlNet是为接收模型而设计的**</p><p>timestep_keyframe -&gt; 时间步长关键帧参数</p><p><strong>参数:</strong></p><p>control_net_name -&gt; 加载的ControlNet模型</p><p>print_keyframes -&gt; 是否打印输出的信息 **在命令行会打印相关信息**</p><p><strong>输出：</strong></p><p>CONTROL_NET -&gt; 输出蕴含控制信息的指定的ControlNet模型</p><p><strong>******以下工作流仅为示例，不要求必须会搭建，因为还没有讲AnimateDiff节点*****</strong></p><p><strong>&quot;动画&quot;示例工作流：</strong></p><p>学习完以上节点，您就可以搭建&quot;动画&quot;示例工作流了</p><p>这里使用SD1.5的大模型，使用麦橘V7大模型去生成真实的人物，使用ControlNet模型去控制人物姿势，通过高级ControlNet节点去加载功能：<img src="https://xiao666.sbs/PicGo/IMG_000000549.png" alt="image"></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000550.png" alt="image"></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000551.png" alt="image"></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000552.png" alt="image"></p><p><strong>孜孜不倦,方能登峰造极。坚持不懈,乃是成功关键。</strong></p><p>__ComfyUI-Advanced-ControlNet核心节点(一）: __<a href="https://t.zsxq.com/15a9J"><strong>https://articles.zsxq.com/controlNet/1.html</strong></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ComfyUI-Advanced-ControlNet库包含大量时间插值控制方法，及从时间维度和latent层的维度对图像的生成过程进行控制，主要概念就是__时间步长关键帧__和__潜在关键帧__两个概念。当您学会使用</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
  <entry>
    <title>【ComfyUI插件】ComfyUI Easy Use插件（一）</title>
    <link href="https://www.fomal.cc/posts/836cbd92.html"/>
    <id>https://www.fomal.cc/posts/836cbd92.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.310Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言："><strong>前言：</strong></h2><p>EasyUse 是 ComfyUI 图像生成和处理框架中的一个模块，旨在通过简化的界面和易于配置的节点来提供用户友好的操作体验，特别适合希望快速开始图像生成、修复、增强等任务的用户。</p><p>__ComfyUI Easy Use插件（二）: __<a href="https://t.zsxq.com/lNdvT"><strong>https://articles.zsxq.com/easyuse/2.html</strong></a></p><p>__ComfyUI Easy Use插件（三）: __<a href="https://t.zsxq.com/UsFSp"><strong>https://articles.zsxq.com/easyuse/3.html</strong></a></p><p>__ComfyUI Easy Use插件（四）: __<a href="https://t.zsxq.com/gSJA1"><strong>https://articles.zsxq.com/easyuse/4.html</strong></a></p><p>__ComfyUI Easy Use插件（五）: __<a href="https://t.zsxq.com/IAye6"><strong>https://articles.zsxq.com/easyuse/5.html</strong></a></p><p>__ComfyUI Easy Use插件（六）: __<a href="https://t.zsxq.com/PhouI"><strong>https://articles.zsxq.com/easyuse/6.html</strong></a></p><p>__ComfyUI Easy Use插件（七）: __<a href="https://t.zsxq.com/jDjyM"><strong>https://articles.zsxq.com/easyuse/7.html</strong></a></p><p>__ComfyUI Easy Use插件（八）: __<a href="https://t.zsxq.com/UXZK4"><strong>https://articles.zsxq.com/easyuse/8.html</strong></a></p><p><strong>本期使用的示例工作流在网盘：小黄瓜知识星球资料分享/插件节点讲解视频/ComfyUI_EasyUse/第一期文件夹中</strong></p><h2 id="目录"><strong>目录</strong></h2><p><strong>先行：安装方法</strong></p><p><strong>一、EasyLoader (Comfy)节点</strong></p><p><strong>二、PreSampling节点</strong></p><p><strong>三、EasyKSampler节点</strong></p><p><strong>四、Pipe Out和Pipe In节点</strong></p><p><strong>五、Pipe Edit节点</strong></p><p><strong>六、EasyLoraStack节点</strong></p><p><strong>七、Wildcards节点</strong></p><p><strong>八、EasyControlnet/EasyControlnet (Advanced)节点</strong></p><p><strong>九、ImageSize/ImageSize (Side)/ImageSize (LongerSide)节点</strong></p><p><strong>十、ImagePixelPerfect节点</strong></p><p><strong>十一、HiresFix节点</strong></p><p><strong>十二、PreDetailerFix/UltralyticsDetector (Pipe)/SAMLoader (Pipe)/DetailerFix节点</strong></p><p><strong>十三、Get/Set/EasyGlobalSeed节点</strong></p><h2 id="安装方法"><strong>安装方法</strong></h2><p><strong>1、在manager管理器里面搜索Easy Use进行安装</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000710.png" alt="image"></p><p><strong>2、通过git clone进行安装，即在ComfyUI/custom_nodes目录下输入cmd按回车进入终端</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000711.png" alt="image"></p><p>__然后在终端输入git clone __<a href="https://github.com/yolain/ComfyUI-Easy-Use?tab=readme-ov-file"><strong>https://github.com/yolain/ComfyUI-Easy-Use?tab=readme-ov-file</strong></a></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000712.png" alt="image"></p><h3 id="一、EasyLoader-Comfy-节点"><strong>一、EasyLoader (Comfy)节点</strong></h3><p><strong>节点功能：该节点了简化和加速加载模型或资源的过程。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000713.png" alt="image"></p><p><strong>可选输入：</strong></p><p>optional_lora_stack: 用于将多个 Lora 模型叠加在一起使用</p><p>optional_controlnet_stack: 在图像生成中使用多个 ControlNet 模型</p><p><strong>参数：</strong></p><p>ckpt_name: 选择需要加载的checkpoint大模型</p><p>vae_name: 选择要加载的 VAE（变分自编码器）模型</p><p>clip_skip: 默认值为 -2，表示跳过特定的 clip 层级</p><p>lora_name: 选择是否使用 Lora 模型</p><p>lora_model_strength: Lora 模型的强度，控制 Lora 模型的影响力</p><p>resolution: 输出图像的分辨率选择</p><p>positive 和 negative：分别表示正面和负面提示（prompts），用于图像生成模型的指导。支持多行输入。</p><p><strong>输出：</strong></p><p>pipe: 返回管道（pipe）,所有的流程汇聚成一个管道</p><p>model: 返回加载的模型对象</p><p>vae: 返回加载的 VAE 模型对象</p><h3 id="二、PreSampling节点"><strong>二、PreSampling节点</strong></h3><p><strong>节点功能：该节点是一个用于图像生成过程中采样设置的节点，主要功能是为图像生成过程配置预采样的相关参数，包括步数、采样器类型、调度器、CFG 值等。它可以将采样的设置与图像生成管道（pipeline）结合，为用户提供更精细的图像生成控制。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000714.png" alt="image"></p><p><strong>必需输入 (required)：</strong></p><p>pipe: 一个图像生成管道，包含模型、VAE、CLIP、以及图像数据等</p><p><strong>可选输入 (optional):</strong></p><p>image_to_latent: 输入图像，可以用于将图像转化为潜在空间表示。</p><p>latent: 输入的潜在图像数据，直接使用已经存在的潜在图像作为输入。</p><p><strong>参数：</strong></p><p>steps: 采样的步数，决定图像生成过程中采样的细致程度。</p><p>cfg: 影响生成图像的质量和准确度</p><p>sampler_name: 采样器类型，选择图像生成时使用的采样器（如 Euler, DDIM 等）</p><p>scheduler: 采样器的调度器类型，控制图像生成过程中采样步长的变化。</p><p>denoise: 去噪值，用于控制图像生成过程中的噪声去除程度。</p><p>seed: 随机种子，控制随机性的生成。</p><p>contorl_after_generate: 控制种子变化方式。</p><p><strong>输出：</strong></p><p>pipe: 返回更新后的图像生成管道（new_pipe）。该管道包含了最新的采样设置（如步数、采样器、调度器等）</p><h3 id="三、EasyKSampler节点"><strong>三、EasyKSampler节点</strong></h3><p><strong>节点功能：该节点是一个简化版本的采样节点。该节点主要用于执行图像生成过程中的采样任务，并提供一些简单的配置选项，用户可以通过此节点指定输出的处理方式和其他采样相关的设置。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000715.png" alt="image"></p><p><strong>必需输入 (required)：</strong></p><p>pipe: 图像生成管道（pipe），该管道通常包含模型、VAE、CLIP 和采样相关的设置</p><p><strong>可选输入(optional)：</strong></p><p>model: 可选的模型参数，允许用户选择用于图像生成的模型。</p><p><strong>参数:</strong></p><p>image_output: 指定输出图像的处理方式</p><p>- Hide: 隐藏输出</p><p>- Preview: 预览输出</p><p>- Preview&amp;Choose: 预览输出并选择</p><p>- Save: 保存输出</p><p>- Hide&amp;Save: 隐藏并保存输出</p><p>- Sender: 将输出发送到其他系统或服务</p><p>- Sender&amp;Save: 发送并保存输出</p><p>- None: 不输出任何图像</p><p>该套文生图流程相比于传统文生图流程简化了很多步骤，__EasyLoader (Comfy)节点__集成了，只需要三个节点就可以完成。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000716.png" alt="image"></p><p>如果此时你觉得easyuse的正向提示词和负向提示词框不太方便使用，此时可单独将正向提示词框和负向提示词框例举出来，如下图所示：</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000717.png" alt="image"></p><h3 id="四、Pipe-Out和Pipe-In节点"><strong>四、Pipe Out和Pipe In节点</strong></h3><p><strong>节点功能：Pipe Out该节点是个用于输出图像生成管道信息的节点，它从传入的管道中提取关键信息并将这些信息作为输出。该节点的作用是对生成管道的各个部分进行汇总，便于后续操作或调试时使用。Pipe In节点则可以接收Pipe Out节点的输入作为下一个生图流程的输入。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000718.png" alt="image"></p><p>如下图，__Pipe In节点__接收__Pipe Out节点__的输出。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000719.png" alt="image"></p><p><strong>当然这里的节点也不需要全部连上，一般只连接pipe就行，如果后续需要改参数就连上相应的参数。</strong></p><h3 id="五、Pipe-Edit节点"><strong>五、Pipe Edit节点</strong></h3><p><strong>节点功能：该节点点用于编辑和更新图像生成管道中的各种条件设置，例如正负提示词、模型、VAE、CLIP 以及潜在空间数据。通过此节点，用户可以在现有的生成管道基础上进行调整，以便在生成图像时实现更多的控制。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000720.png" alt="image"></p><p><strong>参数：</strong></p><p>positive_token_normalization: 正向条件的标准化方法</p><p>- none: 无标准化</p><p>- mean: 均值标准化</p><p>- length: 长度标准化</p><p>- length+mean: 长度+均值标准化</p><p>positive_weight_interpretation: 正向条件权重的解释方法，决定如何应用正向提示词的权重</p><p>negative_token_normalization: 负向条件的标准化方法</p><p>negative_weight_interpretation: 负向条件权重的解释方法</p><p>a1111_prompt_style: 是否使用 A1111 风格的提示词格式</p><p>conditioning_mode: 条件合成的模式，控制如何结合正向和负向条件</p><p>如下图，当我们修改了正向提示词，在__Pipe In__节点上连接__positive__参数，生成图发生变化</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000721.png" alt="image"></p><h3 id="六、EasyLoraStack节点"><strong>六、EasyLoraStack节点</strong></h3><p><strong>节点功能：该节点是将多个 LORA 模型组合在一起，并允许用户通过不同的方式（简单或高级模式）配置 LORA 的强度和其他参数。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000722.png" alt="image"></p><p><strong>参数：</strong></p><p>toggle: 启用或禁用 LORA 堆栈。如果禁用，将不会返回 LORA 堆栈。</p><p>mode: 选择简单模式（simple）或高级模式（advanced）</p><p>num_loras: 指定堆栈中 LORA 模型的数量，最多为 max_lora_num（此处最大为 10）</p><p>lora_1_name: LORA 模型1的名称（从文件列表中获取）。</p><p>lora_1_strength: LORA模型1 的强度，适用于simple模式。</p><p>Easyuse加载lora的方式可以分为3种。</p><p>第一种如下图所示：直接在__EasyLoader (Comfy)__节点中加载lora模型，但只能加载一个。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000723.png" alt="image"></p><p>第二种情况是当lora数量较多时，可以通过外接lora stack节点进行lora管理，如下图所示<img src="https://xiao666.sbs/PicGo/IMG_000000724.png" alt="image"></p><p><strong>但要注意的是有些lora可能会相互冲突，有些lora的使用除了加载lora外还需要提示词去激活lora的使用，这个就需要使用者自己去调试了。</strong></p><h3 id="七、Wildcards节点"><strong>七、Wildcards节点</strong></h3><p><strong>节点功能：该节点主要目的是生成或更新提示词（prompt），支持通过通配符和 LORA 模型动态地修改文本内容。该类可以处理带有 LORA 块权重和通配符的输入文本，并且能够生成与其相关的多种版本（特别是多行文本的处理）。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000725.png" alt="image">参数：</p><p>Select to add LoRA：选择一个 LORA 模型，并将其添加到文本中。这个选择列表是动态的，包含所有当前可用的 LORA 模型。</p><p>Select to add Wildcard：选择一个通配符，并将其添加到文本中。这个选择列表是动态的，包含所有可用的通配符。</p><p>seed：用于生成随机数的种子。默认值为 0，最大值受 MAX_SEED_NUM 限制。</p><p>multiline_mode：如果为 True，表示输入文本是多行的，将分别处理每一行。否则，将处理整个文本。</p><p>第三种方法是通过wildcards进行加载lora使用，这个和webui的加载lora比较类似，具体使用如下图所示：<img src="https://xiao666.sbs/PicGo/IMG_000000726.png" alt="image"></p><p>同时wildcards节点除了加载lora外，还有一个重要的功能，可以支持wildcards，这样我们就可以组合出不同类型的图片了，使用方式如下：</p><p>比如我们想要在上图的基础上组合出不同头发颜色的女孩，就可以采样加载wildcard的方式实现，具体参考下图</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000727.png" alt="image"></p><p>其中__colors__ 代表我们想要加载头发颜色的组合，这里可以看出我们加载了文件中的粉色的头发，而这个颜色是来自于下面wildcards的文件里</p><p>下图是加载的wildcards文件的位置所在，如果你有想要使用的wildcards文件或者自己编写的文件都可以放在这个位置</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000728.png" alt="image"></p><p>文件里的内容是这种格式：</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000729.png" alt="image"></p><p>通过使用wildcards的方式就不必我们每次手动输入各式各样的提示词类型组合，而是通过wildcards组合的方式选出我们最希望得到的组合方式，提高了工作效率。</p><h3 id="八、EasyControlnet和EasyControlnet-Advanced-节点"><strong>八、EasyControlnet和EasyControlnet (Advanced)节点</strong></h3><p><strong>节点功能：该节点作用是将 ControlNet 应用于现有的图像处理管线，并根据给定的参数生成图像的“正向”条件和“负向”条件。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000730.png" alt="image"></p><p><strong>输入：</strong></p><p>pipe: 输入管道对象，包含有关图像生成的上下文信息，例如模型、条件、图像等。</p><p>image: 输入图像，通常是原始的图像数据</p><p>control_net: 可选的 ControlNet 模型对象。如果没有提供，将使用 control_net_name 中指定的模型。</p><p><strong>参数：</strong></p><p>control_net_name: ControlNet 模型的名称，从可用的 ControlNet 模型列表中选择。</p><p>strength: ControlNet模型控制强度，范围从 0 到 10，默认值为 1.0。较高的强度表示效果更明显。</p><p>start_percent: ControlNet开始应用的百分比，范围从 0 到 1，默认值为 0.0。表示从哪个阶段开始应用ControlNet的效果。</p><p>end_percent: ControlNet结束的百分比，范围从 0 到 1，默认值为 1.0。表示在哪个阶段停止应用ControlNet的效果。</p><p>scale_soft_weights: 控制软权重的比例，默认值为 1.0。调整权重的缩放可以影响效果的平滑程度。</p><p>其中，__Easycontrolnet（Advanced）__包含了EasyControlnet，所以我们就以__Easycontrolnet（Advanced）__为例，如下图所示，使用pose给EasyControlnet提供了骨骼图，最后生成出固定姿势的图片。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000731.png" alt="image"></p><p>接下来，在常用的情况下，我们也会需要其它的controlnet模型，这时候我们就需要controlnet的预处理器了，这个通过插件可以通过在manager里面搜索control找到</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000732.png" alt="image"></p><h3 id="九、ImageSize和ImageSize-Side-和ImageSize-LongerSide-节点"><strong>九、ImageSize和ImageSize (Side)和ImageSize (LongerSide)节点</strong></h3><p><strong>节点功能：获取图片的分辨率属性。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000733.png" alt="image"></p><p>如下图，其中__ImageSize (Side)__节点有选择Longest和Shortest选项，Longest就和__ImageSize (LongerSide)__节点一样，输出长和宽之间的最大值，Shortest则是输出长和宽之间的最小值。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000734.png" alt="image"></p><h3 id="十、ImagePixelPerfect节点"><strong>十、ImagePixelPerfect节点</strong></h3><p><strong>节点功能：根据给定的图像和调整模式来估算一个“完美”的分辨率。这个节点在处理图像时常常用于动态计算图像的目标分辨率，尤其是在图像缩放或调整时，需要确保输出图像在某些情况下尽可能符合给定的条件。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000735.png" alt="image"></p><p><strong>参数：</strong></p><p>resize_mode: 缩放模式，决定如何计算目标“完美像素”</p><p>- Just Resize: 常规的缩放方法，目标分辨率等于最大比例的缩放结果。</p><p>- Crop and Resize: 计算使图像完全适应一个给定尺寸的最小分辨率。</p><p>- Resize and Fill: 计算使图像完全适应外部框架的最大分辨率。</p><p>但实际用起来感觉差别不大，“完美像素”都是取的最小值。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000736.png" alt="image"></p><p>这里可以在__EasyLoader(Comfy）__节点中选择自定义分辨率，将计算的分辨率输出转换到__EasyLoader(Comfy）__节点长和宽的输入，这样输出的图像能够更好的适配输入图像的大小。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000737.png" alt="image"></p><h3 id="十一、HiresFix节点"><strong>十一、HiresFix节点</strong></h3><p><strong>节点功能：该节点的主要目的是对图像进行高清修复和分辨率提升，同时提供灵活的调整选项，确保图像质量和细节得到最大化保留。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000738.png" alt="image"></p><p><strong>参数：</strong></p><p>model_name: 使用的超分辨率模型名称</p><p>rescale_after_model: 是否在模型处理后进行额外的缩放。默认为 True，即在模型输出后应用缩放。</p><p>rescale_method: 后处理的缩放方法</p><p>rescale: 确定如何进行缩放。</p><p>- by percentage: 按百分比缩放</p><p>- to Width/Height: 按指定的宽高进行缩放</p><p>- to longer side - maintain aspect: 保持纵横比，以较长边为基础进行缩放</p><p>percent: 缩放百分比。用于在 by percentage 缩放模式下控制缩放的比例。</p><p>crop: 图像裁剪方式</p><p>- disabled: 不裁剪</p><p>- center: 居中裁剪</p><p>这里选择百分比放大，且放大百分比是百分之50，所以最终结果就是放大到原图的2倍，画质有了提升。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000739.png" alt="image"></p><h3 id="十二、PreDetailerFix节点"><strong>十二、PreDetailerFix节点</strong></h3><p><strong>节点功能：该节点主要用于图像的预细节修复，通过为图像处理提供更精细的控制选项，改善图像的细节表现。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000740.png" alt="image"></p><p><strong>必需输入（required）：</strong></p><p>pipe: 当前图像处理管道的相关信息，包括模型、图像、VAE等。</p><p><strong>可选输入（optional）：</strong></p><p>bbox_segm_pipe: 可选的边界框分割管道，用于辅助修复区域的选择。</p><p>sam_pipe: 可选的 SAM（Segment Anything Model）管道，用于提供分割信息。</p><p>optional_image: 可选的额外图像输入，默认从管道中获取图像。</p><p><strong>参数：</strong></p><p>guide_size: 引导图像的尺寸。默认为 256，指定了图像修复时的参考尺寸。</p><p>guide_size_for: 是否将 guide_size 用于边界框（bbox）或者裁剪区域（crop_region）。默认为 True，即用于边界框。</p><p>max_size: 最大图像尺寸，默认为 768，限制图像在修复过程中不超过此尺寸。</p><p>feather: 羽化程度，控制修复图像的边缘柔化效果。默认为 5。</p><p>noise_mask: 是否启用噪声掩膜，默认为启用（True）。</p><p>force_inpaint: 是否强制执行图像重绘，默认为启用（True）。</p><p>drop_size: 控制修复时的丢弃大小，影响图像修复区域的选择。</p><p>wildcard: 用于动态生成的提示文本，可以在图像修复过程中作为变动输入。</p><p>cycle: 图像修复的循环次数，默认为 1。</p><p>该节点需要搭配__UltralyticsDetector (Pipe)<strong>和__SAMLoader (Pipe)和DetailerFix__节点使用，用于脸部修复。具体参数细节可搭配__ComfyUI Impact 节点（二）：FaceDetailer / FaceDetailer(Pipe)节点</strong><a href="https://articles.zsxq.com/id_p5i8ma1vw7hn.html"><strong>https://articles.zsxq.com/id_p5i8ma1vw7hn.html</strong></a><strong>使用。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000741.png" alt="image"></p><p>从下图可以看出，人物的脸部细节有所修复。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000742.png" alt="image"></p><p><strong>十三、Get/Set/EasyGlobalSeed节点</strong><img src="https://xiao666.sbs/PicGo/IMG_000000743.png" alt="image"></p><p>具体用例如下：首先上面这套工作流使用了__Set__节点，并为这套流程自定义命名了ss，然后通过__Get__节点获取ss，从而不需要加载模型就能输出，要想上面和下面一样的话最好把种子设成一样并固定。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000744.png" alt="image"></p><p>使用该节点，可以使界面内的工作流的seed值与EasyGlobalSeed设置的值保持一致，避免在多个工作流做对比时，需要一个一个调节seed的问题。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000745.png" alt="image"></p><p><strong>EasyUse使用小tips</strong></p><p>1、 Bookmark书签的使用</p><p>使用搜索Bookmark，点击第一个即可调用Bookmark节点</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000746.png" alt="image"></p><p>该节点的作用是当我们使用书签上设置的快捷键时，使我们跳转到书签所在的位置。这个在长工作流的使用以及由于误触我们找不到我们工作流位置时，使用快捷键跳转到书签位置。</p><p>__ComfyUI Easy Use插件（二）: __<a href="https://t.zsxq.com/lNdvT"><strong>https://articles.zsxq.com/easyuse/2.html</strong></a></p><p>__ComfyUI Easy Use插件（三）: __<a href="https://t.zsxq.com/UsFSp"><strong>https://articles.zsxq.com/easyuse/3.html</strong></a></p><p>__ComfyUI Easy Use插件（四）: __<a href="https://t.zsxq.com/gSJA1"><strong>https://articles.zsxq.com/easyuse/4.html</strong></a></p><p>__ComfyUI Easy Use插件（五）: __<a href="https://t.zsxq.com/IAye6"><strong>https://articles.zsxq.com/easyuse/5.html</strong></a></p><p>__ComfyUI Easy Use插件（六）: __<a href="https://t.zsxq.com/PhouI"><strong>https://articles.zsxq.com/easyuse/6.html</strong></a></p><p>__ComfyUI Easy Use插件（七）: __<a href="https://t.zsxq.com/jDjyM"><strong>https://articles.zsxq.com/easyuse/7.html</strong></a></p><p>__ComfyUI Easy Use插件（八）: __<a href="https://t.zsxq.com/UXZK4"><strong>https://articles.zsxq.com/easyuse/8.html</strong></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前言：&quot;&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;EasyUse 是 ComfyUI 图像生成和处理框架中的一个模块，旨在通过简化的界面和易于配置的节点来提供用户友好的操作体验，特别适合希望快速开始图像生成、修复、增强等任务的用户。&lt;/p&gt;
&lt;p</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
  <entry>
    <title>【ComfyUI插件】ComfyUI Easy Use插件（七）</title>
    <link href="https://www.fomal.cc/posts/91d9127c.html"/>
    <id>https://www.fomal.cc/posts/91d9127c.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.315Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言："><strong>前言：</strong></h2><p>该插件由B站大佬乱乱呀AI进行开发出来的，此插件主要在使用管道、简化工作流、提供简便工具和集成化等方面起到了明显作用。</p><h2 id="目录"><strong>目录</strong></h2><p><strong>先行：安装方法</strong></p><p><strong>一、Easy Slider Control节点</strong></p><p><strong>二、PreSampling (NoiseIn)节点</strong></p><p><strong>三、Easy Apply Fooocus Inpaint节点</strong></p><p><strong>四、EasyLoader (HunyuanDiT)节点</strong></p><p><strong>五、EasyLoader (Kolors)节点</strong></p><p><strong>六、Easy Apply IPAdapter (FaceID Kolors)节点</strong></p><p><strong>七、Range(Float)节点</strong></p><p><strong>八、LatentNoisy节点</strong></p><p><strong>九、Sleep节点</strong></p><p><strong>十、XY Plot节点</strong></p><p>__ComfyUI Easy Use插件（一）: __<a href="https://t.zsxq.com/AAZQm"><strong>https://articles.zsxq.com/easyuse/1.html</strong></a></p><p>__ComfyUI Easy Use插件（二）: __<a href="https://t.zsxq.com/lNdvT"><strong>https://articles.zsxq.com/easyuse/2.html</strong></a></p><p>__ComfyUI Easy Use插件（三）: __<a href="https://t.zsxq.com/UsFSp"><strong>https://articles.zsxq.com/easyuse/3.html</strong></a></p><p>__ComfyUI Easy Use插件（四）: __<a href="https://t.zsxq.com/gSJA1"><strong>https://articles.zsxq.com/easyuse/4.html</strong></a></p><p>__ComfyUI Easy Use插件（五）: __<a href="https://t.zsxq.com/IAye6"><strong>https://articles.zsxq.com/easyuse/5.html</strong></a></p><p>__ComfyUI Easy Use插件（六）: __<a href="https://t.zsxq.com/PhouI"><strong>https://articles.zsxq.com/easyuse/6.html</strong></a></p><p>__ComfyUI Easy Use插件（八）: __<a href="https://t.zsxq.com/UXZK4"><strong>https://articles.zsxq.com/easyuse/8.html</strong></a></p><p><strong>本期使用的示例工作流在网盘：小黄瓜知识星球资料分享/插件节点讲解视频/ComfyUI_EasyUse/第七期文件夹中</strong></p><h2 id="安装方法"><strong>安装方法</strong></h2><p>安装方法，一共有2种</p><p><strong>1、在manager里搜索Easy Use，然后点击安装第3个即可</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000747.png" alt="image"></p><p>__2、在custom_nodes目录下调用cmd，然后输入git clone __<a href="https://github.com/yolain/ComfyUI-Easy-Use.git"><strong>https://github.com/yolain/ComfyUI-Easy-Use.git</strong></a></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000748.png" alt="image"></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000749.png" alt="image"></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000750.png" alt="image"></p><p><strong>项目地址：</strong><a href="https://github.com/yolain/ComfyUI-Easy-Use.git"><strong>https://github.com/yolain/ComfyUI-Easy-Use.git</strong></a></p><h3 id="一、Easy-Slider-Control节点"><strong>一、Easy Slider Control节点</strong></h3><p><strong>节点功能：提供对sd1.5和sdxl的ipadapter模型中每一层的控制与调节</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000751.png" alt="image"></p><h4 id="参数："><strong>参数：</strong></h4><p>mode -&gt; 目前只能选择ipadapter layer weights</p><p>mode_type -&gt; 可选择sdxl和sd1，分为对应sdxl和sd1.5的ipadapter模型的层控制，默认是选择sdxl</p><p>层0 -&gt; 设置sdxl的IPA的第0层的权重，该层主要影响构图的整体结构</p><p>层1 -&gt; 设置sdxl的IPA的第1层的权重，该层主要影响构图的配色方案</p><p>层2 -&gt; 设置sdxl的IPA的第2层的权重，该层主要影响构图的构成</p><p>层3 -&gt; 设置sdxl的IPA的第3层的权重，该层主要影响构图的光照和阴影</p><p>层4 -&gt; 设置sdxl的IPA的第4层的权重，该层主要影响构图的纹理和细节</p><p>层5 -&gt; 设置sdxl的IPA的第5层的权重，该层主要影响构图的风格</p><p>层6 -&gt; 设置sdxl的IPA的第6层的权重，该层主要影响构图的深度和透视</p><p>层7 -&gt; 设置sdxl的IPA的第7层的权重，该层主要影响构图的深背景和环境</p><p>层8 -&gt; 设置sdxl的IPA的第8层的权重，该层主要影响构图的对象特征</p><p>层9 -&gt; 设置sdxl的IPA的第9层的权重，该层主要影响构图的运动和动力学</p><p>层10 -&gt; 设置sdxl的IPA的第10层的权重，该层主要影响构图的情绪和表情</p><p>层11 -&gt; 设置sdxl的IPA的第11层的权重，该层主要影响构图的上下文一致性</p><p><strong>输出：</strong></p><p>layer_weights -&gt; 输出设置的每层权重参数</p><p>这些参数很难有个标准答案， 得自己慢慢调试到自己需要的风格。但需要注意的是，需要正确选择适配的模型才能生效。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000752.png" alt="image"></p><h3 id="二、PreSampling-NoiseIn-节点"><strong>二、PreSampling (NoiseIn)节点</strong></h3><p><strong>节点功能：该节点的功能是为图像生成管道（pipeline）设置预采样阶段的噪声注入操作。通过调整噪声因子、步数和采样器参数，可以在图像生成过程中引入不同程度的随机性和变化性，为最终结果提供更丰富的多样性。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000753.png" alt="image"></p><h4 id="输入："><strong>输入：</strong></h4><p>pipe -&gt; 输入的管道</p><p>optional_latent -&gt; 输入的潜空间图片，可选项</p><p>optional_noise_seed -&gt; 输入的噪声种子，可选项</p><p><strong>参数：</strong></p><p>factor -&gt; 设置的额外噪声占总体噪声的比例</p><p><strong>注意这里的噪声是经过球面线性插值处理的，所以即使factor为0，也不是和原本一点额外噪声都不加的采样器一样</strong></p><p>steps -&gt; 设置的采样步数</p><p>cfg -&gt; 设置的引导系数</p><p>sampler_name -&gt; 设置的采样器名字</p><p>scheduler -&gt; 设置的调度器名字</p><p>denoise -&gt; 设置的降噪强度</p><p>seed -&gt; 设置的种子数</p><p>control_after_generate -&gt; 设置的种子数生成模式，分为randomize（随机）、fixed（固定）、decrement（减少）和increment（增加）</p><p><strong>输出：</strong></p><p>pipe -&gt; 输出设置完参数后的管道</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000754.png" alt="image"></p><h3 id="三、Easy-Apply-Fooocus-Inpaint节点"><strong>三、Easy Apply Fooocus Inpaint节点</strong></h3><p><strong>节点功能：使用fooocus模型进行重绘的节点，注意只适用于SDXL模型</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000755.png" alt="image"></p><h4 id="输入-："><strong>输入 ：</strong></h4><p>model -&gt; 输入的SDXL模型</p><p>latent -&gt; 输入的潜空间图片</p><p><strong>参数：</strong></p><p>head -&gt; 选择的fooocus重绘模式</p><p>patch -&gt; 选择的重绘模型，默认是inpaint_v26</p><p>如下图，使用fooocus模型对人物的服装进行重绘，在正向提示词中只需要输入需要替换部分的描述词即可。<img src="https://xiao666.sbs/PicGo/IMG_000000756.png" alt="image"></p><h3 id="四、EasyLoader-HunyuanDiT-节点"><strong>四、EasyLoader (HunyuanDiT)节点</strong></h3><p><strong>节点功能：混元模型加载器</strong><img src="https://xiao666.sbs/PicGo/IMG_000000757.png" alt="image"></p><h4 id="输入：-2"><strong>输入：</strong></h4><p>optional_lora_stack -&gt; 输入的lora模型组，可选项</p><p>optional_controlnet_stack -&gt; 输入的controlnet模型组，可选项</p><p><strong>参数：</strong></p><p>ckpt_name -&gt; 设置混元模型</p><p>vae_name -&gt; 设置vae模型</p><p>lora_name -&gt; 设置混元lora模型</p><p>resolution -&gt; 设置生成图片的分辨率</p><p>positive -&gt; 设置输入的正向提示词</p><p>negative -&gt; 设置输入的负向提示词</p><p>batch_size -&gt; 设置一批图片生成的图片数</p><p><strong>输出：</strong></p><p>pipe -&gt; 输出的管道</p><p>model -&gt; 输出的混元模型</p><p>vae -&gt; 输出使用的vae模型</p><h3 id="image"><img src="https://xiao666.sbs/PicGo/IMG_000000758.png" alt="image"></h3><h3 id="五、EasyLoader-Kolors-节点"><strong>五、EasyLoader (Kolors)节点</strong></h3><p><strong>节点功能：快手的可图模型加载器</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000759.png" alt="image"></p><h4 id="输入：-3"><strong>输入：</strong></h4><p>model_override -&gt; 输入的用于覆盖的可图unet模型，可选项</p><p>vae_override -&gt; 输入的用于覆盖的可图vae模型，可选项</p><p>optional_lora_stack -&gt; 输入的用于覆盖的可图lora模型组，可选项</p><p>参数</p><p>unet_name -&gt; 设置可图unet模型</p><p>vae_name -&gt; 设置可图vae模型</p><p>chatglm3_name -&gt; 设置chatglm3模型</p><p>lora_name -&gt; 设置可图lora模型</p><p>resolution -&gt; 设置可图模型生成的图片分辨率</p><p>positive -&gt; 设置输入的正向提示词</p><p>negative -&gt; 设置输入的负向提示词</p><p>batch_size -&gt; 设置一批图片生成的图片数</p><p>auto_clean_gpu -&gt; 设置图片生成后是否清除占用的gpu显存</p><p><strong>输出：</strong></p><p>pipe -&gt; 输出的管道</p><p>model -&gt; 输出可图模型</p><p>vae -&gt; 输出可图的vae模型</p><h3 id="image-2"><img src="https://xiao666.sbs/PicGo/IMG_000000760.png" alt="image"></h3><h3 id="六、Easy-Apply-IPAdapter-FaceID-Kolors-节点"><strong>六、Easy Apply IPAdapter (FaceID Kolors)节点</strong></h3><p><strong>节点功能：使用可图模型的ipadapter模型</strong><img src="https://xiao666.sbs/PicGo/IMG_000000761.png" alt="image"></p><h4 id="参数：-2"><strong>参数：</strong></h4><p>model -&gt; 输入的模型</p><p>image -&gt; 输入的参考图片</p><p>image_negative -&gt; 输入的负向图片</p><p>attn_mask -&gt; 输入的注意力蒙版</p><p>clip_vision -&gt; 输入的clip模型</p><p>optional_ipadapter -&gt; 输入的ipadapter模型，可选项</p><p><strong>参数：</strong></p><p>preset -&gt; 预设的可图ipadapter模式</p><p>provider -&gt; 使用的IPA模型加载方式，一般选择CUDA即可</p><p>weight -&gt; 设置整体IPA模型权重乘积系数</p><p>weight_faceidv2 -&gt; 设置IPA的faceidv2模型权重</p><p>weight_kolors -&gt; 设置kolors的IPA模型权重</p><p>weight_type -&gt; 设置的ipadapter模型权重类型，这个参数决定了权重在模型的不同层中应用的方式，分为linear、ease in、ease out、ease in-out、reverse in-out、weak input、weak output、weak middle、strong middle、style transfer、composition、strong style transfer、style and composition、style transfer precise</p><p>combine_embeds -&gt; 在输入的多个参考图片使用的结合嵌入方式，分为concat、add、subtract、average、norm average</p><p>start_at -&gt; 输入的ipadapter模型起始作用的时间，默认0代表从最开始就开始作用</p><p>end_at -&gt; 输入的ipadapter模型结束作用的时间，默认1代表作用到最后</p><p>embeds_scaling -&gt; 分为V only、K+V、K+V w/C penalty、K+mean(V) w/C penalty，决定了嵌入在模型内的缩放或组合方式</p><p>cache_mode -&gt; 选择模型加载到缓存，分为insightface only（只加载insightface模型）、clip_vision only（只加载clip模型）、ipadapter only（只加载ipadapter模型）、all（全加载）、none（不加载）</p><p>use_batch -&gt; 是否使用批量生成图片</p><p><strong>输出：</strong></p><p>model -&gt; 输出调节后的模型</p><p>ipadapter -&gt; 输出使用的ipadapter模型</p><p>masks -&gt; 输出的注意力蒙版</p><p>ipadapter -&gt; 输出的ipadapter模型</p><p>需要注意的是，这里需要加载clip vision模型，且必须是kolors模型支持的，否则报错。而更多关于__IPAdapter <strong>细节可跳转b站</strong>：<strong><a href="https://www.bilibili.com/video/BV1cD6mY1EkG/?spm_id_from=333.337.search-card.all.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>啦啦啦的小黄瓜</strong></a></strong>。__</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000762.png" alt="image"></p><h3 id="七、Range-Float-节点"><strong>七、Range(Float)节点</strong></h3><p><strong>节点功能：提供一个设置范围内的小数数组，可用于寻找适合的图片生成cfg 系数</strong><img src="https://xiao666.sbs/PicGo/IMG_000000763.png" alt="image"></p><h4 id="参数：-3"><strong>参数：</strong></h4><p>range_mode -&gt; 范围模式，分为step和num_steps两个模式，step模式是根据下面的step从start值进行相加step值到stop值的模式，而num_steps模式是从start值到stop值中输出num_steps个值的模式</p><p>start -&gt; 设置开始值，格式为浮点型</p><p>stop -&gt; 设置终止值，格式为浮点型</p><p>step/num_steps -&gt; 设置step值的累加/设置生成num_steps个值</p><p>end_mode -&gt; 终止点分为Inclusive和Exclusive两个模式，Inclusive是如果有终止值的情</p><p>况下可以包括终止值，Exclusive是不包括终止值</p><p><strong>输出：</strong></p><p>range：输出生成的数组</p><p>range_sizes：输出生成的数组大小</p><p>关于更多参数讲解大家可参考<a href="https://t.zsxq.com/gSJA1"><strong>ComfyUI Easy Use插件（四）</strong></a>中关于__Range(Int)节点__的讲解，基本一样。</p><h3 id="八、LatentNoisy节点"><strong>八、LatentNoisy节点</strong></h3><p><strong>节点功能：该节点将通过计算潜变量空间的噪声级别（Sigma），对潜变量（latent）进行逐步缩放，生成加权后的潜变量。此功能通常用于调整潜变量中的噪声强度，从而影响图像生成过程的细节。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000764.png" alt="image"></p><p><strong>输入：</strong></p><p>pipe -&gt; 输入的管道</p><p>optional_model -&gt; 输入的模型，可选项</p><p>optional_latent -&gt; 输入的潜空间图片，可选项</p><p><strong>参数：</strong></p><p>sampler_name -&gt; 设置采样器名字</p><p>scheduler -&gt; 设置调度器</p><p>steps -&gt; 设置采样步数</p><p>start_at_step -&gt; 设置开始采样步数</p><p>end_at_step -&gt; 设置结束采样步数</p><p>source -&gt; 设置噪声产生来源，可选择CPU或者GPU</p><p>seed -&gt; 设置使用的种子数</p><p>control_after_generate -&gt; 设置的种子数生成模式，分为randomize（随机）、fixed（固定）、decrement（减少）和increment（增加）</p><p><strong>输出：</strong></p><p>pipe -&gt; 输出的管道</p><p>latent -&gt; 输出潜空间图片</p><p>sigma -&gt; 输出sigma参数</p><h3 id="image-3"><img src="https://xiao666.sbs/PicGo/IMG_000000765.png" alt="image"></h3><h3 id="九、Sleep节点"><strong>九、Sleep节点</strong></h3><p><strong>节点功能：提供延迟运行工作流的节点</strong><img src="https://xiao666.sbs/PicGo/IMG_000000766.png" alt="image"></p><h4 id="参数：-4"><strong>参数：</strong></h4><p>any -&gt; 输入的想要开始延迟的节点</p><p>delay -&gt; 设置延迟的秒数</p><p>out -&gt; 输出的节点，用来连接延迟结束后继续运行的节点</p><p>如下图，在__sleep__节点中设置延迟2秒，运行时间就会增加大约2秒（不是精确的2秒）。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000767.png" alt="image"></p><h3 id="十、XY-Plot节点"><strong>十、XY Plot节点</strong></h3><p><strong>节点功能：提供XY散点图，用于记录在不同参数条件下生成的图片变化</strong><img src="https://xiao666.sbs/PicGo/IMG_000000768.png" alt="image"></p><h4 id="参数：-5"><strong>参数：</strong></h4><p>grid_spacing -&gt; 设置每个图片网格间的距离</p><p>output_individuals -&gt; 设置每个生成图片是否还需要独立输出</p><p>flip_xy -&gt; 设置是否翻转xy坐标轴</p><p>x_axis -&gt; 设置x坐标轴参数</p><p>x坐标轴参数栏 -&gt; 设置x坐标轴中每个具体的参数取值</p><p>x_axis -&gt; 设置y坐标轴参数</p><p>y坐标轴参数栏 -&gt; 设置y坐标轴中每个具体的参数取值</p><p>其中的__x_axis__和__y_axis__中是有可选参数的，一般都是些常用的KSampler参数。当不知道如何设置参数时可使用该节点进行对比，从而找到最好的生图参数。</p><h3 id="image-4"><img src="https://xiao666.sbs/PicGo/IMG_000000769.png" alt="image"></h3><p>__ComfyUI Easy Use插件（一）: __<a href="https://t.zsxq.com/AAZQm"><strong>https://articles.zsxq.com/easyuse/1.html</strong></a></p><p>__ComfyUI Easy Use插件（二）: __<a href="https://t.zsxq.com/lNdvT"><strong>https://articles.zsxq.com/easyuse/2.html</strong></a></p><p>__ComfyUI Easy Use插件（三）: __<a href="https://t.zsxq.com/UsFSp"><strong>https://articles.zsxq.com/easyuse/3.html</strong></a></p><p>__ComfyUI Easy Use插件（四）: __<a href="https://t.zsxq.com/gSJA1"><strong>https://articles.zsxq.com/easyuse/4.html</strong></a></p><p>__ComfyUI Easy Use插件（五）: __<a href="https://t.zsxq.com/IAye6"><strong>https://articles.zsxq.com/easyuse/5.html</strong></a></p><p>__ComfyUI Easy Use插件（六）: __<a href="https://t.zsxq.com/PhouI"><strong>https://articles.zsxq.com/easyuse/6.html</strong></a></p><p>__ComfyUI Easy Use插件（八）: __<a href="https://t.zsxq.com/UXZK4"><strong>https://articles.zsxq.com/easyuse/8.html</strong></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前言：&quot;&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;该插件由B站大佬乱乱呀AI进行开发出来的，此插件主要在使用管道、简化工作流、提供简便工具和集成化等方面起到了明显作用。&lt;/p&gt;
&lt;h2 id=&quot;目录&quot;&gt;&lt;strong&gt;目录&lt;/strong&gt;&lt;/h</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
  <entry>
    <title>【ComfyUI插件】ComfyUI Easy Use插件（三）</title>
    <link href="https://www.fomal.cc/posts/fe64f218.html"/>
    <id>https://www.fomal.cc/posts/fe64f218.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.316Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言："><strong>前言：</strong></h3><p>该插件由B站大佬乱乱呀AI进行开发出来的，此插件主要在使用管道、简化工作流、提供简便工具和集成化等方面起到了明显作用。</p><p>__ComfyUI Easy Use插件（一）: __<a href="https://t.zsxq.com/AAZQm"><strong>https://articles.zsxq.com/easyuse/1.html</strong></a></p><p>__ComfyUI Easy Use插件（二）: __<a href="https://t.zsxq.com/lNdvT"><strong>https://articles.zsxq.com/easyuse/2.html</strong></a></p><p>__ComfyUI Easy Use插件（四）: __<a href="https://t.zsxq.com/gSJA1"><strong>https://articles.zsxq.com/easyuse/4.html</strong></a></p><p>__ComfyUI Easy Use插件（五）: __<a href="https://t.zsxq.com/IAye6"><strong>https://articles.zsxq.com/easyuse/5.html</strong></a></p><p>__ComfyUI Easy Use插件（六）: __<a href="https://t.zsxq.com/PhouI"><strong>https://articles.zsxq.com/easyuse/6.html</strong></a></p><p>__ComfyUI Easy Use插件（七）: __<a href="https://t.zsxq.com/jDjyM"><strong>https://articles.zsxq.com/easyuse/7.html</strong></a></p><p>__ComfyUI Easy Use插件（八）: __<a href="https://t.zsxq.com/UXZK4"><strong>https://articles.zsxq.com/easyuse/8.html</strong></a></p><p><strong>本期使用的示例工作流在网盘：小黄瓜知识星球资料分享/插件节点讲解视频/ComfyUI_EasyUse/第三期文件夹中（其中提供了flux checkpoint模型）</strong></p><h3 id="目录"><strong>目录</strong></h3><p><strong>先行：安装方法</strong></p><p><strong>一、EasyLoader（Flux）节点</strong></p><p><strong>二、Styles Selector节点</strong></p><p><strong>三、Image To Base64节点</strong></p><p><strong>四、Load Image (Base64) 节点</strong></p><p><strong>五、ImageRatio节点</strong></p><p><strong>六、imageConcat节点</strong></p><p><strong>七、For Loop Start/For Loop End节点</strong></p><p><strong>八、While Loop Start/While Loop End节点</strong></p><h3 id="安装方法"><strong>安装方法</strong></h3><p>安装方法，一共有2种</p><p><strong>1、在manager里搜索 Easy Use，然后点击安装第一个即可</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000770.png" alt="image"></p><p>__2、在custom_nodes目录下调用cmd，然后输入git clone __<a href="https://github.com/yolain/ComfyUI-Easy-Use.git"><strong>https://github.com/yolain/ComfyUI-Easy-Use.git</strong></a></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000771.png" alt="image"></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000772.png" alt="image"></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000773.png" alt="image"></p><h3 id="项目地址：https-github-com-yolain-ComfyUI-Easy-Use-git"><strong>项目地址：</strong><a href="https://github.com/yolain/ComfyUI-Easy-Use.git">https://github.com/yolain/ComfyUI-Easy-Use.git</a></h3><h3 id="一、EasyLoader-Flux-节点"><strong>一、EasyLoader (Flux)节点</strong></h3><p><strong>节点功能：进行flux模型的加载和提示词的设置</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000774.png" alt="image"></p><p><strong>输入：</strong></p><p>model_override -&gt; 连接的覆盖模型，连接后会覆盖掉现有的ckpt主模型，可连接unet模型</p><p>clip_override -&gt; 连接的覆盖的clip模型，连接后会覆盖掉现有的clip模型</p><p>vae_override -&gt; 连接的覆盖的vae模型，连接后会覆盖掉现有的vae模型</p><p>optional_lora_stack -&gt; 连接多个可选lora，和easy loraStack节点连接</p><p>optional_controlnet_stack -&gt; 连接多个可选controlnet模型，和easy controlnetStack节点连接</p><p><strong>参数：</strong></p><p>ckpt_name -&gt; 加载的主模型</p><p>vae_name -&gt; 加载的vae模型</p><p>lora_name -&gt; 加载的lora模型</p><p>resolution -&gt; 生成图片的分辨率</p><p>positive -&gt; 输入的正向提示词</p><p>batch_size -&gt; 设置一批输出的图片数量</p><p><strong>输出：</strong></p><p>pipe -&gt; 输出的管道</p><p>model -&gt; 输出的主模型</p><p>vae -&gt; 输出的vae模型</p><p>此处加载的是__flux checkpoint__模型，使用flux模型，cfg参数最好设小一点，否则出图效果不好（cfg=8.0）。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000775.png" alt="image"></p><h3 id="二、Styles-Selector节点"><strong>二、Styles Selector节点</strong></h3><p><strong>节点功能：提供已经预设的各种常见图片风格的提示词</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000776.png" alt="image"></p><h3 id="参数："><strong>参数：</strong></h3><p>positve -&gt; 输入的正向提示词文本</p><p>negative -&gt; 输入的负面提示词文本</p><p>styles -&gt; 默认的styles类型</p><p>可勾选的style类型 -&gt; 可以选多个，会增加对应选择的风格类型提示词</p><p>positive -&gt; 输出的经过增加风格类型提示词后正向提示词</p><p>negative -&gt; 输出的经过增加风格类型提示词后负向提示词</p><p>首先可以使用Positive节点输入想要生成图的关键字，比如__1girl__，此时还没勾选__Styles Selector节点__中的风格引入，生成的图像只有大模型引导的风格。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000777.png" alt="image"></p><p>勾选了一个赛博朋克风格后，此时__EasyLoader(comfy)节点__中__positive__和__negtive__提示词发生了变化，图像中也引入了赛博风格。当然，也可以同时勾选多个风格进行混合，这里就不做尝试了。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000778.png" alt="image"></p><h3 id="三、Image-To-Base64节点"><strong>三、Image To Base64节点</strong></h3><p><strong>节点功能：将图片转为Base64编码的字符串</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000779.png" alt="image"></p><h3 id="参数：-2"><strong>参数：</strong></h3><p>image -&gt; 输入的图片</p><p>STRING -&gt; 输出图片转换为Base64的编码</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000780.png" alt="image"></p><h3 id="四、Load-Image-Base64-节点"><strong>四、Load Image (Base64)节点</strong></h3><p><strong>节点功能：加载Base64图片编码转换的图片，使得在分享给他人运行工作流时省去了加载选择图片的过程</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000781.png" alt="image"></p><h3 id="参数：-3"><strong>参数：</strong></h3><p>base64_data -&gt; 输入的base64图片编码字符串</p><p>image_output -&gt; 输出的图片预览</p><p>IMAGE -&gt; 输出的图片</p><p>MASK -&gt; 输出的图片蒙版</p><p>将上个节点所生成的string文本复制输入到__base64_data__后可重新转回图片。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000782.png" alt="image"></p><h3 id="五、ImageRatio节点"><strong>五、ImageRatio节点</strong></h3><p>__节点功能：求出图片的宽高比例 __</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000783.png" alt="image"></p><h3 id="参数：-4"><strong>参数：</strong></h3><p>image -&gt; 输入的图片</p><p>width_ratio_int -&gt; 输出宽的比例的整数形式</p><p>height_ratio_int -&gt; 输出高的比例的整数形式</p><p>width_ratio_float -&gt; 输出宽的比例的浮点数形式</p><p>height_ratio_float -&gt; 输出高的比例的浮点数形式</p><p>上图大小就是454x919，由于两者是除不尽的关系，故输出454：919。</p><p>而下图大小是512x512，两者能够相除，输出1：1</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000784.png" alt="image"></p><h3 id="六、imageConcat节点"><strong>六、imageConcat节点</strong></h3><p>__节点功能：进行2张图片的拼接 __</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000785.png" alt="image"></p><h3 id="参数：-5"><strong>参数：</strong></h3><p>image1 -&gt; 输入的图片1</p><p>image2 -&gt; 输入的图片2</p><p>direction -&gt; 图片2拼接在图片1的方向，分为up、down、right、left</p><p>match_image_size -&gt; 是否启动图片大小匹配，启动后大小不一样的图片会进行自动匹配</p><p>当两张输入的图像大小一样时，可以任意选择拼接，这里着重一下当输入两张大小不同的图片情况。</p><p>当图片大小不一样时，match_image_size为false，无论选择哪个direction，图像都会拼接失败。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000786.png" alt="image"></p><p>image1大小454x919，image2大小512x512，启用图像匹配后，图像也只能纵向排列，left和right依旧失败。该节点首先对image2的宽度插值到image1宽度的大小，然后在高度上进行拼接。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000787.png" alt="image"></p><h3 id="七、For-Loop-Start-For-Loop-End-Batch-Any-Math-Int节点"><strong>七、For Loop Start/For Loop End/Batch Any/Math Int节点</strong></h3><p><strong>节点功能：设置for循环的开始/设置for循环的结束</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000788.png" alt="image"></p><h3 id="参数：-6"><strong>参数：</strong></h3><p>initial_value1 -&gt; 设置输入的最开始初始值1</p><p>total -&gt; 设置循环轮数</p><p>flow -&gt; 输出流</p><p>index -&gt; 输出当前的index值</p><p>value1 -&gt; 输出当前初始值1的值</p><h3 id="image"><img src="https://xiao666.sbs/PicGo/IMG_000000789.png" alt="image"></h3><p><strong>节点功能：用于将两个输入合并成一个输出。</strong></p><p><strong>输入：</strong></p><p>any_1 -&gt; 这是第一个输入，类型为 any_type，即可以是任何数据类型。</p><p>any_2 -&gt; 这是第二个输入，类型为 any_type，即可以是任何数据类型</p><h3 id="image-2"><img src="https://xiao666.sbs/PicGo/IMG_000000790.png" alt="image"></h3><p><strong>节点功能：专门用于执行两个整数之间的各种数学操作。它支持六种基本运算，包括加法、减法、乘法、除法、取模和幂运算。</strong></p><p>该流程相当于2循环7次， 每次在此基础上__add__累加一次，首次运行不进行累加。</p><h3 id="image-3"><img src="https://xiao666.sbs/PicGo/IMG_000000791.png" alt="image"></h3><p>该工作流实现在预设种子数每次循环加1的情况下经过3次循环生成3张图片的效果</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000792.png" alt="image"></p><p>该工作流实现在预设采样步数step每次循环加8的情况下经过3次循环生成3张图片的效果</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000793.png" alt="image"></p><h3 id="十、While-Loop-Start-While-Loop-End-Compare节点"><strong>十、While Loop Start/While Loop End/Compare节点</strong></h3><p><strong>节点功能：设置while循环开始/设置while循环结束</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000794.png" alt="image"></p><h3 id="参数：-7"><strong>参数：</strong></h3><p>initial_value0-9 -&gt; 设置初始值value0-9，可选</p><p>condition -&gt; 判断条件</p><p>flow -&gt; 输出的流，与loop end连接</p><p>value0-9 -&gt; 输出value0到value9的当前值</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000795.png" alt="image"></p><p><strong>节点功能：用于执行两个输入值 a 和 b 之间的比较操作， 并返回一个布尔值（True 或 False）作为比较结果。</strong></p><p>该流程中实现了在预设种子数每次循环加1的情况下经过3次循环生成3张图片的效果。其中a&lt;b时，流程一直在循环进行生图，而当a累加至大于b时，循环终止。如果刚开始直接设置判断条件为a&gt;b，该流程只会走一次就终止了，当不满足条件，其中的Math Int节点就不会起作用，a就不会进行累加，只要不满足判断条件，循环就终止。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000796.png" alt="image"></p><p>__ComfyUI Easy Use插件（一）: __<a href="https://t.zsxq.com/AAZQm"><strong>https://articles.zsxq.com/easyuse/1.html</strong></a></p><p>__ComfyUI Easy Use插件（二）: __<a href="https://t.zsxq.com/lNdvT"><strong>https://articles.zsxq.com/easyuse/2.html</strong></a></p><p>__ComfyUI Easy Use插件（四）: __<a href="https://t.zsxq.com/gSJA1"><strong>https://articles.zsxq.com/easyuse/4.html</strong></a></p><p>__ComfyUI Easy Use插件（五）: __<a href="https://t.zsxq.com/IAye6"><strong>https://articles.zsxq.com/easyuse/5.html</strong></a></p><p>__ComfyUI Easy Use插件（六）: __<a href="https://t.zsxq.com/PhouI"><strong>https://articles.zsxq.com/easyuse/6.html</strong></a></p><p>__ComfyUI Easy Use插件（七）: __<a href="https://t.zsxq.com/jDjyM"><strong>https://articles.zsxq.com/easyuse/7.html</strong></a></p><p>__ComfyUI Easy Use插件（八）: __<a href="https://t.zsxq.com/UXZK4"><strong>https://articles.zsxq.com/easyuse/8.html</strong></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;前言：&quot;&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;该插件由B站大佬乱乱呀AI进行开发出来的，此插件主要在使用管道、简化工作流、提供简便工具和集成化等方面起到了明显作用。&lt;/p&gt;
&lt;p&gt;__ComfyUI Easy Use插件（一）: __&lt;a h</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
  <entry>
    <title>【ComfyUI插件】ComfyUI Easy Use插件（二）——重绘</title>
    <link href="https://www.fomal.cc/posts/b7b66efe.html"/>
    <id>https://www.fomal.cc/posts/b7b66efe.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.321Z</updated>
    
    <content type="html"><![CDATA[<p><strong>前言：</strong></p><p>本节主要是将comfyui的原生重绘工作流与EasyUse重绘工作流进行对比讲解，帮助大家更好的理解不同重绘方式之间的差别（<strong>主要描述了各种不同的重绘方式</strong>）。</p><p>__ComfyUI Easy Use插件（一）: __<a href="https://t.zsxq.com/AAZQm"><strong>https://articles.zsxq.com/easyuse/1.html</strong></a></p><p>__ComfyUI Easy Use插件（三）: __<a href="https://t.zsxq.com/UsFSp"><strong>https://articles.zsxq.com/easyuse/3.html</strong></a></p><p>__ComfyUI Easy Use插件（四）: __<a href="https://t.zsxq.com/gSJA1"><strong>https://articles.zsxq.com/easyuse/4.html</strong></a></p><p>__ComfyUI Easy Use插件（五）: __<a href="https://t.zsxq.com/IAye6"><strong>https://articles.zsxq.com/easyuse/5.html</strong></a></p><p>__ComfyUI Easy Use插件（六）: __<a href="https://t.zsxq.com/PhouI"><strong>https://articles.zsxq.com/easyuse/6.html</strong></a></p><p>__ComfyUI Easy Use插件（七）: __<a href="https://t.zsxq.com/jDjyM"><strong>https://articles.zsxq.com/easyuse/7.html</strong></a></p><p>__ComfyUI Easy Use插件（八）: __<a href="https://t.zsxq.com/UXZK4"><strong>https://articles.zsxq.com/easyuse/8.html</strong></a></p><p><strong>本期使用的示例工作流在网盘：小黄瓜知识星球资料分享/插件节点讲解视频/ComfyUI_EasyUse/第二期文件夹中</strong></p><p><strong>一、ComfyUI重绘 （一）----VAE Encode (for Inpainting)节点</strong></p><p><strong>二、ComfyUI重绘 （二）----Set Latent Noise Mask节点</strong></p><p><strong>三、ComfyUI重绘 （三）----InpaintModelConditioning节点</strong></p><p><strong>四、ComfyUI重绘 （四）----ControlNet（inpainting模型）</strong></p><p><strong>五、ComfyUI重绘 （五）----Differential Diffusion节点</strong></p><p><strong>六、ImageCompositedMasked节点</strong></p><p><strong>七、Easy Use小技巧---EasyUse的管理组/XYplot Advanced节点/EasyUse的同类型节点替换</strong></p><h3 id="一、ComfyUI重绘-（一）-VAE-Encode-for-Inpainting-节点"><strong>一、ComfyUI重绘 （一）-----VAE Encode (for Inpainting)节点</strong></h3><p><strong>节点功能：节点用于将输入图像编码为潜在空间表示，以便在图像修复（Inpainting）任务中处理损坏或缺失的区域。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000797.png" alt="image"></p><p><strong>输入：</strong></p><p>pixels: 输入的图像</p><p>vae: 加载的 VAE 模型</p><p>mask: 修复区域的掩码图像</p><p><strong>参数：</strong></p><p>grow_mask_by: 扩展掩码区域的像素数量。扩大掩码区域，以确保边缘区域平滑过渡，避免修复区域和原图部分的割裂感。</p><p>首先，先加载默认的comfyui的图生图工作流，然后将图生图的__denoise__参数调为1，点击运行，得到结果如下图</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000798.png" alt="image"></p><p>然后我们将复制一个图生图工作流，并将其改成重绘工作流，因为这里我们主要讲解重绘节点的使用，所以这里我们只采用最简单的手绘选择蒙版的方式</p><p>首先在load image节点上，鼠标右键，选择__Open In SAM Detector__节点，并打开具体操作如下图所示：</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000799.png" alt="image"></p><p>在上图中，鼠标左键标记的蓝色点是选择图片中需要的部分，鼠标右键标记的红色点选择图片中不要的部分，Confidence是检测阈值，Detect是开始检测，Clear是清除标记点，当标记完成后点击detect即可完成检测，效果如下图所示，检测效果不是特别好， 但是没关系，这里我们点击右下角的Save to node即可。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000800.png" alt="image"></p><p>此时可以看到检测的蒙版部分已经传入到前图中，此时我们再鼠标右键选择Open In Editer，具体如下图所示</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000801.png" alt="image"></p><p>接下来，我们可以通过调节Thickness调节笔刷大小，Opacity调节不透明度进行手动涂抹，具体操作如下图所示</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000802.png" alt="image"></p><p>涂抹完成后，点击右下角的Save to Node即可完成手动蒙版绘制，如下图所示</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000803.png" alt="image"></p><p>最终效果如下图所示</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000804.png" alt="image"></p><p>然后我们对接__VAE Encode (for inpainting)节点__，点击运行，效果如下图</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000805.png" alt="image"></p><p>从图生图和局部重绘的对比中可以看出，<strong>重绘的本质就是从原本图生图工作流的重绘整个图片变为只重绘图片中蒙版区域的部分。</strong></p><p><strong>但是此时我们会注意到上图的一个问题，那就是重绘部分与非重绘部分的相关性很差，也就是没有很好的与原图融合，那么对于这个情况是因为什么产生的呢？</strong></p><p>这是因为我们选择的模型__不是重绘模型__，而是普通的sd15模型，普通的sd15往往只作用于单一区域部分的补足而不会参考整体图片，也就是非重绘部分，但重绘模型也就是inpainting的模型会参考整体图片部分，所以对于这种情况的重绘效果更好</p><p>此时我们选择加载一个inpainting的模型，如下图</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000806.png" alt="image"></p><p>然后运行下这个工作流如下图，可以看出此时重绘参考了整体图片的效果所以重绘效果很好。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000807.png" alt="image"></p><p>同时在__EasyUse__中我们可以使用更为简单的方式完成这个操作，我们加载EasyUse的重绘工作流如下图，点击运行，可以看出生成图片是完全一样的，且EasyUse的使用方式更加便捷。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000808.png" alt="image"></p><p><strong>那么这个时候我们可能会有另外一个问题，那就是如果我们想要使用的模型不是inpaint模型而且作者也没有提供inpaint模型的版本，这个时候我们应该怎么去做呢？</strong></p><p>我们可以自己去__制作重绘模型__，这里以SD1.5的模型为例，让我们加载制作重绘模型工作流，如下图所示</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000809.png" alt="image"></p><p>通过上图可以看出这个工作流先是用SD1.5的标准的inpaint模型-普通模型，然后将获得的重绘部分与我们想要使用的非重绘模型混合，最后保存为新的模型，这样我们就可以得到我们想要用的模型的inpaint版本，模型默认保存的路径如下图所示</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000810.png" alt="image"></p><p>使用新的inpaint模型的重绘效果如下图所示，可以看出还是不错的</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000811.png" alt="image"></p><p>但是要注意的是这种模型虽然重绘效果比原模型好很多，但是对比作者专门提供的训练版本的inpaint的模型效果还是要差一些的，所有如果有选择的话最好还是使用作者提供的inpaint模型</p><p><strong>小总结：使用VAE Encode (for inpainting)节点注意两点：</strong></p><p>1、使用模型需要是inpainting模型；</p><p>2、denoise权重通常设置为1</p><h3 id="二、ComfyUI重绘-（二）-Set-Latent-Noise-Mask节点"><strong>二、ComfyUI重绘 （二）-----Set Latent Noise Mask节点</strong></h3><p><strong>节点功能：该节点用于在潜在空间中对特定区域添加噪声掩码。该节点的主要作用是在生成或修复过程中，通过掩码区域引入随机噪声，从而影响图像生成或修复效果，常用于图像修复（Inpainting）或局部生成任务。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000812.png" alt="image"></p><p><strong>输入：</strong></p><p>samples: 潜在表示数据，通常是通过 VAE 编码得到的潜在空间样本</p><p>mask: 二值掩码图像，表示在哪些区域引入噪声</p><p><strong>经过上一个的重绘后此时我们会想，如果我们想要更接近原图人物的重绘此时怎么做呢？</strong></p><p>下面让我们去加载__Set Latent Noise Mask节点__的重绘工作流，我们想要的是蒙版中的人从男人变成女人，这里我们使用了inpainting模型，如下图所示，效果不是很好，角色变动不大。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000813.png" alt="image"></p><p>此时我们需要将inpainting模型换成正常sd15模型且denoise调节为0.65，再运行下效果，此时效果比之前好上很多，且得到的效果的人物姿态等也更接近原图。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000814.png" alt="image"></p><p><strong>但是此时我们可以会考虑为什么前一种重绘方式使用inpainting模型效果更好，而后一种重绘方式使用普通的模型效果更好？</strong></p><p>下面让我们将两者重绘方式的denoise的强度调整成0.1，然后运行，将会看出背后的区别，如下图</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000815.png" alt="image"></p><p>通过上图，我们可以看出__这是因为它们的蒙版区域部分的初始噪声不一样。__</p><p><strong>但是此时我们可以会考虑为什么前一种重绘方式使用inpainting模型效果更好，而后一种重绘方式使用普通的模型效果更好？</strong></p><p>重绘方式一（<strong>使用VAE Encode (for Inpainting)节点</strong>）是以空的蒙版区域作为初始噪声加入，所以在原模型没有束缚的情况下效果不好，而使用inpainting的模型效果更好。</p><p>重绘方式二（<strong>使用传统VAE Encode节点+Set Latent Noise Mask节点</strong>）使用原先蒙版区域的男人站立图作为初始噪声加入，由于在初始噪声部分已经参考了原先蒙版区域的图片，而使用inpainting会造成强度过大导致难以进行蒙版区域重绘大幅度改变的情况，所以使用原始模型会更好。</p><p>然后我们在EasyUse中实现这个重绘工作流，点击运行，如下图可以看出生成图片是完全一样的，且EasyUse的使用方式更加便捷。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000816.png" alt="image"></p><p><strong>小总结：使用Set Latent Noise Mask节点注意两点：</strong></p><p>1、使用模型需要是普通模型而不是inpainting模型；</p><p>2、denoise权重通常设置为较低值，比如0.6或者以下</p><h3 id="三、ComfyUI重绘-（三）-InpaintModelConditioning节点"><strong>三、ComfyUI重绘 （三）----InpaintModelConditioning节点</strong></h3><p><strong>节点功能：该节点用于在图像修复（Inpainting）任务中，将潜在表示（latent space）与文本提示（text prompts）和掩码相结合，为扩散模型提供条件输入。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000817.png" alt="image"></p><p><strong>输入：</strong></p><p>positive: 正向文本提示，用于引导模型生成目标区域期望的内容。</p><p>negative: 负向文本提示，指定模型在生成过程中要避免的特征或内容。</p><p>vae: VAE 编码器生成的潜在表示。</p><p>pixels: 原始图像像素数据。</p><p>mask: 修复掩码图像，标记需要修复或重绘的区域。</p><p>然后加载一个使用这个节点的工作流点击运行，对比于重绘方式三（<strong>使用传统VAE Encode节点+Set Latent Noise Mask节点</strong>）的工作流，可以看到两者生成的图片完全一致。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000818.png" alt="image"></p><p><strong>但是这是否意味这两种方法也完全一致呢？</strong></p><p>实际上并不是，此时如果我们将使用__InpaintModelConditioning节点__的工作流的模型换成inpainting模型将很清晰的看出它们直接的差别，如下图</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000819.png" alt="image"></p><p>可以看出换成inpainting模型后，使用InpaintModelConditioning的重绘方式并不会像Set Noise重绘方式一样进行极强的控制导致几乎无法重绘，而是产生了一种介于使用set Noise的非重绘模型方式和Set Noise使用重绘模型方式之间的一种控制，且这种控制更加集中于人物面部。</p><p>然后我们在EasyUse实现InpaintModelConditioning的重绘，如下图，这里仅仅是将__additional__的参数调整为__InpaintModelCond__即可实现，这极大的提升了工作效率。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000820.png" alt="image"></p><p><strong>小总结：使用InpaintModelConditioning节点注意两点：</strong></p><p>1、当使用普通模型时候，其效果和要点与使用Set Latent Noise Mask是一样的；</p><p>2、当使用inpainting模型时，重绘强度介于Set Noise（inpainting模型）与Set Noise（普通模型）之前，且更关注于人物面部</p><h3 id="四、ComfyUI重绘（四）—ControlNet（inpainting模型）"><strong>四、ComfyUI重绘（四）—ControlNet（inpainting模型）</strong></h3><p>关于controlnet的重绘模型，相信经常使用webUI的使用者一定不会陌生，这里我们直接就在EasyUse里面使用controlnet的inpainting模型进行讲解</p><p>让我们加载EasyUse的controlnet的重绘工作流，并点击运行如下图，可以看出EasyUse的controlnet的重绘效果对比上面三种方式是最不好的一种，所以在实际使用时候就排除这种方式了。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000821.png" alt="image"></p><h3 id="五、ComfyUI的重绘（五）-Differential-Diffusion节点"><strong>五、ComfyUI的重绘（五）----Differential Diffusion节点</strong></h3><p>关于differential diffusion也就是差分扩散框架可能有很多人并不了解，它是一个可以集成到我们现在所有扩散模型（也就是我们常说的绘图大模型）的框架，可以帮助我们在重绘时，可以更加精细的控制图像内像素的变化，同时使变化部分与原图其余部分确保更加无缝合成。</p><p>下面让我们在comfyui中加载__differenital diffusion节点__，如下图，该节点就是调用differential diffusion框架的节点，用法很简单只需要把该节点插入绘图模型和采样器的中间即可</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000822.png" alt="image"></p><p>下面让我们加载一个使用差分扩散和不使用差分扩散的对比工作流，来更清晰的认识这个框架起到的作用，点击运行，如下图所示</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000823.png" alt="image"></p><p>这里，我们选择让马的图片蒙版部分变成羽毛，让我们放大结果图片进行细致分析</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000824.png" alt="image"></p><p>通过上图的图片可以看出我们常用的三种方式中，__加了differential diffusion__后，其效果明显更好，比如在马的腹部羽毛的细致度增加了不少，同时蒙版部分与原图的接缝处也进行了更好的融合。</p><p>但是我们可能会注意到在__使用Vae Inpainting的重绘模型方式的条件下这种方式并不起到作用__，如下图所示，这是什么原因造成的呢？</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000825.png" alt="image"></p><p>通过我们对Vae Inpainting前面的分析可以知道，__Vae Inpainting与其它重绘方式最大区别__在于其重绘部分的初始噪声是空的蒙版区域产生，而其它的则是蒙版区域原有图片产生的，这导致了差分扩散效果无效的原因</p><p>下面我们用EasyUse来实现上面的差分扩散效果，让我们加载EasyUse的差分扩散工作流，可以看到在EasyUse中实现InpaintModelCond的差分十分简单，仅仅需要在EasyKsampler（inpainting）节点选择differential diffusion即可。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000826.png" alt="image"></p><h3 id="六、ImageCompositedMasked节点"><strong>六、ImageCompositedMasked节点</strong></h3><p><strong>节点功能：该节点设计用于组合图像，允许将源图像覆盖在目标图像上，在指定坐标处进行叠加，可选择调整大小和使用遮罩。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000827.png" alt="image"></p><p><strong>输入：</strong></p><p>destination: 目标图像，源图像将组合在此图像上。它作为组合操作的背景。</p><p>source: 要组合到目标图像上的源图像。此图像可以选择性地调整大小以适应目标图像的尺寸。</p><p>mask: 一个可选的遮罩，指定应将源图像的哪些部分组合到目标图像上。这允许进行更复杂的组合操作，如混合或部分叠加。</p><p>x: 在目标图像中，源图像左上角放置的x坐标。</p><p>y: 在目标图像中，源图像左上角放置的y坐标。</p><p>resize_source: 一个布尔标志，指示是否应调整源图像的尺寸以匹配目标图像的尺寸。</p><p><strong>虽然经过上述重绘方式我们已经可以实现一个还不错的效果，但我们应该会注意到一个问题，那就是即使我们选择只重绘蒙版区域但是实际上的出图结果也带来了其它区域的变化，这个是因为什么产生的呢？</strong></p><p>是因为图片经过VAE 编码再解码产生的像素损失，差异效果如下图，红框部分就是两图的区别</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000828.png" alt="image"></p><p>那个对于这个问题我们有没有什么好的解决方案呢？</p><p>答案是有的，我们可以使用ImageCompositedMasked节点，如下图</p><p>这个节点的作用是将两张图片根据蒙版进行重叠，其中destination是底层图片，source是顶层图片，mask是作用于顶层图片的蒙版，这样我们就可以将原图放在底层，重绘后的图片放在顶层，再通过蒙版叠加即可保证重绘外的区域与原图保持一致</p><p>下面我们可以根据这个节点，加载如下工作流，如下图所示</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000829.png" alt="image"></p><p>从上图中可以看到经过这个处理后，图片重绘外的区域不会再出现改变了</p><h3 id="七、Easy-Use小技巧-EasyUse的管理组-XYplot-Advanced节点-EasyUse的同类型节点替换"><strong>七、Easy Use小技巧---EasyUse的管理组/XYplot Advanced节点/EasyUse的同类型节点替换</strong></h3><p>接下来，让我们进行今天最后的部分EasyUse的Tips讲解</p><p><strong>1、 EasyUse的管理组</strong></p><p>在空白部分鼠标右键进行选择EasyUse的管理组即可</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000830.png" alt="image"></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000831.png" alt="image"></p><p><strong>但需要注意的是EasyUse的管理组，需要你在工作流里建立组（Group）才能起作用，主要功能就是，我们可以通过管理组去禁用我们当前不需要运行的组或者直接跳转到对应的组的位置。</strong></p><p><strong>2. XYplot Advanced节点</strong></p><p><strong>节点功能：是一个用于在图像生成过程中执行批量参数对比和可视化的节点。通过该节点，用户可以快速生成一组图像，对不同参数的影响进行直观的对比和分析。例如，可以调整参数（如种子、提示词、CFG 比例、采样步骤等），并在同一个网格中呈现这些调整对生成结果的影响。</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000832.png" alt="image"></p><p><strong>参数：</strong></p><p>Grid_spacing：设置Xyplot中每张图片的间隔</p><p>Output_individuals：是否分别输出每张图片，这个主要是在保存图片中使用，如果选择false就会只保存一张总体XYPlot图，如果选择true则会将其中每张图片以及总体XYPlot都分别进行保存</p><p>Flip_xy: 是否反转X、Y的坐标轴</p><p>然后我们这里以不同的步数为X轴，不同CFG为Y轴，如下图所示，XYPlot帮我们以参数的不同匹配去生成所有的图片，然后我们根据结果去选择最符合我们要求的图片</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000833.png" alt="image"></p><p><strong>3、 EasyUse的同类型节点替换</strong></p><p>首先加载一个简单的EasyUse文生图工作流，然后在PreSampling节点上右键选择Swap EasyPreSampling即可选择替换的同类型节点，具体操作如下图所示</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000834.png" alt="image"></p><p>这里我们选择第一个，最终效果如下图所示</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000835.png" alt="image"></p><p>可以看出这很方便我们随时切换节点，节省了多余的操作时间</p><p>__ComfyUI Easy Use插件（一）: __<a href="https://t.zsxq.com/AAZQm"><strong>https://articles.zsxq.com/easyuse/1.html</strong></a></p><p>__ComfyUI Easy Use插件（三）: __<a href="https://t.zsxq.com/UsFSp"><strong>https://articles.zsxq.com/easyuse/3.html</strong></a></p><p>__ComfyUI Easy Use插件（四）: __<a href="https://t.zsxq.com/gSJA1"><strong>https://articles.zsxq.com/easyuse/4.html</strong></a></p><p>__ComfyUI Easy Use插件（五）: __<a href="https://t.zsxq.com/IAye6"><strong>https://articles.zsxq.com/easyuse/5.html</strong></a></p><p>__ComfyUI Easy Use插件（六）: __<a href="https://t.zsxq.com/PhouI"><strong>https://articles.zsxq.com/easyuse/6.html</strong></a></p><p>__ComfyUI Easy Use插件（七）: __<a href="https://t.zsxq.com/jDjyM"><strong>https://articles.zsxq.com/easyuse/7.html</strong></a></p><p>__ComfyUI Easy Use插件（八）: __<a href="https://t.zsxq.com/UXZK4"><strong>https://articles.zsxq.com/easyuse/8.html</strong></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本节主要是将comfyui的原生重绘工作流与EasyUse重绘工作流进行对比讲解，帮助大家更好的理解不同重绘方式之间的差别（&lt;strong&gt;主要描述了各种不同的重绘方式&lt;/strong&gt;）。&lt;/p&gt;
&lt;p&gt;__Comf</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
  <entry>
    <title>【ComfyUI插件】ComfyUI Easy Use插件（五）</title>
    <link href="https://www.fomal.cc/posts/26d72e3a.html"/>
    <id>https://www.fomal.cc/posts/26d72e3a.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.326Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言："><strong>前言：</strong></h2><p>该插件由B站大佬乱乱呀AI进行开发出来的，此插件主要在使用管道、简化工作流、提供简便工具和集成化等方面起到了明显作用。</p><p>__ComfyUI Easy Use插件（一）: __<a href="https://t.zsxq.com/AAZQm"><strong>https://articles.zsxq.com/easyuse/1.html</strong></a></p><p>__ComfyUI Easy Use插件（二）: __<a href="https://t.zsxq.com/lNdvT"><strong>https://articles.zsxq.com/easyuse/2.html</strong></a></p><p>__ComfyUI Easy Use插件（三）: __<a href="https://t.zsxq.com/UsFSp"><strong>https://articles.zsxq.com/easyuse/3.html</strong></a></p><p>__ComfyUI Easy Use插件（四）: __<a href="https://t.zsxq.com/gSJA1"><strong>https://articles.zsxq.com/easyuse/4.html</strong></a></p><p>__ComfyUI Easy Use插件（六）: __<a href="https://t.zsxq.com/PhouI"><strong>https://articles.zsxq.com/easyuse/6.html</strong></a></p><p>__ComfyUI Easy Use插件（七）: __<a href="https://t.zsxq.com/jDjyM"><strong>https://articles.zsxq.com/easyuse/7.html</strong></a></p><p>__ComfyUI Easy Use插件（八）: __<a href="https://t.zsxq.com/UXZK4"><strong>https://articles.zsxq.com/easyuse/8.html</strong></a></p><p><strong>本期使用的示例工作流在网盘：小黄瓜知识星球资料分享/插件节点讲解视频/ComfyUI_EasyUse/第五期文件夹中</strong></p><h2 id="目录"><strong>目录</strong></h2><p><strong>先行：安装方法</strong></p><p><strong>一、Easy Apply IPAdapter节点</strong></p><p><strong>二、PromptLine节点</strong></p><p><strong>三、Easy Apply IPAdapter (Advanced)节点</strong></p><p><strong>四、PromptConcat节点</strong></p><p><strong>五、Easy Apply IPAdapter (Regional)节点</strong></p><p><strong>六、PromptList节点</strong></p><p><strong>七、Image To Prompt节点</strong></p><p><strong>八、imageCropFromMask节点</strong></p><p><strong>九、imageUncropFromBBOX节点</strong></p><p><strong>十、Make Image For ICLora节点</strong></p><p><strong>十一、Image Color Match节点</strong></p><p><strong>本节中更多关于ipadapter的细节示例，大家可跳转：b站：</strong><a href="https://www.bilibili.com/video/BV1cD6mY1EkG/?spm_id_from=333.1387.homepage.video_card.click&amp;vd_source=a094ccbb295024c38e35635c7a510660"><strong>啦啦啦的小黄瓜</strong></a></p><h2 id="安装方法"><strong>安装方法</strong></h2><p>安装方法，一共有2种</p><p><strong>1、在manager里搜索Easy Use，然后点击安装第3个即可</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000836.png" alt="image"></p><p>__2、在custom_nodes目录下调用cmd，然后输入git clone __<a href="https://github.com/yolain/ComfyUI-Easy-Use.git"><strong>https://github.com/yolain/ComfyUI-Easy-Use.git</strong></a></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000837.png" alt="image"></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000838.png" alt="image"></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000839.png" alt="image"></p><p><strong>项目地址：</strong><a href="https://github.com/yolain/ComfyUI-Easy-Use.git"><strong>https://github.com/yolain/ComfyUI-Easy-Use.git</strong></a></p><h3 id="一、Easy-Apply-IPAdapter节点"><strong>一、Easy Apply IPAdapter节点</strong></h3><p><strong>节点功能：提供ipadapter模型使用的基本节点</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000840.png" alt="image"></p><p><strong>输入：</strong></p><p>model -&gt; 输入的模型</p><p>image -&gt; 输入的参考图片</p><p>attn_mask -&gt; 输入的图片蒙版</p><p>optional_ipadapter -&gt; 可选择输入的ipadapter模型</p><p><strong>参数：</strong></p><p>preset -&gt; 选择合适的ipadapter模型，按需选择即可</p><p>weight -&gt; 设置选择的ipadapter模型的权重</p><p>start_at -&gt; 输入的ipadapter模型起始作用的时间，默认0代表从最开始就开始作用</p><p>end_at -&gt; 输入的ipadapter模型结束作用的时间，默认1代表作用到最后</p><p>cache_mode -&gt; 选择模型加载到缓存，分为insightface only（只加载insightface模型）、clip_vision only（只加载clip模型）、ipadapter only（只加载ipadapter模型）、all（全加载）、none（不加载）</p><p>use_tiled -&gt; 是否对输入的参考图片使用tile进行分割图片，对于不是正方形的图片的全图参考可开启</p><p><strong>输出：</strong></p><p>model -&gt; 输出经过ipadapter模型调节后的模型</p><p>images -&gt; 输出的参考图片</p><p>masks -&gt; 输出的蒙版</p><p>ipadapter -&gt; 输出的ipadapter模型</p><p>其中LIGHT，STANDARD，PLUS（low, medium,high strength)代表对人物主体控制越来越强，如下图，LIGHT模型所生成的图和原图相比差别很大，而PLUS基本和原图一致，只是大模型的风格不一样。在使用绿色group中模型时， 模型会调用人脸检测模型，并进行裁剪和调正。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000841.png" alt="image"></p><h3 id="二、PromptLine节点"><strong>二、PromptLine节点</strong></h3><p><strong>节点功能：对于节点参数是字符串的节点，进行获取其对应的字符串参数名，一般用于批量遍历节点里的字符串参数使用</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000842.png" alt="image"></p><p><strong>参数：</strong></p><p>text -&gt; 输入的参数值的字符串，可手动输入，也可通过点击下面的get values from COMBO link自动获取</p><p>start_index -&gt; 设置输出的参数的起始序列值</p><p>max_rows -&gt; 设置输出的最大行数</p><p>get values from COMBO link -&gt; 点击可获取连接节点的参数中的字符串变量</p><p>STRING -&gt; 输出获取的参数字符串值</p><p>COMBO -&gt; 用于连接节点的参数类型为字符串的参数</p><p>如下图所示，提示词中只有1gril和1boy，当__start_index__=0时，模型不仅会根据提示词生成对应图片，还会默认生成一张没有提示词的图片，当__start_index__=1后，模型只会生成和提示词匹配的图片。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000843.png" alt="image"></p><h3 id="三、Easy-Apply-IPAdapter-Advanced-节点"><strong>三、Easy Apply IPAdapter (Advanced)节点</strong></h3><p><strong>节点功能：提供ipadapter模型使用的高级节点</strong><img src="https://xiao666.sbs/PicGo/IMG_000000844.png" alt="image"></p><p><strong>输入：</strong></p><p>model -&gt; 输入的模型</p><p>image -&gt; 输入的正向参考图片</p><p>image_negative -&gt; 输入的负向参考图片</p><p>attn_mask -&gt; 输入的图片蒙版</p><p>clip_vision -&gt; 输入的clip模型</p><p>optional_ipadapter -&gt; 可选择输入的ipadapter模型</p><p><strong>参数：</strong></p><p>preset -&gt; 选择合适的ipadapter模型，按需选择即可</p><p>weight -&gt; 设置选择的ipadapter模型的权重</p><p>weight_type -&gt; 设置的ipadapter模型权重类型，这个参数决定了权重在模型的不同层中应用的方式，分为linear、ease in、ease out、ease in-out、reverse in-out、weak input、weak output、weak middle、strong middle、style transfer、composition、strong style transfer、style and composition、style transfer precise，具体差别可参考工作流图片</p><p>combine_embeds -&gt; 在输入的多个参考图片使用的结合嵌入方式,分为concat、add、subtract、average、norm average</p><p>start_at -&gt; 输入的ipadapter模型起始作用的时间，默认0代表从最开始就开始作用</p><p>end_at -&gt; 输入的ipadapter模型结束作用的时间，默认1代表作用到最后</p><p>embeds_scaling -&gt; 分为V only、K+V、K+V w/C penalty、K+mean(V) w/C penalty，决定了嵌入在模型内的缩放或组合方式</p><p>cache_mode -&gt; 选择模型加载到缓存，分为insightface only（只加载insightface模型）、clip_vision only（只加载clip模型）、ipadapter only（只加载ipadapter模型）、all（全加载）、none（不加载）</p><p>use_tiled -&gt; 是否对输入的参考图片使用tile进行分割图片，对于不是正方形的图片的全图参考可开启</p><p>use_batch -&gt; 是否使用batch进行批量图片处理</p><p>Mad Scientist Layer Weights -&gt; 设置ipadapter模型里的每个层的权重</p><p>如下图，该工作流使用了不同weight_type加载权重，从而产生不同风格的图片。</p><h3 id="image"><img src="https://xiao666.sbs/PicGo/IMG_000000845.png" alt="image"></h3><h3 id="四、PromptConcat节点"><strong>四、PromptConcat节点</strong></h3><p><strong>节点功能：将2个提示词合成为1个提示词</strong><img src="https://xiao666.sbs/PicGo/IMG_000000846.png" alt="image"></p><p><strong>参数：</strong></p><p>prompt1 -&gt; 输入的提示词1</p><p>prompt2 -&gt; 输入的提示词2</p><p>separator -&gt; 输入的提示词相连符号</p><p>prompt -&gt; 输出合成后的提示词</p><p>如下图所示，将两个提示词合并成一个提示词并出输出。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000847.png" alt="image"></p><h3 id="五、Easy-Apply-IPAdapter-Regional-节点"><strong>五、Easy Apply IPAdapter (Regional)节点</strong></h3><p><strong>节点功能：提供使用的ipadapter区域作用节点</strong><img src="https://xiao666.sbs/PicGo/IMG_000000848.png" alt="image"></p><p><strong>输入：</strong></p><p>pipe -&gt; 输入的管道</p><p>image -&gt; 输入的区域控制图片</p><p>mask -&gt; 输入的在区域控制图片中作用的蒙版</p><p>optional_ipadapter_params -&gt; 可选择输入的ipadapter参数</p><p><strong>参数：</strong></p><p>positive -&gt; 输入的正向提示词</p><p>negative -&gt; 输入的负向提示词</p><p>image_weight -&gt; 设置图片作用的权重</p><p>prompt_weight -&gt; 设置提示词作用的权重</p><p>weight_type -&gt; 输入的模型作用权重类型，按需选择即可</p><p>start_at -&gt; 输入的ipadapter模型起始作用的时间，默认0代表从最开始就开始作用</p><p>end_at -&gt; 输入的ipadapter模型结束作用的时间，默认1代表作用到最后</p><p>如下图，模型只对mask区域起作用。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000849.png" alt="image"></p><h3 id="六、PromptList节点"><strong>六、PromptList节点</strong></h3><p><strong>节点功能：提供的提示词列表，用于多个提示词输入展示不同的效果</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000850.png" alt="image"></p><p><strong>参数：</strong></p><p>optional_prompt_list -&gt; 输入的提示词列表</p><p>prompt_1 -&gt; 输入的提示词1</p><p>prompt_2 -&gt; 输入的提示词2</p><p>prompt_3 -&gt; 输入的提示词3</p><p>prompt_4 -&gt; 输入的提示词4</p><p>prompt_5 -&gt; 输入的提示词5</p><p>prompt_line -&gt; 输出的提示词列表</p><p>prompt_strings -&gt; 输出的提示词字符串</p><p>如下图，同时输入不同的提示词列表以及同时生成对应的一批图片</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000851.png" alt="image"></p><h3 id="七、Image-To-Prompt节点"><strong>七、Image To Prompt节点</strong></h3><p><strong>节点功能：将输入的图片推导出对应的提示词</strong><img src="https://xiao666.sbs/PicGo/IMG_000000852.png" alt="image"></p><p><strong>参数：</strong></p><p>image -&gt; 输入的图片</p><p>mode -&gt; 推导提示词的模式，分为fast、classic、best、negative四种，一般选择fast即可</p><p>use_lowvram -&gt; 是否使用低显存模式</p><p>prompt -&gt; 输出推导出的提示词</p><p>其中__best__模式反推的效果最好，__negative__表现最差。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000853.png" alt="image"></p><h3 id="八、imageCropFromMask节点"><strong>八、imageCropFromMask节点</strong></h3><p><strong>节点功能：该节点是一个用于从图像和掩码中裁剪区域的节点。它根据掩码中的非零像素确定感兴趣区域（ROI）的边界框，并在指定的裁剪比例和平滑参数下裁剪图像和掩码。此外，该节点支持对边界框的大小和中心点进行平滑处理，以实现更稳定的裁剪效果。</strong><img src="https://xiao666.sbs/PicGo/IMG_000000854.png" alt="image"></p><p><strong>输入：</strong></p><p>image -&gt; 输入的图片</p><p>mask -&gt; 输入的图片蒙版</p><p><strong>参数：</strong></p><p>image_crop_multi -&gt; 设置输入图片裁剪的比例</p><p>mask_crop_multi -&gt; 设置输入图片蒙版裁剪的比例</p><p>bbox_smooth_alpha -&gt; 设置图片和蒙版裁剪的共同的裁剪乘积比例系数</p><p><strong>输出：</strong></p><p>crop_image -&gt; 输出裁剪的图片</p><p>crop_mask -&gt; 输出的裁剪的图片蒙版</p><p>bbox -&gt; 输出的裁剪参数</p><p>第二个工作流和第三个工作流参数不一样，但裁剪的图片是一样的，但事实上__image_crop_multi*bbox_smooth_alpha__和__mask_crop_multi*bbox_smooth_alpha__是一样的，故两者裁剪的图片一样。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000855.png" alt="image"></p><h3 id="九、imageUncropFromBBOX节点"><strong>九、imageUncropFromBBOX节点</strong></h3><h3 id="节点功能：将裁剪的图片还原到原图中image"><strong>节点功能：将裁剪的图片还原到原图中</strong><img src="https://xiao666.sbs/PicGo/IMG_000000856.png" alt="image"></h3><p><strong>输入：</strong></p><p>original_image -&gt; 输入的原图</p><p>crop_image -&gt; 输入的裁剪图片</p><p>bbox -&gt; 输入的裁剪参数</p><p>optional_mask -&gt; 输入的蒙版，当use_square_mask为false时，需要输入</p><p><strong>参数：</strong></p><p>border_blending -&gt; 设置将裁剪的图片还原到原图中的边缘融合比例</p><p>use_square_mask -&gt; 是否使用方形蒙版</p><p><strong>输出：</strong></p><p>image -&gt; 输出还原后的图片</p><p><strong>border_blending__越大，融合效果越好，如下图：当__border_blending</strong>=0.5时，图片上有正方形的边框。<strong>需要注意的是，当use_square_mask为false时，一定要输入optional_mask，否则会报错。</strong></p><h3 id="image-2"><img src="https://xiao666.sbs/PicGo/IMG_000000857.png" alt="image"></h3><h3 id="十、Make-Image-For-ICLora节点"><strong>十、Make Image For ICLora节点</strong></h3><p><strong>节点功能：制作符合In Context Lora的图片</strong><img src="https://xiao666.sbs/PicGo/IMG_000000858.png" alt="image"></p><p><strong>输入：</strong></p><p>image_1 -&gt; 输入的图片1</p><p>image_2 -&gt; 输入的图片2</p><p>mask_1 -&gt; 输入的图片1的蒙版</p><p>mask_2 -&gt; 输入的图片2的蒙版</p><p><strong>参数：</strong></p><p>direction -&gt; 设置图片摆放的位置，分为top-bottom和left-right</p><p>pixels -&gt; 设置生成图片的最小边长，当为0时，维持输入的原有图片的边长</p><p><strong>输出：</strong></p><p>image -&gt; 输出的合成图片</p><p>mask -&gt; 输出的合成蒙版</p><p>context_mask -&gt; 输出的上下文蒙版</p><p>width -&gt; 输出图片的宽</p><p>height -&gt; 输出图片的高</p><p>x -&gt; 输出第二张图片位于合成图片的x坐标</p><p>y -&gt; 输出第二张图片位于合成图片的y坐标</p><p><strong>更多关于 ICLora的介绍以及操作，可跳转b站：</strong><a href="https://www.bilibili.com/video/BV1T8UKYtE5m/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=fc308fafd0eb9d759dccb9a42d40ae6c"><strong>啦啦啦的小黄瓜</strong></a></p><h3 id="image-3"><img src="https://xiao666.sbs/PicGo/IMG_000000859.png" alt="image"></h3><h3 id="十一、Image-Color-Match节点"><strong>十一、Image Color Match节点</strong></h3><p><strong>节点功能：将输入的图片根据参考图片进行颜色参考</strong><img src="https://xiao666.sbs/PicGo/IMG_000000860.png" alt="image"></p><p><strong>输入：</strong></p><p>image_ref -&gt; 输入的参考图片</p><p>image_target -&gt; 输入的目标图片</p><p><strong>参数：</strong></p><p>method -&gt; 设置的图片颜色匹配方式，分为wavelet、adain、mkl、hm、reinhard、mvgd、hm-mvgd-hm、hm-mkl-hm</p><p>image_output -&gt; 设置图片输出方式</p><p>根据参考图的颜色以不同的方式进行颜色融合。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000861.png" alt="image"></p><p>__ComfyUI Easy Use插件（一）: __<a href="https://t.zsxq.com/AAZQm"><strong>https://articles.zsxq.com/easyuse/1.html</strong></a></p><p>__ComfyUI Easy Use插件（二）: __<a href="https://t.zsxq.com/lNdvT"><strong>https://articles.zsxq.com/easyuse/2.html</strong></a></p><p>__ComfyUI Easy Use插件（三）: __<a href="https://t.zsxq.com/UsFSp"><strong>https://articles.zsxq.com/easyuse/3.html</strong></a></p><p>__ComfyUI Easy Use插件（四）: __<a href="https://t.zsxq.com/gSJA1"><strong>https://articles.zsxq.com/easyuse/4.html</strong></a></p><p>__ComfyUI Easy Use插件（六）: __<a href="https://t.zsxq.com/PhouI"><strong>https://articles.zsxq.com/easyuse/6.html</strong></a></p><p>__ComfyUI Easy Use插件（七）: __<a href="https://t.zsxq.com/jDjyM"><strong>https://articles.zsxq.com/easyuse/7.html</strong></a></p><p>__ComfyUI Easy Use插件（八）: __<a href="https://t.zsxq.com/UXZK4"><strong>https://articles.zsxq.com/easyuse/8.html</strong></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前言：&quot;&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;该插件由B站大佬乱乱呀AI进行开发出来的，此插件主要在使用管道、简化工作流、提供简便工具和集成化等方面起到了明显作用。&lt;/p&gt;
&lt;p&gt;__ComfyUI Easy Use插件（一）: __&lt;a h</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
  <entry>
    <title>【ComfyUI插件】ComfyUI Easy Use插件（八）</title>
    <link href="https://www.fomal.cc/posts/66b23a3f.html"/>
    <id>https://www.fomal.cc/posts/66b23a3f.html</id>
    <published>2025-02-17T09:14:12.000Z</published>
    <updated>2025-02-17T09:25:39.327Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言："><strong>前言：</strong></h2><p>该插件由B站大佬乱乱呀AI进行开发出来的，此插件主要在使用管道、简化工作流、提供简便工具和集成化等方面起到了明显作用。</p><h2 id="目录"><strong>目录</strong></h2><p><strong>先行：安装方法</strong></p><p><strong>一、Portrait Master节点</strong></p><p><strong>二、PreSampling (DynamicCFG)节点</strong></p><p><strong>三、InjectNoiseToLatent节点</strong></p><p><strong>四、Pipe Edit Prompt节点</strong></p><p><strong>五、Math String节点</strong></p><p><strong>六、Image Detail Transfer节点</strong></p><p><strong>七、Easy Apply ICLight节点</strong></p><p><strong>八、Math Float/Convert Any节点</strong></p><p><strong>九、LatentCompositeMaskedWithCond节点</strong></p><p><strong>十、If else节点</strong></p><p>__ComfyUI Easy Use插件（一）: __<a href="https://t.zsxq.com/AAZQm"><strong>https://articles.zsxq.com/easyuse/1.html</strong></a></p><p>__ComfyUI Easy Use插件（二）: __<a href="https://t.zsxq.com/lNdvT"><strong>https://articles.zsxq.com/easyuse/2.html</strong></a></p><p>__ComfyUI Easy Use插件（三）: __<a href="https://t.zsxq.com/UsFSp"><strong>https://articles.zsxq.com/easyuse/3.html</strong></a></p><p>__ComfyUI Easy Use插件（四）: __<a href="https://t.zsxq.com/gSJA1"><strong>https://articles.zsxq.com/easyuse/4.html</strong></a></p><p>__ComfyUI Easy Use插件（五）: __<a href="https://t.zsxq.com/IAye6"><strong>https://articles.zsxq.com/easyuse/5.html</strong></a></p><p>__ComfyUI Easy Use插件（六）: __<a href="https://t.zsxq.com/PhouI"><strong>https://articles.zsxq.com/easyuse/6.html</strong></a></p><p>__ComfyUI Easy Use插件（七）: __<a href="https://t.zsxq.com/jDjyM"><strong>https://articles.zsxq.com/easyuse/7.html</strong></a></p><p><strong>本期使用的示例工作流在网盘：小黄瓜知识星球资料分享/插件节点讲解视频/ComfyUI_EasyUse/第八期文件夹中</strong></p><h2 id="安装方法"><strong>安装方法</strong></h2><p>安装方法，一共有2种</p><p><strong>1、在manager里搜索Easy Use，然后点击安装第3个即可</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000862.png" alt="image"></p><p>__2、在custom_nodes目录下调用cmd，然后输入git clone __<a href="https://github.com/yolain/ComfyUI-Easy-Use.git"><strong>https://github.com/yolain/ComfyUI-Easy-Use.git</strong></a></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000863.png" alt="image"></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000864.png" alt="image"></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000865.png" alt="image"></p><p><strong>项目地址：</strong><a href="https://github.com/yolain/ComfyUI-Easy-Use.git"><strong>https://github.com/yolain/ComfyUI-Easy-Use.git</strong></a></p><h3 id="一、Portrait-Master节点"><strong>一、Portrait Master节点</strong></h3><p><strong>节点功能：提供各种肖像参数来输出关于人物肖像的正向和负向提示词</strong><img src="https://xiao666.sbs/PicGo/IMG_000000866.png" alt="image"></p><p><strong>参数：</strong></p><p>shot：设置镜头，分为-（空）、Head portrait（头像）、Head and shoulders portrait（头肩肖像）、Half-length portrait（半身像）、Full-length portrait（全身像）、Face（脸部）、Portrait（肖像）、Full body（全身）、Close-up（特写）</p><p>shot_weight：设置镜头提示词权重</p><p>gender：设置性别，分为-（空）、Man（男人）、Woman（女人）</p><p>age：设置年龄</p><p>nationality_1：设置国籍1，按需选择即可</p><p>nationality_2：设置国籍2，按需选择即可</p><p>nationality_mix：设置两个国籍的混合比例</p><p>body_type：设置人的体态</p><p>body_type_weight：设置人的体态的权重</p><p>model_pose：设置模特姿势，</p><p>eyes_color：设置眼睛颜色，</p><p>facial_expression_weight：设置脸部表情权重</p><p>face_shape：设置脸型</p><p>face_shape_weight：设置脸型权重</p><p>facial_asymmetry：设置面部不对称权重</p><p>hair_style：设置发型，按需选择即可</p><p>hair_color：设置头发颜色</p><p>disheveled：设置头发蓬松权重</p><p>beard：设置胡须，按需选择即可</p><p>skin_details：设置皮肤细节权重</p><p>skin_pores：设置皮肤毛孔权重</p><p>dimples：设置酒窝权重</p><p>freckles：设置雀斑权重</p><p>moles：设置痣权重</p><p>skin_imperfections：设置皮肤瑕疵权重</p><p>skin_acne：设置皮肤痤疮权重</p><p>tanned_skin：设置晒黑皮肤权重</p><p>eyes_details：设置眼部细节权重</p><p>iris_details：设置虹膜细节权重</p><p>circular_iris：设置圆形虹膜权重</p><p>circular_pupil：设置圆形瞳孔权重</p><p>light_type：设置灯光类型，按需选择即可</p><p>light_direction：设置灯光方向</p><p>light_weight：设置灯光权重参数</p><p>photorealism_improvement：设置照片现实感是否增强</p><p>prompt_start：设置开始处的正向提示词</p><p>prompt_additional：设置额外的正向提示词</p><p>prompt_end：设置结束处的正向提示词</p><p>negative_prompt：设置负向提示词</p><p><strong>输出：</strong></p><p>positive：输出正向提示词</p><p>negative：输出负向提示词</p><p>这个工作流主要就是根据适当的选项，解决用户在编写肖像提示词的细节难点。该节点其实还是作为填充提示词的节点。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000867.png" alt="image"></p><h3 id="二、PreSampling-DynamicCFG-节点"><strong>二、PreSampling (DynamicCFG)节点</strong></h3><p>__节点功能：提供动态调节提示词引导系数的预采样器 __<img src="https://xiao666.sbs/PicGo/IMG_000000868.png" alt="image"><strong>输入：</strong></p><p>pipe：输入的管道</p><p>image_to_latent：输入的图片，用来编码成潜空间图片</p><p>latent：输入的潜空间图片</p><p><strong>参数：</strong></p><p>steps：设置采样步数</p><p>cfg：设置提示词引导系数</p><p>cfg_mode：设置提示词引导系数变化的模式，分为Constant（恒定）、Linear Down（线性下降）、Consine Down（余弦下降）、Half Consine Down（半余弦下降）、Linear Up（线性上升）、Cosine Up（余弦上升）、Half Cosine Up（半余弦上升）、Power Up（升高）、Power Down（下降）、Linear</p><p>Repeating（线性重复）、Cosine Reapeating（余弦重复）、Sawtooth（锯齿波形）</p><p>cfg_scale_min：设置提示词引导系数的最小值</p><p>sampler_name：设置的采样器名字</p><p>scheduler：设置的调度器名字</p><p>denoise：设置的降噪强度</p><p>seed：设置的种子数</p><p>control_after_generate：设置的种子数生成模式，分为randomize（随机）、fixed（固定）、decrement（减少）和increment（增加）</p><p><strong>输出：</strong></p><p>pipe：输出设置完参数后的管道</p><p>该工作流主要对于不同cfg模式下产生的效果进行对比，可以根据实际需求进行选择，一般来说选择__Half Cosine Up__（半余弦上升）比较常见</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000869.png" alt="image"></p><h3 id="三、InjectNoiseToLatent节点"><strong>三、InjectNoiseToLatent节点</strong></h3><p>__节点功能：注入噪声到潜空间 __</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000870.png" alt="image"></p><p><strong>输入：</strong></p><p>pipe_to_noise：输入的管道，用来提供噪声</p><p>image_to_latent：输入的图片，用来编码成潜空间图片</p><p>latent：输入的潜空间图片、</p><p>noise：输入噪声</p><p>mask：输入的蒙版</p><p><strong>参数：</strong></p><p>strength：设置注入的噪声的强度</p><p>normalize：设置注入的噪声是否归一化处理，影响结果潜空间噪声的分布</p><p>average：设置原始噪声和注入噪声是否进行平均处理，可能获得更平滑的结果</p><p>mix_randn_amout：设置混合到潜空间噪声中随机噪声量，引入额外变量</p><p>seed：设置种子数</p><p>control_after_generate：设置的种子数生成模式，分为randomize（随机）、fixed（固定）、decrement（减少）和increment（增加）</p><p><strong>输出：</strong></p><p>latent：输出注入完噪声后形成的潜空间图片</p><p>通过如下工作流，可以看出如果__normalize__选择为否，则需要在预采样器里选择__add_noise__为disable，且采样步数适当增大，否则会出现噪声过大无法去除干净的情况；如果__normalize__选择为是，则需要在预采样器里选择__add_noise__为enable，才能生成不错的图片。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000871.png" alt="image"></p><h3 id="四、Pipe-Edit-Prompt节点"><strong>四、Pipe Edit Prompt节点</strong></h3><p><strong>节点功能：提供修改提示词的管道节点</strong><img src="https://xiao666.sbs/PicGo/IMG_000000872.png" alt="image"><strong>输入：</strong></p><p>pipe：输入的管道</p><p><strong>参数：</strong></p><p>positive：设置的正向提示词</p><p>negative：输入的负向提示词</p><p><strong>输出：</strong></p><p>pipe：输出修改完提示词后的管道</p><p>该工作流主要使用Pipe Edit Prompt节点去修改中间提示词，以此来实现同一模型加载器下不同提示词效果的呈现</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000873.png" alt="image"></p><h3 id="五、Math-String节点"><strong>五、Math String节点</strong></h3><p>__节点功能：提供了字符串的数学操作 __<img src="https://xiao666.sbs/PicGo/IMG_000000874.png" alt="image"></p><p><strong>参数：</strong></p><p>a：输入的字符串a</p><p>b：输入的字符串b</p><p>operation：使用的判断两个字符串的操作，分为a==b（两个字符串完全相同）、a！=b（字符串a和字符串b不一样）、a IN b（字符串a是字符串b的一部分）、a MATCH REGEX(b)（字符串a是否匹配字符串b的模式）、a BEGINSWITH b（字符串a是否以字符串b为开头）、a ENDSWITH b（字符串a是否以字符串b为结尾）</p><p>case_sensitive：字符串a和b匹配是否严格区分大小写，true代表区分大小写，false代表不区分大小写</p><p><strong>输出：</strong></p><p>boolean：输出判断后的结果，分为true或false</p><p>该工作流展示了Math String的在不同判断条件下的结果</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000875.png" alt="image"></p><p>该工作流以提示词中是否以hair结尾进行判断，如果是true则生成对应图片，false则生成512x512的空白图片</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000876.png" alt="image"></p><h3 id="六、Image-Detail-Transfer节点"><strong>六、Image Detail Transfer节点</strong></h3><p><strong>节点功能：将源图片的细节迁移到目标图片上</strong><img src="https://xiao666.sbs/PicGo/IMG_000000877.png" alt="image">__<br>输入：__</p><p>target：输入的目标图片</p><p>source：输入的源图片</p><p>mask：输入的提取源图片细节的蒙版部分</p><p><strong>参数：</strong></p><p>mode：设置2张图片细节迁移的方式，</p><p>- add（将源图像的高频细节添加到目标图像上）</p><p>- multiply（将源图像与目标图像的模糊版本相乘）</p><p>- screen（multiply的反向操作）</p><p>- overlay（结合multiply和screen）</p><p>- soft_light（类似overlay，但效果更柔和）</p><p>- hard_light（类似overlay，效果由源图片亮度决定）</p><p>- color_dodge（减少目标图像的亮度）</p><p>- difference（比较2者差异）</p><p>- exclusion(类似于difference，但对比度较低)</p><p>- divide（2者相除来调节目标图片）具体差别可以看工作流</p><p>blend_factor：设置混合参数，0代表与源图片无混合，一般设置在0.75及以上1.5以下</p><p>image_output：设置图片输出</p><p><strong>输出：</strong></p><p>image：输出细节迁移后的图片</p><p>该工作流显示__blend_factor__在0、0.75、2、10下的效果对比，通过对比可以看出blend factor一般设置在0.75到1.5期间效果较好</p><h3 id="image"><img src="https://xiao666.sbs/PicGo/IMG_000000878.png" alt="image"></h3><p>__<br><strong>该工作流实现了对打光后的图片实施细节迁移的全体效果展示，其中可以看出__overlay</strong>、<strong>soft_light</strong>、__hard_light__模式下迁移效果较好。<img src="https://xiao666.sbs/PicGo/IMG_000000879.png" alt="image"></p><h3 id="七、Easy-Apply-ICLight节点"><strong>七、Easy Apply ICLight节点</strong></h3><p><strong>节点功能：提供光线调节的Iclight节点，只适用SD1.5模型</strong><img src="https://xiao666.sbs/PicGo/IMG_000000880.png" alt="image"></p><p><strong>输入：</strong></p><p>model：输入的SD1.5模型</p><p>image：输入的图片</p><p>vae：输入的vae模型</p><p><strong>参数：</strong></p><p>mode：使用的模式，分为Foreground（前景，根据设置灯光调节）和Foreground&amp;Background（前景和背景，根据输入背景图片的光源作为参考灯光）</p><p>lighting：设置灯光打到的位置，分为None（无）、Left Light（左边）、Right Light（右边）、Top Light（上面）、Bottom Light（下面）、Circle Light（圆形灯光）</p><p>remove_bg：是否移除背景</p><p><strong>输出：</strong></p><p>model：输出调节后的模型</p><p>lighting_image：输出打光图片</p><p>__前景工作流图片版：__该工作流主要使用了不同的打光场景对原有图片进行新的打光处理，使新生成的图片的光源效果与对应使用的打光图片一致。随后由于新生成的图片改变了原有图片的细节和色调，所以通过__Image Detail Transfer节点__把原有图片的细节迁移到打光后的图片，使新生成的图片细节高度和原有图片一致。</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000881.png" alt="image"></p><p>__前景与背景工作流图片版：__该工作流主要与前面不同的点在于使用了自己提供的图片作为打光参考图片，生成了自提供图片的原始状态与翻转状态（左右翻转）两种情况作为打光参考图片的结果</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000882.png" alt="image"></p><h3 id="八、Math-Float-Convert-Any节点"><strong>八、Math Float/Convert Any节点</strong></h3><p><strong>节点功能：提供了浮点数的数学操作/转换所有类型</strong></p><p><img src="https://xiao666.sbs/PicGo/IMG_000000883.png" alt="image"></p><p><strong>节点1参数：</strong></p><p>a：输入的浮点数a</p><p>b：输入的浮点数b</p><p>operation：设置使用的浮点数a和b的计算，分为add（加法）、subtract（相减）、multiply（相乘）、divide（相除）、modulo（取模，也就是取余数）、power（幂运算）</p><p><strong>节点1输出：</strong></p><p>FLOAT：输出计算完后的结果</p><p><strong>节点2输入：</strong></p><p>any：输入的要转换的数据</p><p><strong>节点2参数：</strong></p><p>output_type：设置转换后的数据类型，分为string、int、float和boolean</p><p><strong>节点2输出：</strong></p><p>any：输出转换为类型的数据</p><p>该工作流展示了Math Float的基础运算</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000884.png" alt="image"></p><p>该工作流实现了在相同提示词条件下，将第一次图片的高的1.5倍作为第二次图片的高来生成第二次的图片的效果</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000885.png" alt="image"></p><h3 id="九、LatentCompositeMaskedWithCond节点"><strong>九、LatentCompositeMaskedWithCond节点</strong></h3><p>__节点功能：提供不同文本组合与蒙版结合进行输出 __</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000886.png" alt="image"></p><p><strong>输入：</strong></p><p>pipe：输入的管道</p><p>text_combine：设置的文本列表，一般与PromptList节点连用来实现不同文本组合条件的输出</p><p>source_latent：原始潜空间图片</p><p>source_mask：设置初始的提示词条件作用在原始潜空间图片上的蒙版</p><p><strong>这里可以提供加载图片的整张图片全涂抹后的白色或黑色蒙版作为蒙版</strong></p><p>destination_mask：设置初始的提示词与文本列表中的提示词组合后</p><p>作用在原始潜空间图片上的蒙版</p><p><strong>参数：</strong></p><p>text_combine_mode：设置的文本组合方式，分为add（相加）、replace（替换）、cover（覆盖）三种</p><p><strong>输出：</strong></p><p>pipe：输出的管道</p><p>latent：输出的潜空间图片，这里目前输出的是原始潜空间图片</p><p>conditioning：输出的文本结合后的正向条件</p><p><strong>add__主要是根据不同文本与原始提示词组合然后作用到目标蒙版区域的效果，其中原始提示词作用到__source_mask</strong>，组合后的提示词作用到__destination mask__<img src="https://xiao666.sbs/PicGo/IMG_000000887.png" alt="image"></p><p>在使用__replace__模式时，其中输入的__replace_text__会以__PromptList__中的提示词替换掉__Loader__中相同的词，如下图，其中的__a__就分别替换成了__stone__和__grass__。<img src="https://xiao666.sbs/PicGo/IMG_000000888.png" alt="image"></p><p>cover模式则是使用__PromptList__中的提示词完全替代__Loader__中的提示词</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000889.png" alt="image"></p><h3 id="十、If-else节点"><strong>十、If else节点</strong></h3><p><strong>节点功能：提供if-else判断输出true或false的选项</strong><img src="https://xiao666.sbs/PicGo/IMG_000000890.png" alt="image"></p><p><strong>输入：</strong></p><p>on_true：接入当boolean为true时应该输出的结果</p><p>on_false：接入当boolean为false时应该输出的结果</p><p><strong>参数：</strong></p><p>boolean：设置判断为true或false，可转为输入项</p><p><strong>输出：</strong></p><p>any: 输出满足boolean判断条件的结果</p><p>当是boolean是true的时候输出on_true选项，当boolean是false时输出on_false选项</p><p><img src="https://xiao666.sbs/PicGo/IMG_000000891.png" alt="image"></p><p>__ComfyUI Easy Use插件（一）: __<a href="https://t.zsxq.com/AAZQm"><strong>https://articles.zsxq.com/easyuse/1.html</strong></a></p><p>__ComfyUI Easy Use插件（二）: __<a href="https://t.zsxq.com/lNdvT"><strong>https://articles.zsxq.com/easyuse/2.html</strong></a></p><p>__ComfyUI Easy Use插件（三）: __<a href="https://t.zsxq.com/UsFSp"><strong>https://articles.zsxq.com/easyuse/3.html</strong></a></p><p>__ComfyUI Easy Use插件（四）: __<a href="https://t.zsxq.com/gSJA1"><strong>https://articles.zsxq.com/easyuse/4.html</strong></a></p><p>__ComfyUI Easy Use插件（五）: __<a href="https://t.zsxq.com/IAye6"><strong>https://articles.zsxq.com/easyuse/5.html</strong></a></p><p>__ComfyUI Easy Use插件（六）: __<a href="https://t.zsxq.com/PhouI"><strong>https://articles.zsxq.com/easyuse/6.html</strong></a></p><p>__ComfyUI Easy Use插件（七）: __<a href="https://t.zsxq.com/jDjyM"><strong>https://articles.zsxq.com/easyuse/7.html</strong></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前言：&quot;&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;该插件由B站大佬乱乱呀AI进行开发出来的，此插件主要在使用管道、简化工作流、提供简便工具和集成化等方面起到了明显作用。&lt;/p&gt;
&lt;h2 id=&quot;目录&quot;&gt;&lt;strong&gt;目录&lt;/strong&gt;&lt;/h</summary>
      
    
    
    
    <category term="知识星球" scheme="https://www.fomal.cc/categories/%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83/"/>
    
    
    <category term="啦啦啦的小黄瓜ComfyUI" scheme="https://www.fomal.cc/tags/%E5%95%A6%E5%95%A6%E5%95%A6%E7%9A%84%E5%B0%8F%E9%BB%84%E7%93%9CComfyUI/"/>
    
  </entry>
  
</feed>
